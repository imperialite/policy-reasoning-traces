document,reasoning,verdict,policy_clauses,relevant_cases
"The data subject complained about the installation of a surveillance camera oriented towards a public space. There was no sign indicating the presence nor the purpose of this camera.

The proprietor informed that this camera was a false one and that it did not record any footage, and that it was installed for dissuasive purposes only.","The Spanish DPA closed the procedure since there was no processing of personal data taking place. However, it noted that the camera should preferably be oriented towards a private space, because individuals could still feel intimidated by the presence of this camera.",COMPLIANT,Article 5,"[2,21,26,41,30]"
"A consumers organisation lodged a complaint with the Spanish DPA (AEPD) against Facebook, since according to a series of news articles, Facebook had shared their users' personal data with over 150 third organisations without the users' consent.","The AEPD referred the complaint to the Irish Data Protection Commission (DPC) through the Internal Market Information system (IMI), since Facebook Ireland has their main establishment in Ireland, pursuant to the definition set by Article 4(16) GDPR. And, since the DPC is the lead authority with regard to Facebook Ireland, the DPC is in charge of cases regarding Facebook's international transfers of personal data, in accordance to Article 4(23) GDPR.

According to the AEPD, there are other concerned DPAs in this case, as defined in Article 4(22) GDPR: Spain, Belgium, Rhineland-Palatinate, Netherlands, Lower Saxony, Italy, Luxembourg, France, Sweden, Thuringia, Hesse, Norway, Berlin, Hungary, Finland, Saarland, Slovenia, North Rhine-Westphalia, Portugal, Slovakia, Greece, Austria and Poland.

The DPC rejected the case, alleging that it came from an organisation without an individual mandate. According to the DPC, Ireland has not implemented Article 80(2) GDPR and therefore the authority cannot handle a complaint lodged by an organisation mentioned in such Article (a not-for-profit body, organisation or association which has been properly constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest, and is active in the field of the protection of data subjects' rights and freedoms with regard to the protection of their personal data).

Since the case had been rejected, the AEPD manifested that it was the competent authority to notify the complainant, in accordance with Article 60(8) GDPR. Therefore, the AEPD archived the proceedings, without prejudice of the consumers organisation lodging a new complaint following the mandate of an individual data subject.

Notwithstanding, according to the DPC, these facts are currently under investigation by the DPA within the competences attributed to it as lead authority.",COMPLIANT,"Article 4, Article 60, Article 80","[12,22,9,44,42]"
"Rights International Spain (RIS), a Spanish human rights NGO, filed a claim against LGBTQ Social Network App GRINDR (Grindr LLC) with the Spanish DPA (AEPD) on 9 March 2020. The claim was based on the “Out of Control” report on targeted advertising practices published by the Norwegian Consumer Council (NCC), and the claimant selected Grindr as an example of potentially problematic data mining practices without data subject’s knowledge and consent.

DPA mutual assistance under Article 61 GDPR

The AEPD inquired if any other DPAs were carrying out procedures on this topic through the mutual assistance provision in Article 61 GDPR. The AEDP received affirmative replies from the Norwegian, Slovenian and French DPA.

The Norwegian DPA informed the AEPD that its current investigation was in response to a claim received in January 2020. Hence, it was basing its investigation on Grindr’s active Consent Management Platform (CMP) at that time, and not on the updated CMP introduced in April 2020. The Norwegian DPA expressed that, according to their investigation, the consent obtained by Grindr for processing personal data used for marketing purposes seemed to be in breach of GDPR (see the summary of the Norwegian DPA's Grindr decision here).

The Norwegian DPA also considered that Grindr was specifically oriented towards the LGBTQ community, and therefore, a legal basis under Article 9(2) GDPR for the processing of special categories of data was also required in this case.

The Slovenian DPA informed the AEPD that it had also received a claim based on the same report, and was still awaiting a reply from Grindr’s representatives. The French DPA stated that it had received two complaints regarding this issue, but had not yet initiated any procedures at that moment.

Validity of consent

In its response to the AEPD, Grindr highlighted that it had updated its CMP, which gives the data subject granular information regarding every non-essential processing element, allowing the user to actively consent to each individual one. This, in turn, is separated from the acceptance to their Terms and Conditions, as well as their Privacy Policy. Grindr also provided evidence that all these elements are set to non-consent by default, and users are not nudged in any way to opt in to the processing of any of this data.

Additionally, Grindr noted that users can opt in or out to the processing of personal data for targeted advertisement in both the free and paid version of the application, and that the application will function in the same manner regardless, with the only difference that in the free version, the advertisement will not be personalised.

Processing of special categories of personal data

Grindr claimed that the only sensitive data processed are the data subject’s HIV status, the date of their latest HIV test, and the ethnicity category, and that this data is not shared with any third party, nor is it accessible to third party cookies or online tracking technologies. Additionally, Grindr insisted that despite promoting itself as ""the world's largest social networking app for gay, bisexual, transgender and pansexual people” it is not possible to extract the user's sexual orientation from its use, since it does not strictly adhere to closed sexual orientations or specific gender identities.

Automated individual decision-making, including profiling

Lastly, Grindr stated that it does not carry out automated decision-making to profile its users, and that it only uses automated security systems to block fraudulent or spam accounts (which are subject to human review if contested by the account holder), or to eliminate unacceptable images according to their Terms and Conditions.","Scope of the investigation

The AEPD began by stating that although the claim was received in March 2020, their investigation is based on Grindr current CMP, which was updated in April 2020 (unlike the Norwegian DPA’s investigation previously mentioned in the Facts section, which is based on their previous CMP). The AEPD also stated that this was a generic investigation, in response to a complaint that was merely based on the NCC report, with no specific evidence with which to contrast if what Grindr states is actually true in practice.

Validity of consent

The AEPD held that according to Grindr’s updated CMP, the processing of personal data was lawful based on the data subject’s consent under Article 6(1)(a) GDPR, which in turn meets the conditions for consent laid out in Article 7 GDPR. The AEPD highlighted that this consent was free, with an option to willfully accept properly individualised and differentiated elements. Additionally, the AEPD held that this processing was compliant with the principle of transparency established in Article 5(1)(a) GDPR and further developed in Article 12 GDPR, and that the data subject was duly provided with the information required by Article 13 GDPR.

Processing of special categories of personal data

The AEPD did not find that Grindr processed any special category of personal data in breach of Article 9 GDPR because it does not directly collect information regarding a person’s sexual orientation, and that the platform does not even have a field to specify this information on a user’s profile. The AEDP also noted that this data can only be shared voluntarily by users in their “About Me” text, or in private messages with other users, and that this information would not be accessible to third parties for advertising purposes. The AEPD also deferred that Grindr’s denial that use of the application would reveal any specific sexual orientation due to the fact that the platform is open to all sexual orientations and gender identities, and in Grindr’s own words, including heterosexuals ""out of curiosity or to find a broader expression of self or to interact with other users"".

Automated individual decision-making, including profiling

Lastly, the AEDP held that Grindr does not seem to carry out automated decision-making that can affect data subject rights or process personal data to profile them, finding no apparent violation of Article 22 GDPR.

Conclusion

Based on the considerations, the AEDP held that its investigation had not found any processing of personal data by Grindr in breach of the GDPR. it therefore issued a decision to archive the procedure.",COMPLIANT,"Article 5, Article 6, Article 7, Article 9, Article 12, Article 13, Article 22, Article 61","[34,13,44,14,36]"
"The Spanish DPA investigated the impact study carried out by the Spanish Ministry of Transport on the daily commuting trends during the first days of COVID pandemic. In particular the investigation focused on whether the data used for the study was appropriately pseudonymised and whether there was any risk of re-using the data for different purposes to the original ones.

Data from individuals' mobile phones belonging to one operator were collected during several days to measure daily commuting trends of people on regular days. This data was pseudonymised by the operator with hash techniques and by grouping the data by areas of origin of at least 5000 people. Then the data was provided to a consultant firm that aggregated such data automatically and then processed it to produce the indicators required by the Ministry of Transport.

All the measures put in place to unlink the data, pseudonymise, aggregate and further group and process it to produce the final indicators are considered enough to make practically impossible the identification of the data subjects that originate it.",The Spanish DPA held that the measures put in place by the Spanish Ministry of Transport to conduct the mobility study were enough to ensure that the data could not be associated to individual people or re-used for purposes incompatible with the original ones.,COMPLIANT,Article 89,"[42,32,18,5,2]"
"The Directorate for National Security of the Ministry of Interior issued guidelines for the police forces to monitor news and social networks to spot fake news and misinformation, to prevent some actors from causing social stress, in light of the covid-19 pandemic.

This came to the Spanish DPA (AEPD) knowledge, that launched an investigation to verify that such behaviour complied with the personal data regulations.

Such guidelines were issued to prevent and minimize the effects of misinformation, with extreme vigilance and monitoring of networks and websites where false messages and information aimed at increasing social stress are disseminated, and, where appropriate, calling for the intervention measures provided for in the applicable legislation"".

According to the guidelines, within the surveillance and monitoring of networks and web pages, intervention shall only be carried out in accordance with the aforementioned purposes and principles and always under the protection of the applicable legislation. Also, personal data will only be processed when there is sign of a criminal offence, in accordance with the Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data.

If such activities were related to national security, then the processed would be carried out with basis on the national legislation regarding state secrets and classified matters.

In their response to the DPA, the Directorate for National Security also stated that they do not collect personal data, but only carry out a daily observation of news or public information from social networks, where the information collected relates to data of a public nature, shared by its authors through social networks and public media, consisting primarily of the content of the communication and the medium of dissemination.

For this, specialized officers from the Spanish Civil Guard (""Guardia Civil"") browse the news and create anonymous users to monitor (read) social networks such as Twitter, Facebook, Instagram, Badoo and other websites.

Afterwards, reports with reference to cybercrime, cyberterrorism, hacktivism, cyberattacks, misinformation and news summaries are issued. If there is a sign of a criminal offence, evidence is gathered. Such reports are stored for 5 years.","The DPA concluded that there was no violation of the GDPR, that is not applicable in accordance with its Article 2, nor with the Directive (EU) 2016/680, as personal data were not processed, as the reports showed, and there was no evidence that there was any illegal additional processing. Therefore, the presumption of innocence principle applied.

Hence, the AEPD archived the case.",COMPLIANT,Article 2,"[8,12,18,42,47]"
"The Spanish DPA (AEPD) launched an investigation on body temperature checks carried out by El Corte Inglés, the biggest Spanish department store companies. The company was using thermographic cameras to verify if employees, customers or visitors of its establishments had a high body temperature, as a potential symptom of coronavirus.

According to the system adopted by El Corte Iglés, Persons passed through the range of the cameras, that showed temperature map to private security guards. The information received does not show recognizable details to make possible identification of visitors, nor is it combined with data taken with video surveillance cameras. Body temperature data will be displayed in real-time and only by a particular member of the private security department of El Corte Inglés, located in the control centre, which is provided with an access control and video surveillance system. Data of temperature checks were neither registered, stored or processed in any way. The main purpose of the temperature measurement would be to dissuade symptomatic persons from coming, as well as to reassure the rest of the customers and employees.","The DPA emphasises that body temperature shall be considered personal data and, consequently, data concerning health according to Article 4(1) and 4(15) GDPR. Hence, temperature-check measures could be considered processing of health data relating to an identified or identifiable natural person. If this is the case, compliance with a legal obligation according to Article 6(1)(c) GDPR would be a valid legal basis, related to the exception provided by Article 9(2)(h) GDPR: the employer has the obligation to ensure the safety and health of employees, according to articles 14 and following of Law 31/1995 of 8 November on Prevention of Occupational Risks. This obligation operates as an exception that allows the processing of health data, under the circumstances provided in Article 9.2.h) of the GDPR, and as a legal basis that legitimizes the processing, since the processing is necessary for the fulfilment of a legal obligation imposed on the employer.

At any rate, the Spanish DPA did not reach a solid conclusion regarding whether temperature measurement falls under material scope of GDPR and remarked that the circumstances of each particular case should be taken into account. The device used and other variables that could make a person identifiable shall be considered, such as if body temperature data are registered or stored.

Nevertheless, in this particular case, the Spanish DPA concluded that the GDPR was not applicable, as it did not fall under its material scope: there is not processing of data related to identifiable persons.

The main circumstances taken into account by the Spanish DPA are as follows: the measurement of temperature is not followed by identity checks of visitors; the data of temperature obtained is neither registered nor stored, nor there are other circumstances that enable data subject identification.

Additionally, AEPD underlines that the measurement of temperature may be conducted by private security guards, according to Article 32.1 of the Private Security Act, which establishes that they are responsible, among other functions, for the protection of persons ""carrying out checks, searches and preventions necessary for the fulfilment of their mission"".",COMPLIANT,"Article 4, Article 6, Article 9","[22,49,45,12,8]"
"The Spanish DPA (AEPD) launched an investigation on the company that manages the underground service of Bilbao, one of the main Spanish cities. In the context of the covid-19 pandemic, the company was using thermal cameras to verify if the users of the underground had a higher temperature than a threshold (37.3ºC), in order to identify potential infected people.

People were randomly picked to pass through the range of the cameras, that would show their temperature. What was shown was only a temperature map; images were not processed in any way, nor there was any kind of facial recognition system. Data were neither registered, stored or processed in any way.

The only consequence deriving from the temperature map would be that the employees in charge would carry out a second test, with a clinic thermometer, to verify whether the temperature was above the threshold. Then, if still shown to be above the threshold, they would receive a recommendation on how to act (i.e. not use the metro and contact a doctor).","The Spanish DPA, in line with the allegations of the controller, concluded that the GDPR was not applicable to this case, as it did not fall under its material scope.

The temperature measurement was done without identification, without recording and without registering data of the persons, as their identification is not required either by official document or verbally. At no time was any personal data stored or recorded, neither image data, nor temperature data, nor name and surname, nor any other data relating to an identified or identifiable natural person. No information was stored, which could imply the impossibility of identifying a person by collecting only indirect identifiers, such as the aforementioned heat map or temperature; and no direct identifiers, such as an image or similar, nor the results of the temperature measurements were stored nor were the results transferred to another kind of non-automated or automated support.

At all times, the anonymity of the persons was maintained, as they were not required to identify themselves, and there was no recording, as the image was issued in real time, in a heat map that did not allow a person to be unequivocally identified.

Therefore, following Article 2(1) GDPR, the AEPD concluded that there was no processing of data, neither automated or non-automated but meant to be part of a filing system. Hence, it is outside the material scope of the GDPR.

Also, with regards to the definition of personal data from Article 4(1) GDPR, the DPA did not reach a firm conclusion, but remarked that the circumstances of each particular case should be taken into account. The device used and other variables that could make a person identifiable shall be considered. In this case, even if the person remained anonymous, as they were not asked to identify themselves, the procedure was carried out in public space, so any person that was not allowed to enter the subway because their high temperature would be known to have a temperature higher than 37.3ºC, what is, in addition, health data, so it is classified as sensitive data in accordance with Article 9 GDPR. Therefore, third persons would be able to know that a particular person might be infected by the SARS-CoV-2, as fever is a symptom of covid-19. Therefore, it would be debatable, in a case by case basis, whether the circumstances could have made that a particular person was identifiable.

The DPA also discusses an hypothetical case in which such activity, or a similar activity, it could be considered processing of personal data; then, a legal basis would be necessary for the processing. Options for that would be a vital interest, a public interest or compliance with a legal obligation. Additionally, an exception from Article 9 would be necessary.

In any case, the DPA reached the conclusion that the fact that the persons were not asked to identified themselves definitely meant that they were not identifiable and that no kind of data related to temperature or to the scanned persons was stored or processed in any way. Therefore, as there is not processing of data related to identifiable persons, the case was considered not to fall under the scope of the GDPR, and it was archived.",COMPLIANT,"Article 2, Article 4","[10,20,34,38,48]"
"A data subject addressed the Spanish DPA (AEPD) to request the removal of sexual images of themselves from several websites and from Twitter, where someone had created an account with a fake profile of the complainant where videos and pics were posted.

The DPA sent requests to Twitter and the mentioned websites to take down the content, with limited success.

With regards to the original images, they had been uploaded by the data subject to a sex webcam website. This site, as the respondent, alleged that the complainant had accepted their terms and conditions, that included a box that provided:

""Check this box to attest you have read and agree with the Terms of Use of Cam4 and you acknowledge you have licensed your images to Cam4 and that you will keep all documents.""

The DPA could verify that the box had been ticked by the complainant.","The AEPD concluded that, given that the complainant had ticked the mentioned box and therefore had handed their rights over their images to the controller, the controller had a legitimate basis for the processing.

Hence, the AEPD archived the case.",COMPLIANT,Article 6,"[1,12,9,32,18]"
"A data subject lodged a complaint with the Spanish DPA (AEPD) against Niantic, a software developer, regarding their interactive game ""Pokemon Go"".

Pokemon GO is a game in which users interact with the real world, so they share their location in order to walk the map. This include sharing their user data with others when they go to specific locations called ""gyms"", in which they play together with others. For that, a user needs to be at least at 500m from the site. Therefore, their real location is also known.

However, some users fake their real location, so they can access the gyms from further away. Therefore, the location of other users may be also shared not only with regular players but with players that are faking their location.

From this data, that can easily indicate where a person lives or works, malicious users could access this information and also infer the real identity of these subjects, what may lead to harassment or stalking. It is important to note that a big number of players of the game are minors, what increases the risk.

The complainant had asked Niantic to avoid sharing location data with users that were known to be faking their location.

Niantic stated that they have a security policy in place that tries to tackle that problem. Players who are detected to use these methods are warned with a three-strikes mechanism. They have other additional measures, such as information about the data that is shared, a recommendation not to provide your real name, the lack of a chat where users can directly interact, prohibitions on harassing and misuse, limited sharing of data, and different privacy options and information.","The AEPD considered that the controller had correctly assessed the risks and implemented adequate measures to mitigate them. Their three-strikes mechanism for users that fake their location is deemed to be enough to deal with the alleged risk. Therefore, the DPA decided to archive the case.",COMPLIANT,"Article 6, Article 32","[17,34,35,9,47]"
"A data subject filed a complaint with the Spanish DPA (AEPD) against the Local Police of the Municipal Council of La Puebla del Río, Seville after a police officer took a photograph of their ID with a cell phone. The data subject claimed that the device was privately owned by the police officer.

The context involved restrictive measures due to the Covid 19 pandemic, and the City of La Puebla del Río had its perimeter closed, with entry and exit controls for vehicles. The police officers managed to identify that the data subject was from a different location, and their ID was required and photographed, based on public safety regulatory legislation. The device was actually owned by the police unit, and was not the private property of the agent. Upon completion of police registration procedure, the photograph was removed from the device.

The purpose of taking the photograph was to obtain an image of the ID without physically handling it, and carry out the necessary checks in accordance with Article 16 of the Spanish Citizen Safety Law (Ley Orgánica 4/2015, de 30 de marzo, de protección de la seguridad ciudadana) to comply with specific health and security measures in the context of the pandemic.","The AEPD held that as long as data protection principles in the GDPR and the Spanish Data Protection Act (Ley Orgánica 3/2018 Ley Orgánica 3/2018 de Protección de Datos Personales y Garantía de los Derechos Digitales - LOPDGDD) were observed, state security bodies could process data to achieve their inherent objectives, including prevention, investigation, detection or repression of criminal offenses. The AEPD concluded that in this case, given the exceptional context related to the pandemic, a police agent's use of a cell phone which is owned by the police unit to photograph ID documents complied with the security measures established in Article 32 GDPR, and therefore dismissed the case.",COMPLIANT,"Article 5, Article 32","[4,1,10,32,29]"
"A civil servant of the Spanish Tax Authority complained about their employer beginning to use a biometric system to register access and working hours of employees without proper information to the affected data subjects.

The Tax Authority rejected the claim by providing evidence of the information provided to the employees before starting the collection of their fingerprints and the further information provided before starting to actually use the new system","The Spanish DPA held that the information provided by the Tax Authority to its employees was clear, precise and concise enough to satisfy the requirements of the GDPR. Furthermore, the Tax Authority also complied with the requirements of choosing the correct legal basis for the processing of sensitive data and of performing a Data Protection Impact Assessment.",COMPLIANT,Article 13,"[44,30,36,17,14]"
"The data subject filed a complaint with the Spanish DPA (AEPD) because the company’s website required user’s email address to access the website (WESTWING.ES). According to them, it was not possible to freely access the site. Moreover, the complainant indicated that analytic cookies were installed regardless of the user’s cookies’ preferences.

The company answered that WESTWING.ES is a private shopping club that only registered members can access to. Therefore, the legal basis for the processing of personal data was the necessity for the performance of a contract (Article 6(1)(b) GDPR).

The AEPD confirmed that the website was not public and that only registered members can access to it. It concluded that data subjects were duly informed about this in the website’s Privacy Policy. However, the AEPD found that the website automatically installed 11 non-identified cookies when accessing it for the first time. These cookies were not identified in the Cookies Policy, so it was not possible to classify them as necessary or not. Therefore, Spanish DPA requested the company to inform users about all cookies used on the website and to ask for consent before automatically installing any non-necessary cookie.

The company admitted that those 11 cookies were not adequately identified in their Cookies Policy. They clarified that those cookies were necessary ones, and that law did not required consent in those cases. However, for transparency reasons, they updated their cookie banner with information on the use of necessary cookies.","The AEPD considered that the company did not infringe Article 22(2) of the Spanish Law regulating cookies and unsolicited communications (LSSI). This law permits companies to install necessary or technical cookies without users’ consent. The website only automatically installed necessary or technical cookies without users’ consent. Non-necessary cookies asked for users’ consent. Moreover, after the AEPD request, the cookie banner informed users about the use of necessary cookies. Therefore, the AEPD closed the procedure.",COMPLIANT,Article 6,"[22,47,28,15,12]"
"A data subject lodged a complaint with the Spanish DPA (AEPD) after Google did not fulfilled their right to erasure. This request had to do with a Facebook group in which pictures from the military were uploaded. A picture of the complainant, along with their personal data, had been posted there.

Additionally, the information accompanying it was false, according to the complainant. The information was related to the alleged commission of a criminal offence while participating in a redacted act.

According to the DPA, the complainant had not been able to prove that the information was untrue.","The AEPD discussed the right to be forgotten and its requirements. The AEPD remarked that the right to be forgotten is a right to make a search engine de-list results that contain personal data that may be obsolete and/or incorrect, so as to avoid the harm that such publicly available information may cause to the data subject.

However, the DPA remarked that this is not a right to make an online curriculum on demand, to control the online discourse about oneself or to get a tailored past on the internet by only allowing there the information that is positive or desired.

The AEPD also stated that, in this case, there was no interest from the data subject overriding the rights to freedom of speech and freedom of information. Firstly, because the information was concerning a criminal offence, what is considered itself to be of public interest, according to national case law. It is also taken into account the fact that this information is related to the professional life of the data subject, that is less intimate than private life, and also implies a higher level of public interest towards it.

Also, the AEPD remarks, the fact that a criticism may be offensive, unpleasant, distasteful and hurtful, it does not mean that such opinions are not covered by the freedom of expression and opinion of their authors, as opposed to the right to data protection, specially when they contribute to the formation of public opinion on a publicly relevant topic.

Additionally, the DPA noted that the right to data protection should be distinguished and separated from the right to honour and self-image that is regulated in Spain by a national law. Attacks to one's honour, if the information is believed to be inaccurate and harmful for one's image, shall be discussed in civil courts with regards to this right.

Hence, the AEPD concluded that in this case there was no interest from the data subject overriding the rights to freedom of speech and freedom of information, specially when the information was not obsolete and not proven to be incorrect. The DPA therefore archived the case.",COMPLIANT,Article 17,"[5,28,49,4,38]"
"A worker of a University filed a complaint against their employer with the Spanish DPA (AEPD). The data subject claimed that the controller had not answered a rectification request from Article 16 GDPR.

The data subject wanted the employer to rectify a productivity record deriving from the Pegasus application, alleging that the result was not adequate. This application took into account the degree of satisfaction of the users (foreseeably students). The worker alleged that the coefficients used by the formula that calculated the productivity were not disclosed, which led to a lack of transparency. Additionally, the worker alleged that the process was not objective, impartial and was discriminatory. The worker further argued that productivity must be considered personal data.","The AEPD, however, dissented and stated that what the data subject asked for was not included within the framework of data protection.

Therefore, Article 16 GDPR cannot be applied. Article 16 refers to inaccurate personal data, not to the rectification of processes within the workplace.

The AEPD stated that it is not within their functions to rectify parameters that may affect the economic outcome or performance of individuals, regardless the data subjects consider the formula is accurate, since they affect various individuals and are therefore not considered personal data.",COMPLIANT,Article 16,"[22,27,37,11,17]"
"A data subject filed a complaint with the Spanish DPA (AEPD) against a university where they had had different roles, (""an employee, an employee with disciplinary proceedings, undergraduate student, master's student, course assistant, interested party in administrative procedures, participant in administrative procedures, participant in selection processes, litigant, opposing party, etc."").

The university provided the data subject with certain information (partly non-personal data too) and asked them to specify what additional information they required. They rejected the rest of the generic request with grounds on Article 12(5). The university alleged that they had tried to answer to the request on time but that they didn't have the resources, given that they have 26000 students, 1122 teaching and research staff, 521 administrative staff, 269 project staff; with a teaching structure of 7 faculties, 2 schools, 4 research institutes, 27 departments, 33 services and administrative Units, and 4 management centres, and the data subject had had a role in many of them, as an alumni, worker, and litigant.

The controller also held that they were implementing a more efficient system to handle data subject request. They claim that the data subject is just trying to diminish the university's functioning via different requests, claims and lawsuits, also in law fields other than data protection.

The data subject reiterated the initial request in the same terms. To this, the controller again alleged Article 12(5) GDPR and stated that it constituted an abuse of rights.","The AEPD aligned with the controller and found that the data subject was abusively exercising their rights in bad faith. The AEPD brought forward Article 12(5) GDPR, as well as Article 7 of the Spanish Civil Code, that states that rights must be exercised in good faith, and that it cannot be done in a way that the natural limits of the right are respected.

They also based their decision in the interpretation of such Article by the Spanish Supreme Court, saying that the abuse of rights entails the exercise of a right that, while complying with the formal requirements of such right, the essence of the rights, and its ethos and nature are not respected.

In this regard, the AEPD's records show that the complainant had abnormally exercised their right, both in quantitative terms (this was not the first time they had complained against the respondent) and qualitative terms (given the submission of applications with numerous claims that are not subsequently clarified by the data subject  in order to facilitate their processing when requested to do so).

The necessity of good faith is also stated by the Spanish Procedural Civil Act in its Article 247, also interpreted by the Spanish Supreme Court, that has stated in this regard that complainants shall act in good faith, saying that acting in good faith also means not claiming to access data in a generic way when it can be done through other means. In this case, the AEPD condemns the negative of the data subject to narrow their claim, given that they are aware of the roles they had had in such university and can possibly know what particular information the university holds on them and what specific information they want to access.

Based on these grounds, the AEPD decides not to uphold the data subject's claim and archives the proceeding.",COMPLIANT,"Article 12, Article 13, Article 15","[6,14,29,31,32]"
A data subject made a complaint to the Spanish DPA because a party in a legal proceeding against the data subject shared with another counterparty in the same legal proceeding with the same data subject a legal document containing personal data of the data subject.,"The Spanish DPA, based on case-law from the Spanish Constitutional Court, held that in the context of legal proceeding where the data subject is a party, it is not necessary to ask for his consent  in order to share documents that are used as evidence in a trial with the court and with the other counterparties in the proceedings.",COMPLIANT,Article 4,"[22,24,33,28,46]"
"A claim was filled against the municipality of Fuenlabrada (Spain) because of its usage of drones in order to control vehicle traffic. The claim concerned the lack of communication of the identity of the controller and of the place where to exercise data subjects' rights.

The municipality of Fuenlabrada pointed out that the information on the processing operation is shared through electronic means, through the social networks of the Local Police, through posters in the interested areas, and publication on the website of the City Municipality.

The Spanish DPA asked the municipality of Fuenlabrada to provide copy of the Data Protection Impact Assessment (DPIA) completed before the processing activity. The municipality did not complete a DPIA because it considered that risk for data subjects would be ""acceptable"".","The Spanish DPA considered that the defendant fulfilled the duty of information in accordance with GDPR.

The Spanish DPA considered that Article 35 GDPR applies in this case and thus a DPIA is necessary. The controller has therefore carried out the aforementioned evaluation and provided a copy of it. In the DPIA is concluded that the images recorded with the drones do not have to be treated especially sensitive and may not affect the rights or freedoms of people, since, except for pedestrians that can be visualized momentarily (that are not usually recognizable), in these recordings only vehicles appear in traffic, so the treatment itself would not offer a special risk. Therefore, the controller considers that the treatment can be carried out with the measures taken so far and without the need to apply more incisive measures, specifying that the sum of circumstances that occur in this treatment and the type of personal data that is treated implies that the residual risk is acceptable.

Taking in consideration this ex post DPIA, the Spanish DPA concluded that the Municipality of Fuenlabrada complies with GDPR.",COMPLIANT,"Article 14, Article 35","[28,15,39,33,43]"
"A company called Gureak Lanean suffered an attempt of hacking of their servers. The attacker accessed the data stored in several servers, although according to the company, only a scarce amount of information went to the outside. The AEPD did not receive any complaint from any affected data subject.","The AEPD concluded that there was no violation of Article 32(1) GDPR, because the company had implemented appropriate technical and organisational measures to ensure a level of security, as they had protocols in case of breach, had a quick reaction and has already taken measures to avoid breaches from happening in the future.",COMPLIANT,Article 32,"[3,15,32,33,45]"
"A data subject made a complaint to the Spanish DPA alleging that the website of an Spanish political party (Podemos) placed analytical cookies when visiting such website before asking for consent, neither it offered the option for rejecting cookies or opting out afterwards.","The Spanish DPA analyzed the provisions of the Spanish legislation related to electronic commerce and information society services (LSSI) and concluded that only the websites that fall under the definition of ""service provider"" (with an economic activity) have to comply with the requirements of said legislation.

It therefore decided that, given that the website of the political party ""Podemos"" is not a ""service provider"" in the meaning of the Spanish legislation, the complaint could not be upheld.",COMPLIANT,Article 13,"[2,17,23,39,26]"
"A Spanish football club, Real Madrid, suffered a data breach in which contracts, sport licenses, budgets, and other types of identifying data and economic information, related to around 1000 persons. This was done by a hacker that accessed the system with stolen credentials.

The club diligently informed of such breach to the competent authority and proceeded to scan the deep web and regular Real Madrid information on the web to verify whether the information had been made public or was for sale. There was no evidence that the hacked information had been used, nor received the authority any complaints regarding it.

After the breach, the controller installed additional measures to prevent it from happening again, namely new cyber-security measures, a double factor identification system, new laptop security protocols, and blocking the IPs from which the attack came.

The controller issued a report considering that the stolen information would not affect the reputation of the people involved, not pose any kind of risk to them. Therefore, they decided not to communicate the breach to the data subjects.

Additionally, a police investigation is taking place.","The AEPD concluded that the controller had adequate security measures and was diligent to mitigate its consequences and to report it to the authority.

Such adequate measures included, among others:

* Data protection policy
* Security policies and protocols
* Measures to prevent computer atacks
* Tools for monitoring, detecting, analysis and reporting security incidents
* Data protection and security trainings
* Access control measures
* Risk analysis of the affected data processing activities
* Cyber-security reports
* Cyber-security guides

Because of this, the AEPD considered that Real Madrid had implemented appropriate technical and organisational measures to ensure a certain level of security. Therefore, they did not find a violation of Article 32(1) and decided not to fine the controller.",COMPLIANT,Article 32,"[23,18,15,9,43]"
"After a security guard of Madrid’s public transport system filmed the screen of a video surveillance system with his phone and shared the video via WhatsApp, the AEPD carried out an investigation.","The AEPD found a data breach due to the improper filming of the screens in the video surveillance control center.

However, the ITAA had technical and organizational measures to deal with the incident. These measures allowed the controller to detect, identify, analyze and classify the data breach. It also took a reasonable reaction to notify, communicate and minimize the impact and implement reasonable measures to avoid a repetition of the situation in the future through the implementation of an action plan.

Therefore, the AEPD found that the controller did not violated Articles 32 and 33 GDPR.",COMPLIANT,"Article 32, Article 33","[13,6,0,37,1]"
"The decision is the consequence of a complaint submitted by a Spanish citizen stating that the data controller, who is the owner of a pub, had installed a video surveillance system recording part of the public road; such complaint included a picture proving that the video surveillance system was installed in the main façade of the pub.","Based on point 4.3 of the AEPD's decision 1/2006 (""…those cameras installed in private spaces will only be able to record public spaces as long as it is essential for the required surveillance…"") and the principle of presumption of innocence (as the complainant has not been able to prove the non-compliance), the AEPD understood that the data controller has not infringed the data minimisation principle and decided not to take further actions.",COMPLIANT,Article 5,"[22,33,24,19,45]"
The controller's video surveillance system is oriented toward the public space. The complainant questions its lawfulness.,"The AEPD accepts the arguments put forward by the controller and concludes that the processing does not infringe the data minimisation principle. In so doing, the EAPD considered different factors including the the presumption of innocence principle that can only be overcome by persuasive evidence. In this case, there was no such an evidence that the video surveillance system had recorded the public road. Therefore the Authority closed the procedure without imposing any fine.",COMPLIANT,Article 5,"[5,9,30,37,4]"
"A worker of a clinic lodged a complaint with the Spanish DPA because their employer had used their image for advertisement purposes without consent. They had placed huge banners with it in a display window.

The banners were on sight for more than a year, despite the worker's repetitive request, via different ways, for them to take them down.

Such banners were, however, taken down after the worker made a notarial request. The clinic alleged, mainly, that the worker had signed an image rights transfer agreement previous to the display of the banner.","The Spanish DPA held that the fact that the worker had signed an image rights transfer agreement previous to the display of the banner was considered as a legal basis for data processing. Hence, they did not find a violation of Article 6.",COMPLIANT,Article 6,"[42,48,15,28,9]"
"On July 7th 2016, a 18-year-old girl was raped by 5 men (known as ""La Manada"") during the traditional San Fermín festivity in Pamplona, Spain. Besides, during such act the perpetrators recorded and photographed the victim with their mobile phones. Subsequently, a criminal procedure was launched.

The AEPD received two complaints on different facts related to this case: 1) personal data had been published in different Spanish forums, and 2) personal data regarding the proceeding had also been accidentally disclosed by the Court. Therefore, the AEPD launched an investigation on the whole case and related facts, part of which decided in different proceedings.

The proceeding dealing with the facts related to the rape itself was suspended until the criminal procedure was concluded, according to Article 22(1)(g) of the Spanish Public Procedural Act. On February 8th 2021, this procedure came to an end, and thus the AEPD resumed their own proceeding on the matter.

The perpetrators were sentenced in the criminal proceeding to three years and three months of prison, and to a fine, for a criminal offence against privacy included in Article 197(1) of the Spanish Criminal Code, with the aggravating circumstance from Article 197(5) of being data related to the sex life of the victim.","In this case, the AEPD found an infringement of Article 7(3) of the former Spanish Data Protection Act (LOPD) for the processing of special categories of personal data, such as data referring to the victim's sex life, without consent.

They argued that there could not have been consent in such a context, and that there was obviously no free, unequivocal, specific and informed manifestation of will.

However, according to Article 31(1) of the Spanish Public Sector Act and to Article 25 of the Spanish Constitution, and the interpretation of it made by the Spanish Constitutional Court, the non bis in idem principle forbids from sanctioning a behaviour that has already been sanctioned, both criminally or administratively, when the subject, the facts and the legal grounds are the same.

Therefore, the AEPD reasons that they cannot sanction the perpetrators for these facts, given that there is, between both criminal and administrative proceedings:

1. identity of subject: the perpetrators are the same natural persons
2. identity of facts: i.e. the facts (recording videos and photographing the victim during the commission of a crime of a sexual nature, without her express or tacit consent) are identical, and
3. identity of legal grounds: since both rules protect the same legal right, as the legal assets affected (personal data belonging to the most intimate redoubt of the victim's privacy: her sex life) are the same.

The AEPD hence concluded that, on the basis of the non bis in idem principle, they could not sanction the perpetrators of the offence, as they had already been sanctioned in a criminal proceeding for an criminal offence against privacy.

The AEPD therefore decided to close and archive this proceeding.",COMPLIANT,"Article 6, Article 7, Article 9","[23,42,8,30,0]"
Personal messages were sent by a telephone agent of a TELECOM company to a customer whose telephone number he had access to because he had previously called her to offer her the company's services,The DPA held that the entity who was the object of the complaint was not responsible because it had transferred the agent's number to another entity before the events took place,COMPLIANT,"Article 5, Article 58, Article 83","[16,35,37,7,33]"
The electoral roll list was sent to political parties. The lists were updated up until a deadline. Persons who had objected to being on the lists within the deadline were removed from the list. The AEPD noted that the right to object to processing following Article 21 is not absolute. The data may still be processed if the controller can demonstrate a compelling legitimate ground to continue the processing. The AEPD noted that the deadline set out by national law (LOREG) was one such legitimate ground.,"The AEPD found that as the claimant did not register his objection within the deadline, the PSOE was not in breach of the GDPR or national legislation by sending political advertisement to his address.",COMPLIANT,Article 21,"[46,43,36,32,15]"
"A Spanish citizen objects to the sending of political propaganda. The request, addressed to the Instituto Nacional de Estadística, is ignored and data subject's contact details shared with a political party. The party, which could not be aware of the violation of the Institute, uses the information. According to the AEPD the party is not liable.","In the present case, the party sent political material at the address of a data subject who had already objected to such processing. According to the AAPD, however, the conduct of the party was not negligent as it was impossible for the controller to know how the list was formed. Therefore, the authority archived the proceeding.",COMPLIANT,Article 5,"[14,32,26,24,42]"
"The complaint followed a discovery by Agents of the Local Police of the City Council of Sant Miquel d' Olèrdola of documents containing personal data on the public highway.

The complainant argued that the company SHANA REVOLUTION SHOPS was responsible to maintain security of these documents or otherwise to delete them. They alleged violation of Article 5(1)(f) GDPR and asked for a EUR 15,000 fine to be imposed.","The AEPD found that it could not be proved which entity collected these documents and which was responsible for deleting the personal data. The AEPD highlighted that a basic principle of the GDPR is that personal data should be processed in a secure manner with technical and organisational means and measures laid down in advance, depending on the data processed and the risks involved. This includes taking measures and protocols to ensure that information in tangible formats, when discarded, is discarded by means that ensure the confidentiality of the data. However, it noted that the fact that an entity throws or deposits documents containing personal data on the public highway does not make it responsible for them in terms of security under the GDPR. Thus, it dismissed the allegations against both defendants since there was no concrete evidence against them.",COMPLIANT,"Article 2, Article 5, Article 58","[9,12,17,33,44]"
"A data subject made an access request to an educational institution, asking for course programs, statistical data of the grades and number of students, information about how disproportionate results were corrected, a copy of their son past and future exams, as well as any works done by him, and a copy of the measures that have been implemented to help low-grades students overcome their difficulties.

When not complied with the petitioned, the data subject lodged a complaint with the Spanish DPA (AEPD) that was dismissed, that gave rise to an administrative appeal.

The school argued that most of the request data were not personal data and were therefore not included in Article 15 GDPR. They claimed that such data (educational data) were regulated by different norms. They also remarked that the responsible for the students had met the data subject and shown them the exams and gave the appropriate explanations, according to the norms regulating the matter.

The claimant brought forward the CJEU Nowak ruling, asking for a copy of the exams and other examinations, as well as psycho-pedagogic reports and psychometric tests, including teacher's reports.","The AEPD noted that the right to access from the GDPR was different from the right to access to the educational record, that is regulated by a different norm, and that is also different from rights such as public transparency.

The authority recognized, anyway, that according to the CJEU case law, exams and examinations are considered personal data, and therefore the data subject has the right to access them and obtain a copy.

However, the AEPD held that the access request had not been made following the appropriate channel, as it has been made through an access to the educational record, and not as a GDPR access request. The AEPD therefore compelled the data subject to first make an access request through the educational institution's DPO, and to lodge a complaint if, once made, it was not properly answered.

The AEPD also remarked that, when lodging such complaint, it should be accompanied by a copy of the access request and by the documentation providing justification about the legitimacy to represent the actual data subject (the son of the complainant).",COMPLIANT,"Article 12, Article 13, Article 15","[39,20,5,33,6]"
"On 11/09/2019, Mr(s). A.A.A exercised a right to erasure (to be forgotten) in relation to an URL against GOOGLE SPAIN, S.L.  The complainant, whose personal data appear in a news article from 2012, considered that the information in the search results was old, obsolete and inaccurate, and that it had no impact on the present and no relevance that could contribute to public debate.

On 20/01/2020, the Director of the AEPD agreed to admit the claim presented by the claimant against GOOGLE SPAIN, S.L, and agreed to transfer the claim to the latter, giving a fifteen working days deadline to present allegations. GOOGLE stated in their allegations that the complainant exercised her right of erasure, but her claims were refused on lawful grounds.

The application was then re-examined and it was found that the personal data of the complainant was no longer published on the disputed website. The publisher/webmaster of the disputed website had anonymised the personal data of the complainant by replacing her name with initials. As a consequence, the disputed URL did not even appear among Google search results anymore when searching for her name.

After examining the arguments presented by the defendant, they were transferred to the claimant so that she could formulate arguments that could be considered appropriate. In the allegations of the complainant, she claimed that the fact that the URL that was subject of the complaint no longer appeared among the search results based on her name was due to negotiations with the original webmaster, not by any action from GOOGLE.

Furthermore, she claimed that GOOGLE SPAIN had repeatedly refused to remove the link on the basis of the right to information, a right that that the original website did not felt affected at any moment, removing the content without any objection. On the basis of the above, the complainant considers that GOOGLE’s conduct could constitute an infringement.","The AEPD held that the purpose of this kind of proceedings is to ensure that the rights of the affected parties are duly restored. In the present case, regardless of whether GOOGLE refused to remove the URL, and given that the claimant’s name is not linked to the claimed URL on GOOGLE’s search results anymore, the claims of the complainant had been satisfied, and therefore the complaint should be dismissed for a lack of subject matter.",COMPLIANT,Article 17,"[37,15,10,14,4]"
"The complainant, a former patient at several hopsitals in Madrid, requested the deletion of certain medical practicioner's notes from her medical history. One of the hospitals to which she made this request responded that they could not comply with the complainant's requst in full because certain information would be necessary for any future physician ""to have a true and updated knowledge of your health status, and to provide you with adequate health care"".","The AEPD decided that Article 17 GDPR did not give the complainant the right to have all her medical data held by the hospital(s) erased, due to the remaining data being necessary for reasons of public interest in the area of public health.",COMPLIANT,"Article 9, Article 17","[40,42,45,44,30]"
"The decision is the consequence of an investigation procedure started by the AEPD against the defendant due to a complaint submitted by a Spanish citizen stating that he/she had requested his/her right to be forgotten in relation to nine (9) URLs, but this right was not approved by the defendant.","After obtaining the corresponding evidences, the AEPD understood that, as long as the not-erased-URLs are related to professional and not personal information of the claimant (and that CJEU judgement 13/05/14 clarified that the right to be forgotten can be declined due to the role of the claimant in the public life), they are excluded from the data protection regulation as per Articles 1 and 2 of the GPDR. In this sense, the AEPD decided to dismiss the claim from the Spanish citizen.",COMPLIANT,Article 17,"[49,4,33,36,25]"
"On 15 February 2019, Mrs A.A.A.  (hereinafter, the complainant) exercised her right to erasure against CGT Sector Federal de Telemarketing (hereinafter, the respondent), but had not received a response to her request. In particular, the request included  that complainant's personal data (such as name, surname and telephone number) should not appear in a bulletin posted on the CGT Telemarketing website when a search is made. The complainant provided a list of the URLs concerned.

In response to the request ""to be forgotten"", the respondent instructed the complainant to address Google in order to remove the links or the text.","Results of the investigations conducted by the AEPD revealed that when a search is made by the name of the complainant the result is ""No results found"" for each of the urls in question.

The AEPD decided to dismiss the complaint, regardless of the fact that the search engine refused to cancel the URLs, but given that the claimant's name is not linked to the search results in the URLs claimed and that the controller stated that the complainant's data has been deleted, the claims of the complainant have been satisfied, therefore the claim is dismissed as non-existing.",COMPLIANT,Article 17,"[33,23,40,13,36]"
"The appellant complained that the company, in response to his access request, provided an incomplete dataset in English.","The DPA found that much of the data that the complainant found as missing is data that the complainant is expected to possess. So, it concluded that the company is not obliged to provide data that the data subject already possesses under Articles 13(4) and 14(5)(a) GDPR. Thus, the DPA found that the company has adequately fulfilled the obligation to inform the data subject of the data processing as required by Articles 13-15 GDPR. Finally, the DPA pointed out that the complainant had indicated in its customer profile a language preference to use English, which justifies the data export in English (Article 12(1) GDPR).",COMPLIANT,"Article 12, Article 13, Article 14, Article 15","[10,35,3,6,0]"
"The bank – the controller- notified its client that his account had been closed. The bank did not provide any reasons for the termination of the contract. The client –the data subject- asked for clarification and submitted a subject access request to the controller. The controller provided only for a “limited extract of personal data in English”. The representative of the data subject considered that the controller failed to comply with its obligations under GDPR and submitted a complaint before the DPA. The data subject’s representative claimed that the controller did not provide for an exhaustive copy of their personal data. The controller claimed that it should not be subject to the obligations set out in Articles 15 and 17 to 21 GDPR due to domestic legal obligations. Indeed, it claimed it would be contrary to the Money Laundering and Terrorist Financial Prevention Act to disclose complaint’s personal data to their representative.","The AKI found that the data subject’s rights should not adversely affect the rights and freedom of the others, pursuant to Article 15(4) GDPR. Also, it found that the national law - Money Laundering and Terrorist Financial Prevention Act - could restrict the data subject’s rights.  As a consequence, the controller’s answer was lawful and proportionate.",COMPLIANT,Article 15,"[31,45,39,4,27]"
"The Complainant in this case was a patient in a Belgian hospital. He noticed that the hospital was using unsecured contact forms on its website. In particular, these forms were sent to the hospital in an unencrypted manner and via an unsecured connection. As a result, the personal data contained in these forms, including sensitive health data, were potentially exposed to the risk of being intercepted by third parties and being read in the network traffic.

The Complainant therefore filed a complaint with the Belgian DPA, considering that such processing was unlawful. On the basis of this complaint, the Inspection Service of the Belgian DPA conducted an investigation. During this investigation, the following (additional) breaches of data protection legislation were identified:

* the hospital implemented insufficient technical and organisational measures to guarantee the protection of (health) data (Article 32 GDPR);
* the DPO of the hospital was not directly reporting to the highest management level of within the organization (Article 38(3) GDPR).","Admissibility of the complaint

The Belgian Law on the Establishment of the Data Protection Authority states that anybody can file a complaint with the Belgian DPA, provided that all the prescribed conditions in Article 60 of this law are met. In a previous decision, the Belgian DPA had already decided that an additional condition must be fulfilled, namely that the complainant demonstrates that he has sufficient interest.

In a recent case, the Belgium Supreme Court ruled that anyone who believes that their rights under the GDPR have been violated can lodge a complaint with the supervisory authority, even if their personal data have not been processed, given that the refusal to provide personal data resulted in a disadvantage for the data subject (e.g. not being able to use a certain service). According to the Litigation Chamber of the Belgian DPA, the difference in this case was that the Complainant could not prove to have suffered from any disadvantage by refusing to fill in the contact form on the hospital's website, since other alternatives existed to achieve the same objective, such has contacting the hospital via another mean or filling in paper forms.

Since the Complainant was pursuing a general public concern at the time the complaint was filed (i.e. the protection of the privacy rights of everyone who visits the defendant's website and possibly uses the contact forms on the website) without having a personal stake in the case, the DPA dismissed the complaint.

Other issues

Since the inspection report revealed a number of shortcomings, the Litigation Chamber still decided to stress in its decision that health data fall within special categories of personal data in the sense of Article 9 GDPR. Therefore, all possible technical and organizational measures should have been taken to protect health data, such as encrypted transmission. Furthermore, and opposite to the results of the investigation, the DPO should have been able to report directly to senior management and be given the opportunity to express a dissenting opinion concerning the processing (Article 38(3) GDPR)",COMPLIANT,"Article 9, Article 24, Article 32, Article 38, Article 57","[6,31,40,43,29]"
"Complainants X1 and X2 filed a complaint against a controller (the Defendant) regarding the disclosure to third parties of personal data concerning tenants of social housing in the context of an asset investigation. According to the Complainants, the Defendant did not have any valid legal basis to disclose such data (i.e. breach of Article 6 GDPR), and had failed to properly inform the Complainants about the processing activity (i.e. breach of Article 13 GDPR).

After these complaints were declared admissible, the Belgian DPA conducted an investigation at the premises of the Defendant. During the investigation, five additional breaches against data protection principles were discovered.

The Defendant stated that the processing it carried out formed part of the legal framework for social housing and that the legal basis for the processing, namely the consent of the Complainants, was expressly included in the Flemish regulations governing the social housing system.","Dismissal of the complaints

The processing operations in casu all took place before the GDPR became applicable, except for the period that was granted to the Complainants to leave the house. This period expired on 31 October 2021.

In previous decisions, the Belgian DPA had already stated that it can only be competent for data processing operations which, although having started before 25 May 2018, still continued after that date, but not for one-off or multiple processing operations which exclusively took place before 25 May 2018.

On the basis of these considerations, the Belgian DPA considers itself incompetent ratione temporis to review the merits of the complaints, given that the contested processing operations had been carried out before the GDPR had become applicable. Therefore, the Belgian DPA decided to dismiss the complaints in accordance with the terms of the its dismissal policy.

'Legal obligation' or 'fulfillment of a task in the public interest' as a legal basis

Despite the complaints being dismissed, the Belgian DPA provided guidance on the legal basis of the processing operations. The Belgian DPA stated in particular that if processing operations are carried out because the controller is legally obliged to do so, or because they are necessary for the performance of a task carried out in the public interest, the processing must be based on Union or Member State law. Article 6(3) GDPR specifies that the purpose of the processing must be found in that legal basis. In other words, a legislative standard must normally be sufficiently clear and precise so that the essential characteristics (including the precise purposes) of a processing operation are known when the above legal bases are relied on. The Belgian DPA noted however that, in practice, processing is often carried out on the basis of a general regulatory power, rather than on the basis of detailed provisions specifically allowing for such processing. Therefore, the Belgian DPA considered that when using general legal grounds, a balancing test is necessary between the necessity of the processing and the interests of the data subjects.",COMPLIANT,"Article 6, Article 13","[21,35,40,43,13]"
"Three data subjects registered as volunteers for the distribution of filtering facepieces with their email addresses. They claimed that the controller, the municipality that organised the campaign, had used their email addresses for other purposes. They did not, however specify those alleged purposes.

According to the controller, the volunteers' data were only used for one purpose, namely the organisation of the distribution of the filtering facepieces. In this process, the recipients of the email were placed in ""BCC"" and the e-mail addresses were deleted after the invitation was sent.","The DPA found no violation by the controller. There was no indication that the controller had used the emails for other purposes than the campaign. In particular, it had used the BCC function when sending out emails to the mailing list so that the recipients could not see each others contact data.

According to the DPA, the controller was justified by Article 6(1)(e) GDPR which allows processing of personal data for the purposes of public interest, especially since the data had been provided by the data subjects themselves. Furthermore, the controller had complied with the principles of data minimisation (Article 5(1)(c) GDPR) and of storage limitation (Article 5(1)(e) GDPR).",COMPLIANT,"Article 5, Article 6","[22,19,7,17,44]"
"The complainant is an accountant in Luxembourg. On 18 July 2019 and 9 August 2019, the complainant issued a request for information, access, rectification, and restriction of the processing of their personal data to the Belgian Special Tax Inspectorate (""Directie Algemene Administratie van de Bijzondere Belastinginspectie""), following the mention of their name in various files concerning investigations into tax payers. According to the complainant, the Tax Inspectorate had wrongly referred to them as a 'straw man' (""stroman"") for a company alleged to have committed tax evasion.

When the Tax Inspectorate rejected the complainant's requests in a letter dated 28 October 2019, the complainant filed a complaint with the Belgian DPA.

Among other things, in its submissions, the Tax Inspectorate argued that the words 'straw man' and 'suspected straw man' do not constitute personal data as defined by the GDPR, since they concern an opinion or viewpoint of the Tax Inspectorate regarding the relation of the complainant to the relevant company. The complainant is therefore not entitled to request rectification of this data, or restriction of its processing.

Further, the Tax Inspectorate argued that, in accordance with Article 322 §1 of the Income Tax Law 1992 ('wetboek van de inkombelastingen', or 'WIB92') it is entitled to take a position on relevant tax issues to ensure the correct collection of tax. Specifically, this means that it is entitled to state that the complainant is suspected of acting as a 'straw man'. It argued a different reading of Article 322 §1 WIB92 would be contrary to Article 322 §1 WIB92 itself, as well as to a civil servant's freedom of expression within the meaning of Article 10 ECHR.

The Tax Inspectorate also argued that it had indeed satisfied the complainant's right to information under Article 14. This is because Law of 3 August 2012 containing provisions on the processing of personal data by the Tax Inspectorate in connection with its tasks, specifies a derogation which provides that the right of information may be restricted in order to safeguard the public interest objectives of monetary, budgetary, and fiscal matters. Specifically, it refers to the processing of personal data that has at its purpose the aim of preparing, organising, and monitoring activities which may result in an administrative fine or penalty. The restriction applies during the period of which the relevant individual is subject to investigation.","Firstly, the Litigation Chamber of the Belgian DPA held that the Tax Inspectorate had not executed the complainant's request for information, access, rectification, and restriction of processing, within good time - that is, within one month of the request - thereby infringing Article 12(3) of the GDPR, as well as 11 §3, 11/1 §3, 11/2 §3 and 11/3 §3 of the Act of 3 August 2012.

With regard to the complainant's right to rectification, the Litigation Chamber emphasised that, contrary to the Tax Inspectorate's assertion, the description of the complainant as a 'straw man' qualifies as personal data, which, in line with Article 4(1) and Recital 26 GDPR, as well as Opinion 4/2007 of the WP29 and the case law of the CJEU, must be interpreted broadly to include elements characterising the physical, physiological, genetic, mental, economic, cultural, or social identity of the individual. Importantly, personal data includes subjective information, such as the term 'straw man' irrespective of whether or not this information is correct. The litigation Chamber highlighted that in its opinion 04/2017, the WP29 pointed out that data protection rules take into account the possibility that such subjective information is inaccurate, and give the data subject the right of rectification, which is possible. In this regard, the Litigation Chamber noted that since it is not in a position to check the accuracy of the contested information ('straw man'), and cannot take the place of the Tax Inspectorate in this, it recommends the Tax Inspectorate rectify the personal data by allowing the complainant to add a statement to the file to the contrary.

The Litigation Chamber further held that the Tax Inspectorate cannot rely on the derogations provided for in the Act of 3 August 2012 and is therefore obliged to facilitate the complainant's data subject rights.

This is because these derogations must satisfy certain conditions, based on Article 52 of the Charter of Fundamental Rights of the EU, read in line with Article 8 of the same law, as well as CJEU case law. The Litigation Chamber notes that these conditions are not satisfied, in particular because the derogations are very broadly formulated, and go beyond what is provided for in Article 23 GDPR on restrictions to the GDPR. That Act not only allows the rights of data subjects to be restricted, but also makes it possible to exclude them altogether and deprive the data subject of any right. By incorrectly relying on these derogations, and failing to inform the complainant of the lack of applicability of the derogations, the Tax Inspectorate violated Article 12(2) GDPR, in conjunction with Articles 14, 15, 16, and 18 GDPR.

The Litigation Chamber ordered the Tax Inspectorate to comply with the complainant's requests to exercise their rights, in particular their right to information and access under  Articles 14 and 15 GDPR and Articles 11 and 11/1 of the Act of 3 August 2012.

In line with Articles 16 and 19 GDPR, the Litigation Chamber also ordered the Tax Inspectorate to inform any recipient to whom the personal data concern  were disclosed of this rectification. It emphasised the Tax Inspectorates obligation under Article 5(1)(d) GDPR to ensure personal data processed are accurate and up to date, and take steps to ensure all inaccurate data are rectified without delay.

It also issued a reprimand in accordance with Article 58(2)(b) GDPR and     Article Article 100, §1, 5° WOG in addition to these corrective measures. It takes into account that the Tax Inspectorate is a public authority which has an exemplary function in terms of compliance with legislation on the protection of personal data, and which, as a tax authority, also processes a large amount of personal data. In accordance with the principle of 'lead by example' it must therefore ensure that it acts in conformity with the GDPR at all times and in particular with the provisions regarding the rights of data subjects.",COMPLIANT,"Article 4, Article 14, Article 15, Article 16, Article 18","[5,29,19,42,40]"
"On 25 of February 2019 the complainant has submitted a complaint against Organization 2. The essence of the  complaint was: screenshot of his Facebook profile picture was shared by Organization 2 without his consent. The complainant asserted that his profile picture was not publicly available. On 8 July 2019 DPA declared the complaint admissible. On 23 July 2019 the Disputes Chamber decided that the file was ready to be considered on the merits.  On 4 September 2019 the Disputes Chamber received the response of both organizations involved in this processing (defendants). On 8 October 2019 the Disputes Chamber received the conclusion response of the complainant, limiting the subject of the complaint to the sharing of the picture via email. On 30 October 2019 Disputes Chamber accepted another comment from the defendants, stating that the complainant violated article 124 of the electronic communications law by deliberately accessing the email that was not addressed to him.  On 27 May 2020 the parties were heard by the Disputes Chamber.","DPA held that: 1) Organization 2 was acting as a processor on behalf of Organization 1 when it shared complainant's pictures via email with third parties; 2) Personal data processing via automated means took place. The argument of the defendants that the complainant failed to demonstrate that his picture was structured according to the specific criteria was not relevant because the filing system criterion applies to manual processing only; 3) The fact that profile picture was publicly available doesn't mean that it can be used without legal basis; and 4) Legitimate interest was a valid legal basis in this case:

Purpose test satisfied, purpose: enforcing the judgement of the Sports Court;
   Necessity test satisfied: picture of the complainant was necessary to identify him. In addition, the controller edited the picture of the complainant is such a way, that another person on that photo was no longer visible, complying with the principle of data minimization;
   Balancing test satisfied: DPA took into account the reasonable expectations of the complainant and found that because the complainant made his picture publicly available, it was within his reasonable expectations that third parties might access that picture and use it. Moreover, according to the Sports Court judgement, organization 1 (controller) was required to communicate the prohibition to all organizers of completions in Belgium. Although the judgement did not specifically instruct organization 1 to share pictures of the complaint, DPA considered this necessary for the purpose of identifying the complainant.",COMPLIANT,"Article 2, Article 4, Article 6","[2,25,31,38,7]"
"The controller in this case is an online newspaper which published an article regarding the spending of public funds within a European Union funded programme. In this article, the newspaper published a data subject’s name, last name, and the fee data subject earned for their work as part of the programme. The data subject claimed the newspaper did not have a legal basis to share their personal data, and filed a complaint with the Croatian DPA.","The Croatian DPA rejected the complaint. It considered that, in principle, the newspaper has a legal basis that follows from Article 3(1) and 3(2) of the Croatian Media Act (Official Gazette 59/04, 84/15, 81/13) which protects freedom of expression of the media. According to this law, the newspaper has the right to inform the public about matters of public interest. In this case, the DPA found that information on the how public authorities spend public funds must be considered in the public interest. Moreover, the DPA held that the processing of personal data was not excessive, and limited to what was necessary. Hence, the DPA concluded that the newspaper had a legal basis under Article 6(1) GDPR to publish the data subject’s personal data, and did not violate Article 5(1)(a) GDPR.",COMPLIANT,"Article 5, Article 6","[12,26,46,19,45]"
"In 2018, the Luxembourg DPA (the CNPD) initiated 25 different audit proceedings both in the private and public sector with regard to the role of the Data Protection Officer (DPO) under Section 4 of Chapter 4 of the GDPR (see in particular Article 37 GDPR to Article 39 GDPR).

One of these audit proceedings concerned a not-for-profit association (Association Sans But Lucratif) established under Luxembourg law (hereafter, the ASBL). The ASBL is part of a confederation specialised in the provision of social services. In that context, the ASBL has established different partnerships with various entities providing social services in Luxembourg (the Patner Entities). The core activities of the ASBL is therefore not to provide social services, but rather to manage the funding of the Partner Entities, validate common strategies for the confederation, and determine which Partner Entities are responsible for their implementation.

During the audit, it was found by the head of investigation of the CNPD that the ASBL had appointed a DPO pursuant to Article 37(1) GDPR. No violation of the obligations relating to the role and position of the DPO was found. In the course of the proceedings, the CNPD questioned however the necessity for the ASBL to appoint a DPO in the first place. The CNPD therefore invited the head of investigation to get complementary information on that point. The head of investigation further communicated with the ASBL, and concluded that the latter was under the obligation to appoint a DPO.","Based on the received complementary information, the CNPD decided not to concur with the conclusion of the head of investigation. Taking into account the managerial role of the ASBL within the confederation, and in particular the fact that the ASBL itself was not processing health data for the provision of social services, the CNPD found that the ASBL had wrongfully concluded that it was under an obligation to appoint a DPO pursuant Article 37(1) GDPR. The CNPD further pointed out that the investigation should have covered the processing activities of the Partner Entities of the confederation.

Given the absence of any violation on the part of the ASBL, the CNPD decided to close the case.",COMPLIANT,Article 37,"[29,48,6,27,11]"
"In 2018, the Luxembourg DPA (the CNPD) initiated 25 different audit proceedings both in the private and public sector with regard to the role of the Data Protection Officer (DPO) under Section 4 of Chapter 4 of the GDPR (see in particular Article 37 GDPR to Article 39 GDPR).

One of these audit proceedings concerned a Luxembourg private company (hereafter, the Company). During the audit, it was found by the head of investigation of the CNPD that the Company had failed to appoint a Data Protection Officer (DPO), in line with Article 37(1) GDPR.

Article 37(1) GDPR envisages two situations where private controllers (such as private companies) must appoint a DPO. In particular, a private controller must appoint a DPO when:

* its (i) core activities consist of processing operations which require (ii) regular and systematic monitoring of data subjects (iii) on a large scale; or
* its (i) core activities consist of processing (ii) on a large scale of (iii) sensitive data pursuant to Article 9 GDPR or Article 10 GDPR.

In the case a hand, it was not contested that the Company was not processing sensitive data on a large scale. However, the audit report drafted by the head of investigation had concluded that one of the core activities of the Company was the offering of a loyalty programme to its customers, which included the processing of personal data through loyalty cards, and that such processing had to be considered as a regular and systematic monitoring of its customers on a large scale.

The head of investigation of the CNPD therefore recommended to issue an injunction against that Company to appoint a DPO, and to impose a fine of €80.000 on the Company for failure to appoint a DPO in due time.","After reviewing the facts of the case and the applicable law, the CNPD decided against the recommendations of the head of investigation.

The CNPD first noted that the Company had completed a documented analysis on the need to appoint a DPO pursuant to Article 37(1) GDPR, and had concluded that it was not bound to do so.

The CNPD then agreed with the conclusion of the audit report that the offering, by the Company, of a loyalty programme to its customers was part of the core activities of the Company. The CNPD also agreed with the conclusion of the audit report that such activities were conducted on a large scale, taking into account, in particular, the number of customers concerned, and the geographical scope of the processing.

As for the third condition however, the CNPD found that the offering by the Company of a loyalty programme to its customers did not constitute a ""regular and systematic monitoring of data subjects"". The CNPD noted in this respect that the Company was processing the personal data attached to loyalty cards in order to manage its customers' account and offer them rewards, but not for monitoring their purchasing behaviors. In other words, the CNPD considered that the purpose of the processing was the management of the loyalty programme, and not the regular and systematic monitoring of the customers' behaviors.

Based on these considerations, the CNPD concluded that the conditions of Article 37(1)(b) GDPR were not fulfilled, and that the Company did not have the obligation to appoint a DPO. As a consequence, the CNPD decided to close the investigation, and not to issue any injunction or impose any fine on the Company.",COMPLIANT,Article 37,"[29,28,26,19,25]"
"According to the Hospital's policy on its discharges procedure, the patient receives only an attestation form and a digital copy of MRI scans. The complainant was hospitalised for several days back in 2016. In September 2019, she asked for her full medical report for which the hospital has asked her to pay administrative fees.

Furthermore, some days after the discharge from the hospital, her employer fired her. She thought that the firing was on the grounds of the health incident, and the only possible source to her employer was the very same Hospital's employee.","With regard to the leak of the complainant's health information, the Cypriot Office of the Commissioner for Personal Data Protection has not been convinced of the substance of relevant complaints. It appears that a complainant for any allegation shall provide some evidence compatible with a minimum burden and standard of proof. Nevertheless, Cypriot DPA has not specified yet the minimum level of the required proof.

Regarding the primary concern, Cypriot DPA started her reasoning with the fact that state health require command a health facility to prepare a medical report only upon request from the patient and only if (s)he pays the regulated fee. Hence, before the patient's request, the desired information and data did not exist at all. That means the right of access, as the GDPR describes, it entirely incompatible under such circumstances.

The secondary allegation from the Complainant was her belief that the medical report has been lost due to negligence of the Hospital's employees. The Cypriot Commissioner for Personal Data Protection was satisfied with the security measures that the health facility has adopted, while had considered not only these measures of that sort was mentioned as part of the defence’s reply. On the contrary, the Cypriot Commissioner for PDP also considered all measures, which already have been the brought to Commissioner's notice by previous DPA's initiative enquiries and activities.",COMPLIANT,"Article 15, Article 32","[3,4,21,29,48]"
"The controller is the Personal Injuries Assessment Board (PIAB), an independent statutory body that deals with personal injury claims.

The personal data breach occurred when a third party organisation contracted by the PIAB returned materials containing personal data to the PIAB on an unencrypted USB key in a paper envelope. That USB key was ultimately lost in the post with only a ripped envelope delivered to the PIAB. The inquiry considered whether the PIAB had complied with its obligation to implement an appropriate level of security under Article 32 GDPR.","The inquiry established that the PIAB had requested in advance that the third party not send personal data to the PIAB. In those circumstances, the DPC found that the PIAB could not possibly have foreseen that without consultation, the third party would post an unencrypted USB storage device in an unpadded envelope by ordinary (not registered) post.",COMPLIANT,Article 32,"[24,22,46,7,6]"
"The controller runs the ski lift service in a ski resort (name is not known). When a day ticket or multi-day ticker holder passes through the access controls the first time, the controller takes a first photo of the user. After that, each time the user passes an access point, another photo is taken and compared with the first one by an authorised employee to check whether the ticket holder transferred their ticket to a third person, which is prohibited according to the terms and conditions of the service. The first photo is deleted after the ticket is expired while the other(s) after 30 minutes the user has passed a certain control point. The data subject used the controller's service from 27 to 29 December 2019. On 7 January 2020, he lodged a complaint with the Austrian DPA (Datenschutzbehörde - DSB) alleging that the controller's conduct was unlawful since no consent had ever been provided by the user. The controller counterargued that it did not rely on consent but rather on its legitimate interest to check whether a customer violates the terms and conditions by transferring the ticket to a third person.","The DSB rejected the complaint because the controller's conduct was justified under Article 6(1)(f) GDPR. It reasoned that the controller's interest to check whether the data subject violated the terms and conditions was legitimate and that it was not overridden by the data subject's interest to data protection. By referring to sentence 3 of Recital 51 GDPR, the DSB found that the pictures taken from the data subject did not constitute biometric data according to Article 9(1) GDPR because they did not result from ""specific technical processing"", as required by Article 4(14) GDPR, but are rather used to manually check the identity of the customer. It then held that the measures taken by the controller are not unusual nowadays and, therefore, the data subject could have reasonably expected them (first sentence of Recital 47 GDPR).",COMPLIANT,"Article 6, Article 9","[13,22,38,3,45]"
"Mr X and Ms Y have a son and are divorced. Ms Y has sole custody of their son. Reliable care is required for the son due to special needs (e.g. hyperactivity, medication, etc.). The mother of the Mr X often takes care of him.

In a court order, a number of the data subject's health conditions had been identified. The order referred to the data subject only as the ""father of the child"" or “father”. Among other things, it lists Mr X's depressive currents and rapid mental exhaustion/overstrain, so that Mr X is dependent on a specially created daily structure with many breaks.

Ms Y forwarded this court order to the Mr X's mother via WhatsApp. In an accompanying message, the Ms Y referred to the data subject by his first name and questioned whether he still is an eligible to take care for the son.

Mr X filed a complaint with the Austrian DPA (Datenschutzbehörde, DSB) alleging a violation of the his right to data protection as well as to confidentiality.","The complaint was dismissed as unfounded. Neither the GDPR nor the Austrian Data Protection Act (DSG) applied due to the exception in Article 2(2)(c) GDPR.

Classification of the Data

The DSB first found that the data transferred was personal data. Furthermore, the information relates to the physical or mental health of the data subject and contains information about the health status of the data subject, i.e. data concerning health within the meaning of Article 4(15) GDPR.

GDPR Does Not Apply Due to Exception of Article 2(2)(c) GDPR

The DSB founds that the GDPR does not apply due to the household exception provided for in Article 2(2)(c) GDPR.

Pursuant to Article 2(2)(c) GDPR, the GDPR does not apply to the processing of personal data by natural persons in the course of purely personal or household activities. As a restriction of the fundamental right under Article 8 EU Charter, this provision was to be interpreted restrictively in accordance with Article 52(1) EU Charter. The criterion of delimitation is the absence of any reference to a professional or economic activity. This means that the central criterion for the applicability of the exception - and thus for the non-applicability of the GDPR - is the imputability of the data processing to the private sphere. It was noted that the terms ""personal"" and ""household"" refer to the activity of the person processing personal data and not to the person whose data are being processed.

The GDPR itself mentions in this respect, for example, the conduct of correspondence or social networking and online activities in the context of a personal or household activity (cf. recital 18 GDPR). However, this only applies to the extent that data is exchanged in closed groups that have no relation to the professional or economic activities of the users. The exclusively private use of services such as WhatsApp is covered by the scope of the exception, provided that it is not accompanied by an unrestricted publication of personal data on the internet.

Furthermore, the term ""household"" is not to be interpreted strictly in terms of family law [please note that the German version of the GDPR is using the terms “personal” and “family”], but also includes other relationships that are described as ""family"" by the public perception, irrespective of marriage and filiation. In this respect, it is irrelevant whether there is a formal bond or whether personal relationships exist on a purely informal basis.

In the specific case, the WhatsApp message in question was sent to an individually determined recipient (and not to an undetermined or unlimited public group of addressees) on the occasion of a personal and at least indirectly family-related correspondence between the controller and her former mother-in-law, who often looks after the son who is in the sole custody of the respondent.

Relationship Between the GDPR and the DSG: DSG Does Not Apply Either

The DSP then examined whether the DSG applied beyond the scope of the GDPR and, in this respect, whether there was a breach of the right to confidentiality under § 1(1) DSG.  However, the applicability was denied.

This followed from the legislative competence of the EU according to Article 16(2) TFEU for regulations on the protection of individuals with regard to the processing of personal data. It follows that if the facts of the case fall within the scope of Article 8 EU Charter, those provisions of the member state (§ 1 DSG) which offer the same guarantee must be disregarded. To the extent of this conformity, the national provisions remain ""dormant in force"" and the assessment is based exclusively on Union law.

In the DSB's view, § 1 DSG does not go beyond Article 8 EU Charter. In this respect, the DSG does not apply due to the exception of Article 2(2)(c) GDPR.

In Eventu: Processing Not Covered in any Case due to the Exception of Article 2(2)(c) GDPR

The DPA lastly found that even if recourse to § 1 DSG was possible, processing activities in the personal and household sphere are not covered because of § 4(1) DSG in conjunction with Article 2(2)(c) GDPR.  § 4(1) DSG provides that the GDPR applies in addition to the DSG. The DSB concludes that this also applies to the exemptions of the GDPR, so that processing operations excluded from the scope of the GDPR are also not covered by the GDPR due to Article 2(2)(c) GDPR.

In addition, the DSB stated that it is possible in principle to have a data protection right in a member state that covers cases that go beyond the GDPR. This is specifically justified with the corresponding old case law of the ECJ on household exceptions under the GDPR (Article 3(2) Directive 95/46/EC), which corresponds to Article 2(2)(c) GDPR. While the Austrian legislator had made use of this possibility with § 45 DSG 2000, a provision similar to § 45 DSG 2000 no longer exists since the introduction of the GDPR. This leads to the conclusion that the Austrian legislator did not want to extend the DSH to matters that exclusively concern the personal or family sphere.",COMPLIANT,"Article 2, Article 4","[46,1,23,12,13]"
"The data subject entered the retail store of the controller. Because she did not were a face mask, she was denied entry by an employee of the controller. She explained that she could not wear a face mask for health reasons. The employee asked her to show an appropriate doctor's certificate which the data subject did. The data subject lodged a complaint against the controller with the Austrian DPA (Datenschutzbehörde - DSB) asserting that the controller violated her right to privacy because already the fact that she cannot wear a face mask for health reasons is sensitive data. The controller objected to this assertion stating that, under § 19 of the forth Austrian Covid-19 Protection Ordinance (§ 19 4. COVID-19-SchuMaV), it had to check whether customers are wearing face masks and, if not, verify which health reason prevents them from doing so. The data subject replied to this argument that the ordinance violates the GDPR and is therefore not to be applied according to the principle of Primacy of EU Law.","The DPA rejected the complaint. It held that the data subjects' rights are sufficiently safeguarded because according to § 6(1) DSG (Austrian Data Protection Law) the employees of the controller are obliged to secrecy regarding data which they accessed exclusively in their professional occupation. Furthermore, the DPA found that the protection of public health overrides the interest of the data subject to not disclose (part of) her health record and that § 19 4. COVID-19-SchuMaV constitutes an exception under Article 9(1)(i) GDPR.",COMPLIANT,Article 9,"[28,19,22,29,2]"
"The controller is active in the field of address trading and direct marketing. It offers its customers the service to store (within a pre-determined period of time) incoming mails at one of its offices, which is close to the customer's residential or company address.  The data subject ordered this service on-site by filling in a form at a touch-pad terminal which asked for his name, address and date of birth. The form also contained a note that the data can be transferred to third parties for the purpose of direct marketing and that the customer can forbid this transfer by unticking the pre-ticked box below.  The text on the side of the pre-ticked box said ""I do not object to the transfer of data"".

Afterwards the data subject lodged a complaint with the Austrian DPA (DSB) arguing that the controller violated Articles 4(11), 6(1)(a) and 7 GDPR because the box was pre-ticked and, therefore, the consent to the processing was not given freely. The controller argued that it processes this data under Article 6(1)(f) GDPR and the purpose of the box is not to obtain consent from its customers but rather to give them the opportunity to object against the processing according to Article 21 GDPR. It further stated that it did not transfer any information of the data subject to a third party since the data subject objected against the transfer.","The DSB rejected the complaint because it did not find any violation of the GDPR by the controller. The DSB found that no transfer to third parties took place and that the controller did not violate Articles 4(11), 6(1)(a) and 7 GDPR, because the purpose of the pre-ticked box was to give the data subject the possibility to object against the transfer and not obtain its consent.",COMPLIANT,"Article 4, Article 6","[35,21,15,31,22]"
"The subject matter of the complaint is whether the respondent violated the first and second complainants' right to confidentiality (under §1(1) DSG) by obtaining their ""most personal"" data - which the Austrian DPA understood to mean their address data, specifically title, name, date of birth and address - from the customer and prospect file systems of other address and direct marketing companies.

The respondent argued that it had the commercial authority of an address publishing and direct marketing company, and therefore lawfully processed the complainant's personal data. They supported this claim by handing over declarations of the data providers to the Austrian DPA.","The Austrian DPA assessed the documents the respondent provided, and held that the processing of the complainant's address data was lawful because (i) the respondent had a valid trade licence ""for the exercise of the trade of address publishers and direct marketing companies"", (ii) only obtained the relevant data for advertising purposes, (iii) processed the data in line with the principle of proportionality per §151(3) Trade Regulation Act 1994.",COMPLIANT,"Article 4, Article 6, Article 51, Article 77, Article 82","[16,9,6,11,1]"
"The controller pursues, among other things, the purpose of scientific research on the history of fascism and National Socialism, the resistance to the latter movements and on political manifestations of right-wing extremism, including the purpose of documentation and archiving. The controller operates different types of archives. Relevant here is the so-called ""cut archive"", in which clippings from various media, in particular daily newspapers, are stored. These articles are stored and key-worded online. The respondent made media contributions by the complainant accessible on its website and labelled the complainant as ""extreme right-wing"". An employee of the controller had also made corresponding statements to the media.

The complainant requested the controller to delete the aforementioned articles. This was based on the claim that the controller cannot rely on a legal basis under the GDPR to process such special categories of personal data. Also, it was stated that the controller does not use such data for scientific purposes, as claimed, but for daily political purposes.

The respondent rejected the request. It stated that the processing served purposes pursuant to Article 89(1) GDPR and was exempted from the right to deletion by § 2d (6) of the Austrian Research Organization Act (FOG). Further, the controller referred to Article 9 (1) and (2) (e) GDPR. The political conviction of the complainant was not a secret and was based on verifiable statements made publicly by the complainant.

The complainant filed a complaint with the Austrian DPA (Datenschutzbehörde - DSB).","Exclusion of the Right to Erasure under National Law not Applicable

With § 2d(6)(3) FOG, there is a national provision that excludes the right to erasure insofar as this is likely to render impossible or seriously impair the achievement of purposes pursuant to Article 89(1) GDPR.

In principle, Article 89(3) GDPR contains an opening clause. This provision was also applied in the present case. The DSB decided that the maintenance of the ""cut archive"" falls under data processing for an archiving purpose in the public interest pursuant to Article 89(3) GDPR. The complainant's contrary assertion that the controller pursues ""day-to-day political purposes"" and is therefore not scientifically active did not apply. For this to be the case, it would have to be proven that the archive management pursued the sole purpose of serving political goals not further described by the complainant. However, there was not even a sufficiently substantiated factual allegation for the inclusion of such evidence. The fact that the controller takes a basic political stance and repeatedly expresses this publicly, does not harm the scientific purpose of the respondent's activity.

However, § 2d(6)(3) FOG was not applied in the present case due to the primacy of national law. Article 89(3) GDPR does not provide for an opening clause for the exclusion of the right of erasure, as there is no reference to Article 17 GDPR.

Article 17(1)(d) GDPR

The DSB decided that there is no ground for erasure under Article 17(1)(d) GDPR.

According to the DSB there is a legal basis for processing. Union law, together with complementary national law, also covers the processing of special categories of data for archiving purposes in the public interest, including ""political background information"" on individuals who are the subject of archived documents. In any case, a categorization is covered which, as is the case here, makes it possible to find media reports attributing a "" nationalist "" or "" German nationalist "" attitude to the complainant.

Specifically, the DSB cites Articles 5(1)(b) and (e), 9(2)(j), 89(1) GDPR and Section 7(1)(1) and (2)(1) GDPR. In particular, it follows from Article 9(2)(j) GDPR that the processing of data relating to the political conviction of a data subject may be carried out for archiving purposes. Ultimately, the DSB relies on §2f(1)(6)(a) FOG, which provides accordingly.

Article 17(1)(c) GDPR

For a right of erasure pursuant to Article 17(1)(c) GDPR, the first requirement, namely a justified right of objection, was already missing.

The DPA noted that Article 17(1)(c) GDPR, by its logical and systematic context, also applies to the right to object under Article 21(6) GDPR. Pursuant to Article 21(6) GDPR, where personal data are processed for scientific or historical purposes or statistical purposes, the data subject, on grounds relating to his or her particular situation, shall have the right to object to processing of personal data concerning him or her, unless the processing is necessary for the performance of a task carried out in the public interest.

The complainant had not succeeded in justifying this right to object. The accusation of day-to-day political influence did not suffice. This is because processing with the addition of ""political background information"" is - as has been seen - expressly permitted. According to the DSB, the complainant would rather have been free to take legal action against the statement itself by way of civil or media law.",COMPLIANT,"Article 5, Article 9, Article 17, Article 21, Article 89","[25,26,14,45,46]"
"The complainant (hereinafter the ""company"") is a limited company under Austrian law conducting business as pharmacy wholesale. It was subject to an audit of the Bundesamt für Sicherheit im Gesundheitswesen (hereinafter ""BASG""), the Austrian Federal Office for Safety in Health Care. In the course of this audit, the BASG processed personal data of the company.

The company lodged a complaint with the DSB, claiming that the BASG had violated the company's right to confidentiality of personal data pursuant to §1(1) DSG by unlawfully collecting, processing, disclosing and failing to delete the company's personal data ex officio.

The BASG contested the company's entitlement to lodge a complaint with the DSB, as the company was not a natural person.

Further, the BASG contested to have violated any data protection rights, mainly because under Austrian Law the BASG was under a legal obligation to process the data in connection with the audit.","The DSB held that at a legal person has the constitutional right to data protection under § 1 DSG (Austrian Data Protection Act) and is entitled to lodge a complaint before the DSB if these rights are violated. The DSB further held that the procedural provisions of the DSG - which deal with the procedure before the DSB - also apply regarding data protection complaints lodged by legal persons.

The DSB reasoned as follows:

* §1 DSG has a wider scope of applicability than Article 8 GRC (the latter only protects natural persons).
* As Article 16(2) TFEU leaves it to member states to grant data protection rights to legal persons as well as long as this does  compromise the level of protection of the GRC, nor the primacy, unity and effectiveness of Union law.
* The provisions of the DSG - which deal with the procedure before the DSB - must also apply on legal persons because the Austrian legislator cannot be accused of treating legal persons grossly disadvantageously differently from natural persons in the pursuit of their constitutionally guaranteed rights without comprehensible reason.

In conclusion, the DSB held that the company was entitled to lodge a complaint, but rejected the complaint on the merits of the case as there was no violation of data protection rights granted by § 1 DSG.",COMPLIANT,"Article 4, Article 9","[14,17,40,43,4]"
"In June 2019, the complainant requested erasure of her personal data from the respondent's website, claiming that an article on that website contained wrong statements about her. After the respondent’s refusal to do so, the complainant lodged a complaint with the DSB.

The respondent argued that publishing the article on its website qualified as processing carried out for journalistic purposes under Article 85 GDPR and § 9(1) of the Austrian Data Protection Act (Datenschutzgesetz - DSG). Due to the derogations in § 9(1) DSG, the DSB would hence not be competent to handle the complaint.","The DSB held, that the respondent qualifies as a media company under § 1(1)(6) of the Austrian Media Act, because it is a company which creates the content of the medium and handles the production, distribution, broadcasting and retrievability of the medium. It further held, that the data processing (publishing the complainant's personal data in an online article) was carried out for journalistic purposes. As the complainant is an former politician and the article revolved around legal procedures that she is involved in there was a public interest in mentioning the complainant's name.

Under Article 9(1) DSG, Chapter III and Chapter VI of the GDPR do not apply on data processing carried out by media companies for  journalistic purposes. Such GDPR violations must be tried before civil courts. Hence, the DSB considered itself not competent, rejected the complaint and did not investigate the alleged violation of Article 17 GDPR.",COMPLIANT,"Article 17, Article 85","[14,15,17,37,47]"
"The respondent operates a primary care centre. Among other things, PCR tests for SARS CoV-2 are carried out under its responsibility.

The complainant had a voluntary PCR test (SARS-CoV-2) carried out at the respondent's primary care centre.  By text message of 28 September 2020, he had been informed that the result of his PCR test was available and that the result was negative. The following day, he received an SMS with the following text: ""Your test result of the sample collection of 28 September 2020 has been received. COVID-19 test for Walter, born 19** is NEGATIVE. Your district administrative authority"".

The respondent argued that it was allowed to pass on the data on the basis of the Ordinance of the Federal Minister of Health concerning electronic laboratory reports in the register of notifiable diseases, Federal Law Gazette II No. 184/2013 as amended by Federal Law Gazette II 323/2020. However, this was contested.","The DPA held “that the wording of Art. 4(15) GDPR does not link a certain (minimum) impairment of physical or mental health, which argues in favour of a broad interpretation of the term ""health data"".

This is even clearer in Recital 35 of the Regulation, which states that personal data concerning health should include any data revealing information about the past, present and future physical or mental health status of the data subject.

These considerations are also covered by the case law of the ECJ, according to which the term ""date of health"" is to be interpreted broadly (cf. on the comparable legal situation under Directive 95/46 the judgement of the ECJ of 6 November 2003, C 101/01, Rs Lindqvist, para 50 f).

As an interim result, it must therefore be noted that (also) the negative test of the complainant is to be qualified as a health data pursuant to Art. 4 Z 15 GDPR and the scope of protection of Art. 9 para. 2 leg. cit. must be taken into account as a standard in the subsequent review of lawfulness”

The DPA went on and held that “A synopsis of the provisions of Article 9(1)(i) of the GDPR in conjunction with Article 3(1)(1), (1a) and (2) of the EpiG shows that the competent institution or, subsidiarily, the responsible laboratory that diagnoses the pathogen of a notifiable disease (such as the coronavirus) is obliged to notify the competent district administrative authority (as public health authority). In order to fulfil this legal obligation, it is therefore necessary (and thus permissible) for the respective agency to submit an official notification of a positive PCR test.

In the case in question, however, an official report was submitted on a negative PCR test. The obligation to submit an official report on a negative PCR test cannot be derived from the wording of Section 3(1)(1) and (1a) EpiG.

The obligation to submit an official notification specified in § 3 para. 1 EpiG may, however, be extended by the Federal Minister of Health pursuant to § 1 para. 2 leg. cit. may be extended by the Federal Minister of Health if this is justified for epidemiological reasons or required due to international obligations.

This possibility to extend the reporting obligations was used in the context of the current pandemic around COVID-19:

The Ordinance of the Federal Minister of Health concerning electronic laboratory reports in the register of notifiable diseases, Federal Law Gazette II No. 184/2013 as amended, was amended by Federal Law Gazette II No. 323/2020 to the effect that, pursuant to its § 1 para 3, facilities are obliged to also transmit all negative and invalid results to the district administrative authority in the event of a pandemic with COVID-19.

The regulation relevant here, which extended the reporting obligation, is based on the legal basis of Section 3 (1) EpiG and equally binds the respective medical institutions. Moreover, according to the first sentence of recital 41 of the GDPR, a legal basis, on which (the here relevant) Art. 9(2)(i) of the GDPR is based, does not necessarily have to be based on a legislative act adopted by a parliament.

Furthermore, there are no concerns with regard to the requirement of determinacy of normative provisions: In contrast to the Vienna Contact Tracing Ordinance objected to by the data protection authority (see the decision of 19 November 2020, GZ 2020-0.743.659), the scope and application of Section 3(1) of the EpiG in conjunction with Section 1(3) of the above-mentioned Ordinance of the Minister of Health are clear and precise. 3 of the aforementioned Ordinance of the Minister of Health are clear and precise, and it is clear to data subjects from the wording of these standards that negative and invalid PCR tests are also covered by the obligation to report to the district administrative authority (cf. recital 41, second sentence of the GDPR).

The extension of the reporting requirement of Section 3(1) of the EpiG is also expedient for combating COVID-19, as the data material (i.e. country- and federation-specific information on negative and invalid PCR tests) is relevant for targeting the pandemic strategy - especially the testing strategy. Although this was not objected to by the complainant, it must also be pointed out - with due brevity - that the standards of the EpiG and the cited ordinance of the Minister of Health also contain requirements with regard to purpose limitation, data minimisation and data security.

Against the background of all these considerations, the data protection authority therefore comes to the conclusion that the transfer of data relevant here can be based on the legal obligation of the respondent to also transfer negative PCR test results to the competent district administrative authority, which is standardised in § 3 para. 1 EpiG in connection with § 1 para. 3 of the aforementioned ordinance of the Minister of Health.

The disclosure of data relevant here therefore proves to be lawful and no violation of the complainant's right to confidentiality is to be assumed.

Therefore, the appeal is dismissed as unfounded.",COMPLIANT,"Article 4, Article 6, Article 9","[43,37,24,8,33]"
"The complainant belongs to a political party and is a member of the city council of an Austrian municipality. In November, the municipality held a meeting on the ""parking space concept"", to which a certain group of addressees, including the complainant, was invited. The complainant did not take part in this discussion because of an incorrect delivery of the invitation. The respondent, another political party, then posted an entry on her public Facebook page in which, to put it bluntly, criticism was made of the complainant's failure to appear.","The limits of permissible criticism in relation to a politician acting in his public function must be interpreted more broadly than in relation to a private individual.  Moreover, the use of the complainant's data in the proceedings was not unlawful because this form of political work is covered by § 1.2 of the PartG, and thus has a legal basis in the meaning of § 1.2 of the DSG.

==Comment==",COMPLIANT,"Article 4, Article 85","[12,21,30,49,3]"
"The complainant went to a post office to receive a letter addressed to him. From the post office employee, he was informed that the letter had not been delivered to him and that it had been left at that post office and that a notice had been left to the complainant (the so-called “yellow slip”). This was a non-official, recomanded (with a take-over certificate) registered letter. The post office clerk asked the complainant to show his identity document with a photo in order to take the letter. The complainant showed his identity card. Subsequently, the post office employee electronically (using a scanning device) recorded identity card data: type of ID card, ID card number, issuing authority, date of birth and the corresponding name. It was  stored for 6 months. After the retention period expired, the data in question were deleted. However, no copy of the ID document itself was made. The complainant alleged that the post office infringed confidentiality obligations by making a copy of his identity card. The complainant pointed out that even the general terms and conditions of the Post Office, in the event of doubts as to the identity of a person, refer to a presentation of a document and not to data collection. That is why he lodged a complaint with the supervisory authority.",The DPA rejected the complaint. It held that making by the post office a copy of a recipient's identity card does not infringe complainant's right to privacy and the post office has a legitimate interest in processing the personal data contained in the identity document to safeguard or defend its legal claims.,COMPLIANT,"Article 4, Article 5, Article 6, Article 13, Article 51, Article 57, Article 77","[14,33,41,31,21]"
"The Lernsieg app is an evaluation platform on which students can evaluate their school and teachers according to a predefined points system.  The individual criteria that can be evaluated include (currently): teaching, respect, patience, explanatory style, personality, fairness, motivation and organisation. The operator of the app (hereinafter: ""the data controller"") relied on the legal basis pursuant to Art. 6 para. 1 lit. f GDPR (legitimate interests) with regard to the processing of teacher data (name, department, related assessments).  The controller has implemented several mechanisms to counteract the effect of pillorying.","The processing of teacher data was lawful on the basis of Art. 6 para. 1 lit. f GDPR, i.e. that the interests of the general public and in particular of the pupils in the processing in question outweighed the interests of the teachers. The right to freedom of expression and information is not limited to objectifiable, generally valid value judgments. The present teacher evaluation concerns the professional activity of the teacher. The professional group of teachers must therefore be prepared for the observation of their behaviour by a broad public and for criticism of their performance. In the present case, the professional sphere is affected, which, in contrast to the intimate sphere, enjoys less protection.",COMPLIANT,Article 6,"[21,24,31,32,9]"
"The controller is Tryg Forsikring A/S, an insurance company, and the data subject is one of their policyholders. The data subject requested compensation from the company because of an injury. On 3 September 2020, the data subject lodged a complaint with the DPA against Tryg Forsikring. They claimed that the company had collected and retained their health data of a period dating back ten years, although they only consented for the company to collect health data for a period of five years prior to the injury.

Tryg Forsikring, on the other hand, argued that the health data had been obtained to determine whether the data subject was entitled to compensation. In their opinion, the processing of health data was necessary for the establishment, exercise, or defence of legal claims, and the exception laid down in Article 9(2)(f) GDPR was applicable. Moreover, the company stated that Article 6(1)(b) GDPR was the legal basis for the processing of the data subject's personal data, and therefore did not rely on the data subject's consent.","The DPA concluded that Tryg Forsikring processed the data subject's personal data in accordance with the GDPR. More specifically, the medical records were obtained to determine a possible claim for compensation under the insurance agreement between the data subject and the company. Hence, the DPA found that Tryg Forsikring's processing of the data subject's health data was covered by the exception laid down in Article 9(2)(f) GDPR.

Furthermore, the DPA found that the processing of the data subject's health information was based on legal ground set out in Article 6(1)(b) GDPR, because the processing was necessary for the performance of the insurance contract to which the data subject is a party.",COMPLIANT,"Article 6, Article 9","[6,37,43,44,31]"
"The controller is Den Blå Avis' (DBA), an online platform for second hand goods. The data subject has a blocked user account on the platform and requested the controller to erase his personal data pursuant to Article 17 GDPR. The controller refused to comply because it had received three independent complaints from buyers regarding the data subject. Hence, in order to prevent fraud, the controller claimed it needed to retain the personal data (the blocked account) in order to identify any newly created profiles by the data subject, pursuant to Article 6(1)(d) GDPR. Moreover, the controller stated there was no other way to achieve this objective of fraud prevention. The data subject filed a complaint with the Danish DPA (Datatilsynet).","The DPA rejected the complaint.

First, the DPA considered that the controller blocked the data subject’s account because of several complaints, and noted that the controller did this on the basis of Article 6(1)(f), and not Article 6(1)(d) GDPR, since the controller balanced the interests. However, the DPA also noted that there is no basis to disregard the controller’s assessment that their interests (fraud prevention) outweigh the data subject’s interests.

Second, the DPA considered that the data subject may object to the controller’s processing, but that the data subject did not bring forward any reasons that would justify the objection pursuant to Article 21(1) GDPR. Hence, the DPA found that it did not need to assess Article 17 GDPR, and rejected the erasure request.",COMPLIANT,"Article 6, Article 17, Article 21","[5,12,23,29,39]"
"After the termination of employment, a former municipality employee requested access to all communications in connection with his duties, in order to collect evidence against the municipality concerning his dismissal.

After providing some information under the rules on access to documents, the municipality tried to get the former employee to clarify and limit his request. It explained that the desired material was extensive after several years of employment. However, the data subject failed to clarify the scope of his request.

The municipality subsequently refused to provide additional material. It referred to the fact that the requested material constituted a vast amount of information in the form of notes, letters and e-mails which the former employee had prepared or sent in connection with the performance of his duties.","The Danish DPA held that in principle, under Article 15 GDPR, the data subject has a right to access his personal data processed by the controller, but that this rights is not absolute. The DPA stated that pursuant to Article 12(5)(b) GDPR,  a data controller may refuse to comply with an access request if it is manifestly unfounded or excessive.

The DPA also emphasized that although the information contained in such communications should be considered personal data,  this information was first and foremost related to the data subject's functions, and not information about the data subject himself or his personal attributes. The DPA held that in some cases, information which might include a description of a course of action which is a personal choice made by the data subject may thus be subject to his right of access, and that this would be an assessment that the controller would have to carry out.

The DPA therefore held that it had no basis for overriding the municipality's assessment since the information requested spanned over several years, and was only related to his duties during that time.",COMPLIANT,"Article 12, Article 15","[30,37,9,34,3]"
The Danish DPA investigated a company's compliance with the GDPR information obligations. The company processed personal data in relation to rapid COVID-19 testing of children aged 12 or above in primary school. Information about the processing could be found in a privacy policy that had been forwarded to both the data subjects (the children) as well as their guardians through a digital communications platform used by the schools. The company had also attached an invitation to read the privacy policy.,"The DPA had to assess whether the controller had fulfilled its information obligations under Article 13(1)(a-f) GDPR and Article 13(2) GDPR. The DPA first noted that pursuant to Artilcle 12(1) GDPR, the information must be given in a ""concise, transparent, intelligible and easily accessible form, using clear and plain language, in particular for any information addressed specifically to a child"".

The DPA held that the privacy policy contained all the information the controller had to provide. Furthermore, the DPA found that using a digital communications platform was sufficient to fulfil the information obligations. The DPA therefore found no violation of the GDPR. However, the DPA recommended that the controller prepares information more directly aimed at children, both in form and content.",COMPLIANT,"Article 12, Article 13","[8,14,34,23,39]"
"A data subject was in 2011 sentenced to four years in prison for a serious case of corruption and for concealing the output from their criminal acts. They were also sentenced to pay about €550,000 in compensation and lost their right to run a business, including acting as a general manager or another leading position in any company's board, indefinitely. The case was mentioned in several newspaper articles.

The data subject contacted Google and Bing in February 2020 to request deletion of four search results leading to articles mentioning the prior criminal case. Bing deleted the results, but Google refused, stating: ""Having assessed the balance of relevant rights and interest relating to the content in question, including factors such as its relevance to your professional life, Google has decided not to block this content."" Consequently, the data subject lodged a complaint against Google.

The DPA noted that the lawful basis was Article 6(1)(f) GDPR and referred to the Article 29 Group's guidelines WP225 relating to search engine results and the balancing between fundamental rights and interests vs. de-listing of information. They also took into account that the information the search results lead to, was convered by Article 10 GDPR that by default prohibits processing of such personal data (relating to criminal convictions and offences). Normally, this would support erasure in this situation, cf. G.C. & Others v. CNIL, section 67 (C-136/17 24 September 2019).

However, on the other hand, two of the search results lead to articles with objective and factual information the data subject's criminal past. The DPA found this to contradict the data subject's right to erasure. Further, the DPA emphasized that the search results was published for journalistic purposes and the context for which the articles was published, support the public interest and contradicts the right to erasure. Finally, the DPA notes that the information relates to the data subject's work life and is less of a private nature, which further supports their assessment to deny the erasure request.

The DPA noted that the data subject, who today acts as a Chief Security Officer, still has a role in the Norwegian business landscape. The search results are therefore still relevant, despite the articles dating back nine and ten years, and especially because the company they work at plans to go public. The public therefore has a particular interest regarding their work-related past.","The DPA investigated four search results in total. They instructed Google to delete one search result and requested more information for another one. However, the DPA denied the erasure request from the data subject for the two other search results.",COMPLIANT,"Article 5, Article 6, Article 10, Article 17, Article 21","[5,44,47,9,43]"
"The general manager of Lindstrand Trading AS conducted multiple credit ratings of the complainant and her sole proprietorship, despite having no customer relationship or any other affiliation with the company. The DPA noted that the general manager used the credit rating tool for personal purposes, completely outside of the company's area of business. Consequently, Lindstrand Trading did not have a legal basis for such processing as per Article 6(1)(f) GDPR.","No, Lindstrand Trading AS did not have legal grounds for processing the personal data of the complainant for credit scorings, as per Article 6(1)(f) GDPR. For this offense, the company was fined NOK 100,000.

They also didn't have sufficient internal controls for the use of credit scoring in their business, as per Article 24 GDPR. For this offense, the company is required to establish corresponding internal controls and, within four weeks after the expiry of the appeal period, submit a written confirmation and actual documentation of the internal controls, to the DPA.",COMPLIANT,"Article 6, Article 24","[3,13,19,28,11]"
"After reviewing their Microsoft Hotmail account login activity, a data subject believed that the account had been hacked as the list of IP addresses showed unlawful logins and email activity. The data subject asked Microsoft support for help to identify these IP addresses, both in terms of the IP ""owner"" and the login location. Microsoft rejected the request.

The data subject then required assistance of the Norwegian DPA, based on GDPR rights. The DPA denied the request as per Article 55 GDPR, stating that the GDPR does not apply to his situation. In this regard, the DPA noted that IP addresses may be personal data as per Article 4(1) GDPR and that the data subject indeed has a right to obtain these from Microsoft - however only as far as it concerns his own personal data. According to Article 15(1) GDPR where a data subject's access right pertains to their personal data, not the personal data of someone else. Consequently, the DPA stated that they are not competent to instruct Microsoft to hand over this information.

The data subject lodged a complaint to the DPA about their decision, however, the DPA upheld their decision and it was (as per Norwegian law) referred to the Privacy Appeals Board.","The Privacy Appeals Board agreed with the DPA and rejected the data subject's complaint. The Privacy Appeals Board noted that regardless of the data subject's claim, it's not Microsoft who has the list of IP addresses matched with identity, but internet providers (for limited time). Further, they note that it's usually difficult to determine the location of an IP address, especially if someone uses a mobile phone and VPN (Virtual Private Network).",COMPLIANT,"Article 15, Article 55","[47,11,16,35,48]"
"A data subject who comes from the Netherlands moved to Norway and established a customer relationship with a bank (Sbanken ASA). For several years, the complainant has been in dialogue with the bank to correct the way they write his name. The bank writes his name in capital letters in ""van"" (Name Van Navnesen, instead of Name van Navnesen).

The bank stated that its processing systems retrieve customer information from the National Population Register. In the National Register, all names are written in capital letters and Sbanken has a program that automatically changes the spelling of names from uppercase to lowercase letters with the exception of the first letter which is written in capital letters: from ""NAME VAN NAVNESEN"" to ""Name Van Navnesen"". The reason for this choice is that most customers write all names with a capital letter in line with the Norwegian naming tradition.

As the data subject was unsuccessful in having his name spelled differently, he lodged a complaint with the Datatilsynet. The DPA held that Article 16 does not require a qualified degree of inaccuracy, and does not allow for a risk-based approach to when the data subject's rights can be asserted. The Datatilsynet also emphasised the objective nature of the personal data in question, and noted that such data (the same as age, address, personal name, or other information with an objective standard) shall be corrected by replacing it with information that is objectively correct. Furthermore, the DPA found the bank’s proposal, of correcting the complainant’s name in the online banking website but not in the bank's underlying systems, to be insufficient.","The PVN unanimously overturned the Datatilsynet’s decision. In building its arguments, the PVN recognized that in the Dutch passport the name was written with a lowercase letter (“van”). However, it then noted that it is normal to have differences between countries in spelling names, and gave examples of characters which do not even exist in all languages.

Other than the Datatilsynet, the PVN’s reasoning did not focus on the objective nature of the data, nor on it being objectively incorrect. Instead, the PVN relied on the principle of data accuracy and emphasised that the correctness of the data must be assessed in light of the processing purposes. As the purpose of the bank is to administer the customer relationship with the complainant, the PVN held that the current spelling of the name entails no danger of misidentification. Therefore, the PVN held that there is no incorrect personal data that can be required to be corrected in accordance with Article 16.",COMPLIANT,"Article 5, Article 16","[4,5,22,27,30]"
"The Norwegian Consumer Council (Forbrukerrådet) filed three complaints against the gay/bi dating app Grindr and five adtech companies that received personal data through the app. Subsequently, Datatilsynet sent a request for more information from one of the adtech companies; OpenX.

OpenX refused to respond on the basis that Datatilsynet does not have legal grounds to impose such a request on them, because, in their opinion, the issue relates to the Electronic Communications Act § 2(7)(b) (cf. Article 5(3) ePrivacy Directive 2002/58/EC), where the Norwegian Communications Authority is the right supervisory authority (and not Datatilsynet), and filed a complaint to the Privacy Appeals Board.",The Privacy Appeals Board rejected OpenX's complaint as they concluded that Datatilsynet has legal grounds to impose such requests for information as per Article 58(1) GDPR.,COMPLIANT,"Article 57, Article 58","[6,10,17,41,49]"
"The newspaper Bergens Tidende published a story regarding an insolvency case, which highlighted that the tax authority had declared the complainant bankrupt due to unpaid taxes. The article also mentioned that the complainant had payment remarks and execution proceedings against him, and that the information was collected from a credit rating. The newspaper later informed that some of the information was factually incorrect. The complainant also filed a complaint with the Norwegian Press Complaints Commission (""Pressens Faglige Utvalg""), where the complaint was upheld.","PVN remarked that the wording of the exemption for journalistic activities in Personopplysningsloven § 3 was broader than Article 85 GDPR. It highlighted that the exemption was not absolute, but that freedom of expression needed to be proportionally balanced against the right of privacy.

PVN based the assessment on the wording of Article 85 GDPR, The Norwegian Constitution § 100, The European Convention of Human Rights Article 10, and the International Covenant on Civil and Political Rights (ICCPR) Article 10 and Article 19.

PVN refers to C-73/07 para. 55 and 56 to support their view of the assessement of proportionality and that the exemption must be read in light of freedom of expression.

PVN agreed with the complainant that the exemption for journalistic activities was not absolute. However, the personal data collected in the specific case was for an article under an established newspaper with editorial control and with a clear public interest. The complaint was therefore rejected.",COMPLIANT,Article 85,"[14,0,6,41,19]"
"The DPA examined a complaint against a search function which suggested certain search suggestions automatically. Thus, when entering certain words, the complainant’s name was automatically suggested and two search results appeared in the search engine.","The Datatilsynet confirmed that a municipality had a legal basis to process information about citizens who used a “type-ahead” search function on the municipality’s website under Article 6(1)(e) GDPR. It also found that the purpose of this function was to offer a better service to citizens and that only the keyword was stored in the search engine, not any user’s details; in accordance with Article 5(1)(c) GDPR.",COMPLIANT,"Article 5, Article 6","[21,8,39,13,11]"
"A data subject complained to the Danish DPA that his former insurance company, Velliv, Pension & Livsforsikring A/S, did not provide him with all his personal data in the course of an Article 15 data subject access request. In particular, the data subject complained that he did not receive the name of the medical consultant who had prepared a medical assessment of the complainant. The DPA did not consider the name of the medical consultant to represent personal data related to the data subject, and therefore did not find grounds for initiating a complaint.

The data subject then contacted the Datatilsynet once again and stated that he still believes that there was more information to which he was entitled, and which the controller did not provide to him. The insurance company then informed the DPA that it had not provided the data subject with an internal working document, which contained the controller's legal assessment as well as correspondence with the company's lawyer as a preparation for an upcoming lawsuit notified by the complainant. In addition to the legal assessment, the internal document also contained extracts of medical information and an observation which had previously been handed over to the data subject in complete versions.","The Datatilsynet held that the insurance company did act in line with Article 15 GDPR. The DPA did not consider the name of the medical consultant to represent personal data related to the data subject, and highlighted that the information contained in the internal working document had already been accessed by the data subject.

With regards to the company's correspondence with the lawyer, the Datatilsynet considered that this did not contain information covered by the data subject's right to access in Article 15 GDPR. In this context, the DPA made a reference to the fact that data controllers may, depending on the circumstances, refuse to grant data subjects insight into e.g. a note assessing whether a particular lawsuit against a customer can be won.",COMPLIANT,Article 15,"[5,32,23,41,8]"
"The DPA conducted an audit of the IT University of Copenhagen (ITU) and their use of an online proctoring service for one of their online exams.

Following COVID-19, ITU was required by Danish authorities to provide education and exams online. They were also instructed to ensure integrity of the exams, to prevent cheating. ITU considered the need for monitoring for each exam and found that one required the use of monitoring (”Algorithms and Data Structures”), because the exam answers would be identical for every student (it would be easy to copy and share answers). This processing would be based on Article 6(1)(e) GDPR, cf. § 6(1) the Danish Data Protection Act.

ITU stated purpose for using an online proctoring tool, which in this case was ""ProctorExam"", was 1) to supervise the student during the exam, and 2) to prevent cheating. The use of ProctorExam included that:  1) The student would show an ID to the webcam (a student card from ITU or other valid ID). This would be manually controlled by an ITU representative. 2) A video and sound recording, and a recording of the student's screen 3) Recording of the web browser browsing history The use did not include any processing of biometric data or facial recognition technology.

The DPA emphasized the following in their finding and decision:

* ITU had conducted (and documented) a concrete necessity test of the need to use monitoring tools, for all their exams
* ITU had chosen an online proctoring tool that was considered to be the least invasive one (for their circumstances)
* ITU had informed the students in a concise, transparent, intelligible and easily accessible form, using clear and plain language, specifically for the type of processing when using ProctorExam, as well as providing the students with their general privacy notice
* ITU had conducted a risk assessment, considered technical and organizational security measures and introduced measures to minimize the processing in question (e.g. encryption in transit and at rest, secure servers located in the EEA, access control and more)",The DPA held that ITU had legal grounds for requiring students to acccept monitoring while taking an online exam.,COMPLIANT,"Article 5, Article 6, Article 32, Article 35","[43,48,27,15,38]"
"In a previous case, a data subject informed the Hellenic DPA (HDPA) that during the period from July to September they were getting frequent phone calls and nuisances by the representatives of a Greek bank on debt matters from a consumer loan, and filed a complaint on the grounds that this practice constitutes automated decision-making (including profiling) according to Article 22 GDPR.

The Hellenic DPA rejected the claim and did not apply legal remedy since there was no substantial documentation or essential proof that any processing activity through automated decision-making had taken place, or that the data subject's rights were infringed upon.

The data subject then submitted a new complaint regarding the same issue.","The HDPA rejected this new complaint on the grounds that there was no new evidence brought forward by the claimant in this case. Moreover, the HDPA stated that the data subject could exercise their rights through the right to object under Article 21(1) GDPR, which should be addressed to the controller first (the Greek bank in this case). The HDPA also indicated there is a specific national legal framework (Law 3758/2009) regulating information related to bank clients and debtors.",COMPLIANT,"Article 22, Article 21","[4,14,15,23,34]"
"A data subject complained that 401 Athens General Military Hospital unlawfully processed personal data of people entering the hospital, collecting details from their ID and information about where exactly in the hospital they intend to go, time of entrance and exit.

The Military Hospital claimed that this information was necessary for the security of the hospital and that in any case, the DPA was not competent to deal with the case as it concerns data related to activities concerning national security.","The HDPA found, first of all, itself competent to decide on the case as the personal data collected (a) has not been characterised as ""classified information"" (b) nor does it relate to activities concerning national security, as required by the national Data Protection Act.

Then, the HDPA rejected the complaint as it found the processing necessary for the protection of military facilities and thus lawful according to Articles 6(1)(e) and 9(2)(g) GDPR.

Lastly, the HDPA imposed the corrective measure of Article 58(2)(d), ordering the Military Hospital to appoint a DPO.",COMPLIANT,"Article 2, Article 4, Article 6, Article 9, Article 37, Article 45, Article 51, Article 55, Article 58","[6,19,21,23,44]"
"The Complainant was working in one of the merchant's stores where a CCTV system was installed and active. The employer repeatedly had assured the employees that not only was that the field of view of the cameras the cash registers, but also that the CCTV did not capture any sound at all.

The Complainant began to believe that more cameras had been installed in the store and that they were recording sound as well. Therefore, she submitted the following complaint to the Greek DPA. She also brought a court action with which she claimed damages for the unlawful processing. She claimed that some of the cameras were scoped to the WC room and the changing rooms.

During the hearing, the employer declined any allegation regarding the sound recording. He also submitted a detailed list of all the cameras with recording samples for each one and clarified all the ways he used to inform visitors and staff of the existence of that CCTV system, including notices, signs and brochures, as well as the entire Company's policy of the personal data protection in written form.","The Greek Data Protection Officer argued four points:

First, under Article 4(1), the Greek DPA Office confirms that visual and sound data may be considered personal data when identifiable information relating to natural persons is included.

Second, indoor and outdoor video surveillance in areas which persons are invited to visit fulfils the definition of processing as per Article 4(2) of the GDPR.

Third, the Greek DPA concludes that a genuine adoption of the concept of proportionality in such circumstance shall also examine (a) the lawfulness, fairness, and transparency of the processing without underestimating aspects as (b) how much further the process goes in a manner that is incompatible with announced, specified, explicit and legitimate purposes or (c) minimising the amount of data to what is absolutely necessary within those purposes.

Fourth, the Board concluded that the contested CCTV system was compatible with the requirement of Article 6(1)(f) GDPR according to which, a data processing is lawful when it is strictly necessary for the purposes of the legitimate interests pursued by the Controller, except where fundamental rights of the data subject override such interests.

The Greek DPA found that the merchant collected only the strictly necessary data in order to increase the security level of the store and protect it against thieves.",COMPLIANT,"Article 4, Article 5, Article 6","[4,7,12,13,33]"
"Alien asked the erasure of his data from SIS and EKANA. The HDPA invited the Aliens Division of Attica to provide supporting documentation. The complainant exercised his right to erasure twice before EKANA, but his request was rejected both of the times, since he hadn't submitted the documents needed to prove a legal residence in Greece.","The HDPA found that the complainant had been arrested because he didn't have residence documents. He was also sentenced in prison for eight months by the Greek Courts for other violations, while a return decision against him is still pending. Therefore, the HDPA found that the complainant was lawfully registered in both registers for reasons of public order and public security and there has been no reason for the registration's reassessment since the three-year period after the last registration is still ongoing.

On these grounds, the HDPA rejected the complaint as unfounded.",COMPLIANT,"Article 6, Article 21","[8,11,21,28,38]"
"The Lithuanian DPA (VDAI) launched an investigation into the Lithuanian Quarantine App (""Karantinas"") in May 2020 after information in the media that there potentially was unlawful processing of personal data involved. This App was launched by the National Center for Public Health (Nacionaliniam visuomenės sveikatos centrui) and developed by UAB IT Solutions Success (UAB „IT sprendimai sėkmei“).

The App was suspended after preliminary findings which triggered the investigation process. The DPA ordered UAB IT Solutions Success to suspend the processing of personal data. However, UAB IT deleted this data instead.

In the investigation, the DPA found that the personal data of 677 individuals were collected in April 2020. This generally included personal data such as identification number, latitude and longitude coordinates, country, city, municipality, postal code, street name, house number, name, surname, personal code, telephone number, address, 2nd address, whether the place of residence is declared in Lithuania and other information. The processing was conducted in Lithuania, other EU/EEA States, as well as third countries (non-EU such as India and the US).","The Lithuanian DPA first established that the National Center for Public Health (Nacionaliniam visuomenės sveikatos centrui) and the Company responsible for developing the App,  UAB IT Solutions Success (UAB „IT sprendimai sėkmei“), were joint controllers.

The DPA discovered from its investigation that a Data Protection Impact Assessment had to be done prior to processing in line with Article 35 GDPR. The App concerned processed personal data using new technology as well as a systematic monitoring of data subjects in self-isolation. The App also aimed to process large datasets (data subjects throughout Lithuania and abroad). The processing was intended to be continuous and vulnerable data subjects were concerned.

The DPA found that the National Center for Public Health violated Article 24 and 32 GDPR on the implementation of organisational measures, as well as the principle of integrity and confidentiality found in Article 5(1)(f) GDPR.

The DPA found that both the National Center for Public Health and UAB IT Solutions Success violated the principle of lawfulness Article 5(1)(a) GDPR as they failed to prove that they had a legal basis for processing. The principle of transparency was also infringed (Article 5(1)(a)) . Finally, as neither entities recognised that they were data controllers, the accountability principle was not met (violation of Article 5(2)).

In summary, the DPA found that the National Center for Public Health breached Articles 5, 13, 24, 32, 35 and 58 (2)(f) GDPR and imposed a fine of €12,000 on the public body. In turn, the DPA found that UAB IT Solutions Success violated Articles 5, 13, 24, 32 and 35 GDPR and imposed a fine of €3,000.

The fines reached this level as the National Center for Public Health and UAB IT Solutions Success processed personal data without a legal basis in an intentional way, systematically, without technical and organisational measures. The DPA also took into consideration that this concerned special categories of personal data. Finally, in addition, UAB IT Solutions Success did not comply with the DPA's request to suspend the processing and instead, deleted the personal data collected.",NONCOMPLIANT,"Article 5, Article 13, Article 24, Article 32, Article 35, Article 58","[19,40,33,32,29]"
"Starting in July 2020, the VDAI was investigating the incident of a data breach in the systems maintained by the State Enterprise Center of Registers. The data affected by the data breach was stored in:

Electronic health services and collaboration infrastructure information system;
  Real estate register;
  Real estate cadastre;
  Register of Legal Entities;
  Population Register of the Republic of Lithuania;
  Register of seizure deeds;
  Mortgage Register of the Republic of Lithuania;
  Register of wills;
  Register of marriage contracts;
  Register of credentials;
  Register of incapacitated and restricted persons;
  Register of contracts;
  Information system for participants of legal entities;
  Bailiffs information system;
  License information system;
  Money Restriction Information System;
  Legal aid services information system;
  Registration service information system;
  Electronic signature and timestamp service;
  Register center document management system;
  Personnel administration system of the Register Center;
  Accounting software of the Register Center.","The fine of 15000 EUR was imposed for infringements of Article 32(1) (b) and (c) of the BDAR, ie failure to ensure the integrity, availability and resilience of data processing systems and services as well as failure to restore the conditions and access to personal data in the event of a physical or technical incident within the legal deadline.

In determining the amount of the administrative fine, the VDAI took into account the factors mitigating the violation committed by the Center of Registers listed in Article 83(2) (b), (c), (e), (f) and (h) GDPR, i. e. the absence of intent, the efforts made to restore the damaged data, the absence of facts about the material damage suffered by the data subjects, the close cooperation with the VDAI and the absence of previous violations of a similar nature. The VDAI also took into account that the Center of Registers, when implementing security measures, is dependent on both the data controller, the Ministry of Health of the Republic of Lithuania, and other institutions dealing with the consolidation of state IT resources, and ruled that the proposed fine was a proportionate sanction to ensure future compliance with the provisions of the GDPR.",NONCOMPLIANT,"Article 32, Article 83","[26,36,6,43,24]"
"The Spanish DPA (AEPD) launched an investigation on Mercadona, a supermarket chain, after having notice, via the media, that it was using a video surveillance system using facial recognition to prevent access to their premises of people convicted for robbery or other crimes related with Mercadona and with entry bans in force.

Afterwards, also two complaints were lodged in this regard by a consumers association and an association for computer enabled crimes and problems.

Mercadona started to use this system on 1/06/2020 until 6/05/2021, after the AEPD issued an interim measure ordering the controller to stop the processing. Additionally, the process was brought to court in the meantime, what resulted in an order to stop the processing by a Spanish court in AP Barcelona - Auto 72/2021.

The system used a facial recognition process that compares a ""dubious biometric sample"", obtained from one or more images of a person, against a database of biometric samples already associated with the identity of a person, which have been previously registered through one or more images of that person. To this end, the ""dubious biometric samples"" are transformed into patterns though algorithmic calculations that are evaluated based on previously established matching thresholds.

The data processing included the capture, matching, storage and destruction - in case of negative identification (after 0.3 seconds of its collection) - of the captured biometric image of any person entering the supermarket.

Mercadona, the controller, informed that they were relying on a public interest, from Article 6(1)(e) GDPR, for the processing, as it purpose was to ensure the safety of the people and goods, as well as of their premises. The particular national law alleged was the Private Security Act.

As regards to biometric data, the controller acknowledged that they were processing special categories of data from Article 9 GDPR, and that they were relying on the exception from Article 9(2)(f), since they were processing data for complying with the court judgments that allowed the controller to use electronic means to control what the judgments provide (such as entry bans).

The controller alleged that the use of such a system is the only adequate way of actually controlling entry bans, since Mercadona has 1,623 shops and 95,000 employees, and that that system would provide more legal guarantees and reliability than any other system, that could not ensure control.

Mercadona also had informative banners in all the (40) shops in which the system was used.","The DPA held that Mercadona had violated Articles 5(1)(c), 6(1), 9(1), 12, 13, 25(1), and 35 GDPR.

On Articles 6, 9 and 5(1)(c) GDPR

Special categories of data

The DPA started by confirming that the data processed by Mercadona was included in the special categories of data from Article 9 GDPR, since it is biometric data that is used for the purposes of biometric identification (as opposed to biometric authentication). As remarked by the DPA, facial recognition systems are identification systems that are very intrusive for rights and freedoms.

The DPA also noted that the processing was carried out at a distance, continuously, and it was automate, and used algorithms to create the patterns, what derived in a extreme risk, as it may lead to an indiscriminate and mass surveillance.

Therefore, the controller should have relied on a valid exception from Article 9(2). According to the DPA, the controller could not have relied on the exception from Article 9(2)(g), regarding public interest, since such interest must be set by national law, that shall also specify the circumstances, limits, rules, and measures for applying the exception and relying on a public interest, and be proportionate. Since there is no national law allowing this type of processing, the controller could only have relied on explicit consent.

The DPA also remarked that all the persons that entered any of the shops of the controller were the system was used were treated as convicted subjects, since the controller's justification to use the system was to control and prevent only the entry of convicted persons.

The judgments allowed for the use of electronic means to implement the system, as requested by the controller; in some cases even mentioning facial recognition, in accordance with the measures allowed by the Spanish Criminal Code. However, the AEPD concluded that such measure may only affect the (rights of the) convicted persons. Additionally, not all judgments talk about facial recognition. And, particularly, the DPA noted that the use of such system should take into account the nature and context of the situation that leads to the processing, including the seriousness, probability and size of the potential harm and consequences to rights, guarantees and freedoms of all the affected persons, including the convicted persons. Also, the judgment allowing the use of such means should have included the necessary and proportionate conditions and guarantees to be implemented, what they did not actually do, leaving it to the discretion of the controller.

In this regard, the DPA also considered important that the controller had tried to prepare in advance the legitimacy to carry out such processing by directly requesting the courts to allow them to use a facial recognition system to control the entry, and that this had been done without carrying out in advance a data protection impact assessment (DPIA), an analysis of the (extreme) risk and a prior consultation to the AEPD, as they should have done. This, that should had been done before requesting the permission of the court, should have led the controller to determine the unacceptability of the risk. Additionally, the DPA stated, the electronic means used by the controller shall only had affected the convicted persons to which the judgments concerned, not third persons such as Mercadona clients and workers.

Legal basis

The DPA also remarked that the controller did not have an appropriate basis form Article 6 to rely on. In the same way as what the DPA noted regarding the exception from Article 9(2)(g), the public interest legal basis from Article 6(1)(e) needs to be defined by law, including a mention to affected interests, restrictions to its use, limits and conditions. This will pose a limit for public powers, as well as ensure the principle of legal certainty.

However, in this case, there is no real connection between the security measure they system is used for and public interest; it only pursues the private interest of the controller. The DPA also differentiated between activities that are connected to a public interest, so they benefit the society as a whole, and where a judge or court should assess its proportionality, against an activity in which public interest is used to legitimize the massive processing of the data of every person, so everyone is treated as a convicted person.

Anyway, the DPA argued, in line with the previous judgment, that there is no such public interest, since the company was only pursuing a private interest.

Analysis of the legal bases and exceptions

In its analysis about legal bases and exceptions, the AEPD differentiated between three types of processing: the processing of convicted persons data, the processing of potential clients, the processing of Mercadona workers.

With regards to the data of the convicted persons, Mercadona alleged the use of the exception from Article 9(2)(f), regarding the processing of data for legal claims. However, the DPA concluded that the use of this exception was not valid.

In this case the legal claims had already been exercised or defended. Additionally, the existence of a legal claim does not entitle the controller to process such data per se; other conditions must be met. In accordance to Recital 52, this shall be done exceptionally and when it is necessary. It also requires adequate guarantees. Therefore, the interpretation of the legal text must be done in a restrictive way. In this sense, the AEPD compared this exception to Article 10 GDPR, that also requires, for the processing of criminal data, to be under the supervision of a public authority; in this case, the processing was not supervised, only potential consequences deriving from it (such as the non-compliance with the judgment). The DPA also remarked here that, for example, if it was the court that would be the one to carry out the processing, they could only process data of the convicted persons, since the measures contained in the judgment can only affect convicted persons. Therefore, what a court cannot do should not be allowed for a private actor to do.

With regards to the legal basis from Article 6, the DPA stated, as already explained, that the basis from Article 6(1)(e) needs, firstly, to be defined by law and, mainly that such public interest did not exist, since the company was only pursuing a private interest.

With regards to the data of potential clients, Mercadona tries to rely also on the exception from Article 9(2)(f), which as explained is not valid. The DPA explained again that the court can only establish measures in its judgment that affect the rights of convicted persons; third persons cannot have their rights affected. This third persons include children, minors and vulnerable people. This totally disproportionate measure, as the AEPD remarked, violates the spirit of the GDPR.

The DPA concluded that, even if the exception from Article 9(2)(f), the measure, that is a taken in the framework of a criminal procedure, can only affect the persons affected by the judgment; otherwise, it would indirectly mean massively imposing a criminal measure on non-related third persons. This would generate a perverse effect, that would be translated in practice to the establishment of a large scale facial recognition system, highly intrusive in people's rights and freedoms, that would pose an unacceptable risk.

Although it is true that the Spanish law, both the Data Protection Act, in its Article 22, and the Private Security Act, in its Article 42, allow for video surveillance systems, this does not include facial recognition systems, that pose a much bigger risk and are more intrusive, and are not meant to be used for private interests.

With regards to Mercadona workers, the AEPD concluded that they were not taken into account in the DPIA carried out by the controller, even when they were specially affected. In accordance with the Opinion from the A29WP, the controller should have carried out an evaluation between legitimate interests of the controller and the reasonable privacy expectations of the employees by outlining the risks posed by this technology and by undertaking a proportionality assessment, what was not done at any moment. The use of the technology was clearly disproportionate, also as there is a risk that it may result in an indirect control of the workers.

The DPA also made reference to the new provision implemented in the Spanish labour law, providing for algorithmic transparency of artificial intelligence systems that affect workers, as they found a lack of transparency regarding the functioning of the system. This is also connected with Articles 5(1)(a), 12, 13, and 14 GDPR, and Article 89 of the Data Protection Act, that provides for a privacy right for workers.

In conclusion: a measure that affects only a very small number of persons that have been convicted does not legitimize the use of this technology. There is no legal basis, nor any exception from Article 9, that can legitimize the processing. Therefore, Articles 6 and 9 had been violated.

Proportionality assessment

Data processing requires a proportionality assessment. The assessment must entail three requirements: adequacy assessment, necessity assessment and proportionality assessment in a strict sense (rights and freedoms balance). The assessment must additionally be carried out at the right moment, i.e. before actually carrying out the processing. Also, it will require a detail look when dealing with biometric data, that pose a higher risk. Whether the  the resulting loss of privacy is proportional to any anticipated benefit must be weighed.

The processing must be essential to fulfill the need. This also means that if there is a less intrusive way to achieve the pursued end, it shall be followed. Therefore, the processing must not just be useful, but strictly necessary to achieve the purpose.

According to the DPA, the processing was neither proportionate, since it affected the rights of every potential client and the employees when it should only affect convicted persons, nor necessary, since there are less intrusive ways of achieving the purpose, such as having the photographs of the convicted persons in every premise, for the security staff to know them. The AEPD also remarked that, in this case, this system may not even be adequate for the purposes, since it would be easy for the convicted persons to fool it, using, for example, a mask, so it may be neither useful nor effective.

This is also linked with Articles 5(1)(c) and 25(1) GDPR. The fact that the processing is authorized by a judgment does not make it necessary; specially since it does not provide for any safeguards, what should be hence done by the controller, that is responsible for the compliance, in accordance with the accountability principle too. The controller still has to comply with the data protection rules.

The DPA also remarked that it was not proven that the controller had adopted any technical measures to avoid the transfer of data to third parties, including international transfers of data.

Minimization principle

With regards to Article 5 GDPR, the DPA also noted that the minimization and purpose limitation principles shall be respected; particularly the minimization principle from Article 5(1)(c) GDPR. However, the own nature of facial recognition systems leads it to a massive processing of biometric data - that shall entail reinforced guarantees, also because of the high number of affected data subjects.

The processing activity at stake is, additionally, not proportionate, since it could be argued that it is adequate but it is neither necessary nor strictly proportionate, since there are less intrusive alternatives and as the rights and risks are not properly balanced. Therefore, the processing is exercise; the controller is processing data of every potential client and employee only for the purpose of controlling a small number of convicted persons. Therefore, the minimization principle was infringed, so there had been a violation of Article 5(1)(c) GDPR.

Personal data of children

The AEPD put special emphasis in the fact that the controller should have carefully considered the risks that the processing of personal data from children and vulnerable persons entail, in accordance with Article 28(2) of the Data Protection Act.

Conclusion

Hence, the DPA concluded that there is no possibility of relying on the exception from Article 9(2)(g), there is no valid legal basis from Article 6(1), and that the necessity, proportionality and minimization principles had not been respected. Therefore, Articles 6(1), 9(1) and 5(1)(c) GDPR were violated.

On Articles 12 and 13 GDPR

The DPA concluded that Mercadona had not respected the transparency principle, since the controller does not provide adequate information to data subjects. Firstly, because the banners informing about the system only mentions the use of the facial recognition system in relation with convicted persons, but does not make any reference to the data of the supermarket's clients.

It is, additionally, misleading, since it mentions that the purpose is the security of the clients, when it is actually only pursuing a private interest of the controller; the security of the clients could be achieved with a standard video surveillance system.

Also, the controller does not specify in which shops in particular the system is being used (nor the duration of it and the actual purpose), therefore limiting the capacity of the clients to decide not to enter particular shops that are actually using it. Their auto-determination right, freedom and privacy is being violated this way.

There is neither information on international transfers of data, that may occur in accordance to the data processing agreement with the processor, even if the controller denied such possibility.

Therefore, the AEPD concluded that Articles 12 and 13 GDPR had been violated.

On Article 25 GDPR

The AEPD also analyzed how the high ratio of error in facial recognition systems was linked to data protection by design. According to the DPA, algorithmic bias, produced by the lack of training data from vulnerable collectives, such as radicalized people, women, children and elderly people, may lead to discrimination and social exclusion, which poses an unacceptable risk by design. Also, nowadays, in the context of the covid19 pandemic, the risk of error is higher due to the use of masks.

Therefore, the DPA concluded that there had been a violation of Article 25(1) GDPR.

On Article 35 GDPR

The AEPD determined that the controller should had carried out a data protection impact assessment prior to the processing, in accordance to Article 35 GDPR, since the processing can be considered high risk, in accordance with EDPB Guidelines. Albeit, the controller requested the court the permission to use a facial recognition system before carrying out the DPIA.

A proper understanding of proactive accountability and privacy by design implies assessing from the very first moment of the outline of a processing activity of personal data whether it can be carried out. Thus, the first moment in which the idea of requesting the use of a facial recognition processing before the courts, should have been the moment to assess and detect the risks to the rights and freedoms of citizens.

Additionally, the DPA remarked that the risks arising from such automated processing are high in themselves and, in fact, unacceptable, since the initial inherent risk cannot be reduced to adequate levels (residual risk), as there is a prohibition in accordance with Article 9(1) GDPR. Such processing occurs without human intervention, in such a way that the data subjects are unable to exercise the right of erasure and object.

The DPIA that was carried out (extemporaneously) also failed to take into account different risks, namely:

* The fact that facial recognition entails an involuntary processing of personal data, to which data subjects cannot object, and that gathers a very high amount of data.
* The risk of discrimination, social exclusion and infringement of the accuracy principle due to the high ratio of error of these systems.
* The risk of stigmatization of the convicted persons.
* The risk of making every client a potential suspect subject to surveillance.
* The specific risks regarding vulnerable collectives.
* The risk of loss of privacy and intimacy.

The lack of consideration of such risks de facto invalidates the DPIA.

The AEPD concluded that Article 35 GDPR had been violated.

Sanction and amount of the fine

The AEPD fined Mercadona a total of €3,150,000, that were reduced a 20% to €2,520,000 for early payment. The AEPD also ordered Mercadona to stop the processing, in line with the interim measure it took during the course of the procedure.

The amount of the fine was divided as follows:

* €2,000,000 for the violation of Articles 6 and 9 GDPR.
* €100,000 for the violation of Articles 12 and 13 GDPR.
* €500,000 for the violation of Article 5(1)(c) GDPR.
* €500,000 for the violation of Article 25(1) GDPR.
* €50,000 for the violation of Article 35 GDPR.

In order to determine the amount of the fine, the DPA took into account, as a mitigating factor, the lack of recidivism and reiteration.

As aggravating factors:

* The fact that the fine needs to be effective, proportionate and dissuasive. The size of the company (more than €25,000,000,000 revenue in 2019, 90,000 employees and 1,636 shops) was taken into account in this regard.
* The nature, gravity and duration of the infringement, taking into account that the processed data entail special categories of data and the volume of data that were processed, including data from minors and vulnerable persons. The DPA remarked that the processing was carried out in a remote, massive and indiscriminate way.
* The fact that Mercadona did not make a prior consultation to the DPA, regardless the risk of the processing to the employees' and clients' rights and freedoms.
* The fact that Mercadona was a controller and had full responsibility on deciding about the processing.
* The fact that the processing entailed a systematic and exhaustive processing of special categories of data.
* The fact that the DPA had to know about the processing via two complaints not related to the controller.
* The continuous nature of the infringement, since the processing was carried out from 1/06/2020 until 6/05/2021.
* The link between the controller's business activity and the processing of personal data.
* The fact that the processing affected children's personal data.",NONCOMPLIANT,"Article 5, Article 6, Article 9, Article 12, Article 13, Article 25, Article 35, Article 57, Article 83","[21,41,35,13,25]"
"Caixabank, a Spanish bank, is the controller in this case. In 2019, some of the bank's customers complained to the Spanish DPA (AEPD) stating that the bank was asking them to accept the consent terms for processing personal data through pre-ticked boxes. If the data subjects did not accept the terms, the bank would charge them a fee of €5 per month for the bank account's maintenance.

The AEPD opened an investigation and sought details from the bank regarding its privacy policy and advertising carried out for certain categories of bank accounts. The AEPD also physically inspected the bank for further investigation.

In their defense the bank stated that the fee is not a charge, just a necessary fare for the providing of banking services to its customers and is, therefore, an essential element of the contract. The bank added that the exemption from the fees was a benefit given to interested parties, and also an essential element of the contract.

According to the bank, Article 7(4) GDPR is not applicable to this case, since the terms of the contract do not mandate a condition, and consent for the processing of personal is not a must-have for signing the contract with the bank. It argued that a customer not consenting to the processing of personal data gets the same services that are being offered to a customer who has given their consent for the processing, and that customers were free to choose other banking products offered by the bank which were exempt from fees.","The AEPD established that during a certain period, for new customers who chose a particular type of bank account, the consent acceptance fields were pre-ticked, In the AEPD's view, linking an exemption from fees to the provision of obtaining consent for the processing of personal data would mean that the consent was not given freely, since not giving consent entailed the payment of maintenance fees, which were detrimental to the data subject.

In addition, the AEPD held that these charges cannot be considered an inherent element of the contract, and were at odds with the national law regarding payments for bank services (Real Decreto-ley 19/2017 de cuentas de pago básicas, traslado de cuentas de pago y comparabilidad de comisiones), which establishes that fees for basic bank accounts need to be freely agreed upon between the customer and the bank. The AEPD found that in this case, because consent could not be considered as being freely given, then the fees could also not be considered as freely agreed upon by both parties.

The AEPD also noted that the bank's arguments related to the offering of different banking products were not relevant in this case, since these other products had different requirements based on, inter alia, customer's economic conditions, minimum purchases per month, insurance contributions and holdings into investment funds. The AEPD also established that linking processing of personal data with a waiver of fees could not be considered analogous to loyalty program.

The AEPD held that in this case, the two legal bases for the lawful processing of personal data (ie. consent and performance of a contract), were merged or blurred, in violation of Article 7(4) GDPR. Based on these considerations, the AEPD issued a €2,000,000 fine against Caixabank for infringing Article 6 GDPR in relation to Article 7(4) GDPR by imposing conditions based on obtaining consent for the processing of personal data, for purposes that were not necessary for the performance of a contract. It also fined Caixabank an additional €100,000 for requesting this consent through pre-ticked boxes, in violatoin of Article 6(1) GDPR.",NONCOMPLIANT,"Article 6, Article 7","[49,32,19,27,9]"
"The Banco Bilbao provided clients with ‘Affinity Cards’, which are a credit cards that could be used only within an affiliated group of several stores and companies. In this regard, any person calling the automated information hotline provided by the bank was able to obtain details of the last transactions of a card in exchange of the card-holder's ID-number.

In the abstinence of other security measures to confirm the identity of the client, any person could call into the automated systems to obtain financial information only by giving the ID-number without verifying that they are the real owner of the document.","The AEPD decided that the bank thereby failed to adopt security measures, violating the principle of integrity and confidentiality according to Article 5(1)(f) GDPR and the necessity to implement technical and organizational safeguards from Article 32 GDPR. Accordingly, only asking for the ID-number is insufficient to appropriately authenticate the client in question.

Considering the number of clients affected, the solvency and the high degree of responsibility of the entity, the DPA imposed a fine of €200.000 on the bank. However, the fine was finally reduced to €120.000 because of prior voluntary payment and their acknowledgment of responsibility.",NONCOMPLIANT,"Article 5, Article 32, Article 83","[9,13,28,41,12]"
"The Spanish DPA (AEPD) initiated proceedings exercising its investigation powers under Article 58 GDPR against Ramona Films S.L. (previously Kalandrakas Films S.L.), owner of https://www.putalocura.com, a website containing adult and pornographic material. The investigation was related to the possible processing of personal data and profiling of data subjects below the age of 14. In particular, the AEPD inquired the controller regarding the risk of processing activities that could take place if a minor gained unauthorised access to the website’s contents, a data protection impact assessment related to these risks, the technical and organisational measures implemented to ensure data protection, as well as its privacy policy.","In its investigation, the AEPD determined that the page contained a warning that the website contained adult material, and to abandon the website in case of being a minor.

However, the AEPD found that the website did not have a mechanism that permitted the rejection of non-essential cookies, or a second layer to allow the granular acceptance of specific cookies. Additionally, the AEPD also found that when accessing the website, the use of non-essential cookies took place without prior consent, and that there was insufficient information related to the nature of the cookies, and if any of them were third party cookies. The AEPD held that the website’s cookie policy violated Article 22.2 of the Spanish Law of Information Society Services (LSSI), which establishes that clear and complete information on the use of cookies and the purposes of the data processing must be provided to data subjects, and that where the use of a cookie entails processing that makes it possible to identify the user, data controllers must provide users with information in compliance with the provisions of the GDPR.

Furthermore, the AEPD found that the website’s privacy policy referred to the previous data protection laws in Spain, which were derogated when the GDPR entered into force. Therefore, the AEPD held that the website did not provide users with adequate data protection information, in violation of Article 13 GDPR.

Based on these considerations, the AEPD issued a total fine of €10,000 on the controller, €5000 for the violation of Article 22.2 LSSI and €5000 for the violation of Article 13 GDPR. However, this fine was reduced to €8000 because the controller did not object to the fine and paid it voluntarily within the period established by the AEPD to do so, although the reduction of the fee paid for by the controller did not include an express acceptance of culpability regarding the violations held by the AEPD. The AEPD also ordered the controller to modify its privacy and cookie policy in order to comply with GDPR.",NONCOMPLIANT,Article 13,"[48,25,12,28,2]"
"The Spanish police notified the Spanish DPA (AEPD) that a private individual had placed security cameras facing public and private spaces in the surroundings of their property. The police report stated that they had warned the individual that the cameras should not be pointed in the direction of areas beyond their property, and that there was no sign posted with adequate information related to the functioning of these video cameras.

Despite the police’s warnings, the individual refused to redirect the cameras, or to place the appropriate sign with information required under GDPR. The AEPD therefore initiated proceedings in order to investigate the issue, and bring the individual into compliance with their obligations related to the use of security cameras under GDPR. The individual did not submit any allegations or proof to contradict the police report, and also ignored the AEPD’s request for information related to their compliance with GDPR on this matter.","The AEPD held that according to Article 22 of the Spanish Data Protection Act (Ley Orgánica de Protección de Datos Personales y Garantía de los Derechos Digitales – LOPDGDD), security cameras can be installed in order to preserve the safety of persons and property, as well as the security of premises, but that recording of public streets is only permitted to the extent that it is essential for these purposes. Additionally, the AEPD held that any recording of private premises cannot take place without consent.

Morever, the AEPD held that when installing video cameras, the information requirements under Articles 12 and 13 GDPR  must be fulfilled by placing  a sign in a sufficiently visible place which announces that the video processing of personal data is taking place, the identity of the data controller, and the possibility for data subjects to exercise the rights provided for in Articles 15 to 22 GDPR.

Since the individual did not submit any defense in order to justify why the cameras were pointed towards the street and adjacent private areas, the AEPD issued a fine of €1500 against the individual (€1000 for a violation of the data minimisation principle under Article 5(1)(c) GDPR, and €500 for a violation of the information requirements under Article 13 GDPR). Additionally, the AEPD ordered the individual to either take down the cameras, or to redirect them facing his property and place a sign containing the aforementioned information requirements.",NONCOMPLIANT,"Article 5, Article 13","[49,29,17,48,27]"
"In July 2020, the AEPD initiated an investigation after becoming aware of the dissemination, through a social media network (Twitter), of a video that showed images that could constitute a gender-based violence crime. The video was accompanied by a message aiming to raise awareness about violence perpetrated against women.

Although the video was also disseminated by the media, they pixelated the the faces of the victims. However, in the video that was retweeted by the individual against whom the investigation was launched, it was possible to identify the victim of gender-based violence as well as her child. Considering the facts, the AEPD contacted the individual (controller), requesting information about the origin of the video and why the faces of the victims had not been blurred.

Subsequently, the AEPD requested Twitter to remove the content from its platform to which Twitter responded that the Tweets were posted with the intention to raise awareness about violence against women, which is aligned with Twitter’s mission to facilitate public conversation. It further added that the content did not violate the Terms of Service of Twitter, the Twitter Privacy Policy, or the Twitter Rules, and will not be removed from the platform.

Nevertheless, later the AEPD could confirm that the content was labelled as sensitive without being removed from the platform.","The AEPD indicated that the physical image of a person constitutes personal data according with Article 4(1) GDPR therefore its processing falls within the scope of GDPR.

The DPA also analysed whether the controller had an appropriate legal basis for the processing of personal data, and concluded that as the video was recorded and published without the consent of the parties involved, there was no appropriate legal basis in place for the processing of personal data.

The AEPD held that there had been a breach of Article 6(1)GDPR, which was considered 'grave' because of the nature of the infringement, and fined the data subject €10,000, that was reduced to €6000 for voluntary payment and for the admission of guilt.",NONCOMPLIANT,Article 6,"[4,7,22,38,46]"
"On October 16th 2019, due to complaints from neighbours about the cameras facing the public space, the local police came to check the content of the recordings, but they were not allowed access to the images.

On December 18th 2019, the AEPD informed the company of the complaint and requested more information regarding the video surveillance system.

PLAY ORENES S.L. invoked article 22 LOPDGDD, which allows the capture of images of the public highway, in some cases, with the aim of preserving the security of people and goods.

From the inspection of the frames taken from the system's viewing monitor, which through 4 cameras facing the outside, it was verified that the entire width of the street was captured, as well as the vehicles parked.

It is also recorded as a proven fact that the claimant removed 3 of the 4 cameras facing outwards, following the claim. However, a camera has been maintained which captures images of the street and the parked vehicles.","The AEPD held that the installation of a video surveillance system under Article 22 LOPDGDD must always comply with the principle of minimization of data, set out in Article 5 (1) (c) GDPR.

The aggravating circumstance taken into account was: the intentionality or negligence of the infringement (Art. 83 (2) (b) GDPR); while as mitigating circumstances: the adoption of measures taken by the person responsible to mitigate the damage (Article 83 (2) (c) GDPR), collaboration with the Agency in responding to the complaint (Article 83 (2) (f) GDPR), not linking the activity of the offender to the processing of personal data (Article 76 (2) (b) LOPDGD), the non-existence of profits obtained as a result of the infringement (Article 76 (2) (c) LOPDGDD and, having the figure of the data protection delegate even though it is not obligatory for the company (Article 76 (2) (g) LOPDGDD).

Furthermore, the AEPD requested the company in question to prove that it had removed the camera that still recorded images of the street, in accordance with Article 58(2)(d) GDPR.",NONCOMPLIANT,"Article 5, Article 83","[33,7,38,35,34]"
"The Spanish DPA analyzed the possible unlawfulness of the installation of a video surveillance system composed of 3 cameras located outside a house in SANTA CRUZ DE TENERIFE, a system that could capture images of neighbouring areas of houses in a disproportionate manner, as well as an automatic door phone for private use outside the building, all without the corresponding authorization of the Neighbours' Community.

The authorization of the Homeowners' Association has not been accredited for the installation of the above-mentioned devices, having to comply with the requirements established by Law 49/1960 of 21 July on horizontal property (LPH). This law regulates that the installation of a video surveillance system by a private individual will require the authorization of the Community of Owners' Meeting both when it is planned to be located in a common area and when, even if located in a private use area, it is oriented towards surrounding common areas and captures - respecting, in any case, the principle of data minimization - tangentially these common areas.","The Spanish DPA has found that the facts of the present proceedings show that 2 of the 3 cameras installed by the claimant capture a disproportionate share of communal areas, neighbouring housing, and even public roads.

This situation is not covered by the exclusion set out in Article 22.5 of LOPDGDD as the capture of images that exceed the verification about the identity of people trying to access an address beyond the treatment ""carried out by a natural person in the exercise of exclusively private or domestic activities"" of Article 2.2.c) of the RGPD.

The same consideration must be extended to the video door entry system installed on the exterior wall of the Community, since its location cannot be compared to the video door phone installed at the front door of a house.

As this is a warning sanction, the AEPD gives the defendant a period of one month to correct the unlawful conduct.

The AEPD agreed to impose a warning sanction, according to the following facts:

-This is a private individual whose main activity is not linked to the processing of personal data -No recidivism can be detected since no more than one infringement of the same nature has been recorded within a year. And furthermore, because the respondent has shown a cooperative attitude with the Agency in replying to the request.",NONCOMPLIANT,"Article 5, Article 58, Article 83","[4,12,20,24,36]"
"The case refers to the processing carried out by four hospitals in the region of Castilla La Mancha. The Health Service was using an application for managing files. Due to wrong settings, the system exposed sensitive information to unauthorized personnel. The technical malfunction also overwrote different files resulting in the loss of and therefore lost over 400 files containing patient information.  The Castilla La Mancha Health notified the AEPD of the breach. In the course of the investigation, it was discovered that among other things, the Health Services had not carried out any Data Protection Impact Assessment.","The AEPD held that the Health Service infringed the data confidentiality principle under Article 5(1)(f) by ""improperly allowing access to the health data of 431 patients by unauthorised personnel"".  The AEPD also held that the respondents had failed to prove that they had carried out an adequate risk analysis or necessary data impact assessment as required by Article 35(3)(b). The AEPD also held that there had a been a violation of Article 32 because of a failure to comply with GDPR security measure requirements, such as ensuring a level of data security appropriate to risks for that data, and assessing the appropriate level of risk for certain processing activities. For all three violations, the AEPD issued the Castilla La Mancha Health Service with a warning pursuant to its powers under Article 58(2)(b) GDPR. The Authority ordered the Health Service to carry out a DPIA and bring its processing operations in line with the GDPR within six months, pursuant to Article 58(2)(d) of the Regulation.",NONCOMPLIANT,"Article 5, Article 32, Article 35, Article 58","[39,12,16,1,18]"
"The complainant had an outstanding debt with his neighbourhood community. After several attempts to notify the debt, the administrator of the community published the complainant's name, address, and amount owed on the community's notice board. The publication was allegedly justified by Article 9 (h) of the Ley 49/1960 de Propriedad Horizontal.","Article 9 of Ley de Propriedad Horizontal provides that: ""If a summons or notification to the owner cannot be made in the place foreseen in the previous paragraph, it will be understood that it has been made by placing the corresponding communication on the community notice board, or in a visible place of general use enabled for this purpose, with express diligence of the date and reasons for which this form of notification is made"".

The Spanish DPA held that the public sharing of the personal data on the notice board infringes the principles of integrity and confidentiality set forth in Article 5(1)(f) GDPR. In quantifying the fine, the Authority took into consideration different factors including the non-intentional nature of the infringement and the categories of data concerned. The controller was finally fined for Euro 10.000,00.",NONCOMPLIANT,Article 5,"[46,38,10,7,28]"
"A citizen brought to the attention of the AEPD that the website that the respondent used as a platform for the position of president of a professional association in Madrid in 2019, did not have a privacy policy or legal notice, and therefore could be in breach of the right to information of visitors to the website.

The website contained a form to collect personal data (name, telephone number, and e-mail address) from those interested in the project led by the defendant.

The respondent stopped the data processing when it was warned of the possible unlawfulness of the conduct, and the AEPD was able to verify that the personal data collection form had been removed.","The AEPD considered that, in the present case, it was sufficient to impose a warning sanction for breach of the duty to provide information on the processing of data, as set out in article 13 GDPR.

In order to determine the level of the sanction, the AEPD took into account the fact that this is a natural person whose main activity is not linked to the processing of personal data and that there is no evidence of recidivism, as there is no record of the commission of previous infringements.",NONCOMPLIANT,"Article 13, Article 83","[49,45,24,4,25]"
"A customer of the data controller filed a complaint with the Spanish DPA (AEPD), alleging that up to six phone lines had been opened in his name despite the data subject not having given his consent.

It was a fraud by which someone pretends to be a real client of the company - after obtaining their documentation - and calls the operator to contract voice or Internet products pretending to be that real user.

The situation also led to the inclusion of the customer who reported the operator in the files of ASNEF (Asociación Nacional de Establecimientos Financieros de Crédito), in whose records the customers of companies with outstanding invoices are stored.

Orange replied to the AEPD that the consent had been unequivocal and did not attribute falsity to the line registrations that have met the regulatory recruitment requirements","The AEPD considered that ORANGE ESPAGNE did not act with due diligence to identify the contracting parties. Therefore, it processed personal data without accrediting that it had the legal basis to do so.

Furthermore, it was not aligned with the principle of proactive liability, which consists of previously determining that it met the requirements for processing the complainant's data.

The fact that it was a non-intentional negligent action, that basic personal identifiers were affected and the continued nature of the infringement were considered aggravating factors, determining the amount of the fine in €80,000.",NONCOMPLIANT,"Article 6, Article 83","[30,49,35,44,31]"
"The complainant lodged a complaint with the AEPD about the installation of video surveillance cameras in the neighbours' doorway, from which several entrances to homes could be monitored, and believed that excessive and disproportionate use was being made of the video surveillance system in relation to data protection regulations.

The defendant responded that the installation of the video surveillance system was necessary to protect himself and his family from neighbourhood disputes caused by non-payment by his tenants.","The AEPD held that the video surveillance system was excessive in relation to the purposes alleged by the defendant. It imposed a warning sanction and ordered that the system should only be operational when the defendant or his family were living at the address where the camera was located.

Given that the defendant is a natural person, that there is no evidence of recidivism and that, furthermore, he has shown cooperation with the AEPD in repairing the possible damage caused, it was decided to impose a warning sanction.",NONCOMPLIANT,"Article 5, Article 13","[35,30,34,44,25]"
"The AEPD launched an investigation on Vodafone due to the high number of complaints received regarding unsolicited commercial communications. The AEPD found that 191 claimants held these complaints because Vodafone had sent the communications without previous consent or after they had exercised their right to object (mainly by soliciting to be included in the internal or general Robinson list), which would be an infringement of Article 21 LSSI (the Spanish Information Society Services Act). Additionally, the fact that Vodafone did not facilitate or gave an option to the claimants to exercise the right to object, and the unsolicited communications per se, supposed a breach of Article 48(1) LGT (the Spanish Telecommunications Act).

The AEPD also notes that Vodafone has already been sanctioned several times in a short period of time (2 years) for the same reasons, and that they however have not been able to rectify the infringing behaviour. The AEPD has continued to receive claims based on the same facts by a high number of data subjects.

The AEPD also discovered that there was lack of real, continuous, permanent and audited control of the processing operations carried out by the processors in which they relied to carry out part of their commercial actions. Many of the contracts or agreements performed between them were merely a checklist, and there was no further control or verification by Vodafone on whether they provided the adequate level of protection, measures and safeguards for the processing.

Additionally, it was also found that Vodafone contracted with a processor that would carry processing of data in Peru, therefore transferring data to a third country, without ensuring an adequate level of protection in any way, as the contract did not make any reference to any kind of mechanism related to international transfers of data.","The AEPD imposed on Vodafone the following sanctions, resulting in a record fine of € 8 125 000:

- A € 4 000 000 fine for the infringement of Article 28 GDPR: due to the hiring of processors who do not comply with adequate safeguards, and the lack of control by Vodafone on that;

- A € 2 000 000 fine for the infringement of Article 44 GDPR: due to the carrying out of international transfers without implementing adequate safeguards (first significant sanction by the AEPD for this reason under GDPR);

- A € 150 000 fine for the infringement of Article 21 LSSI: due to the sending of unsolicited electronic commercial communications;

- A € 2 000 000 fine for the infringement of Article 48(1) LGT + Article 21 LSSI: due to the making of unsolicited commercial calls, after several claimants having expressed their opposition or after being included in the general or internal Robinson list. Vodafone did not guarantee the effective exercise of the right to object.

The aggravating factors used to modulate the sanction are of special relevance in this case, taking especially into account the high number of complaints in a quite short period of time. Among the aggravating factors used by the AEPD to graduate the sanctions, the following stand out:

a) The fact that the company had already been sanctioned with a fine or warning, from January 2018 to February 2020, in more than 50 occasions;

b) The fact that there were 161 complaints in a period of just two years;

c) The large number of marketing actions via telephone calls (around 200 000 000).",NONCOMPLIANT,"Article 28, Article 44","[31,35,45,38,21]"
"On 23 October 2019, a complaint was lodged before a court relating to the fact that the personal data of users have been falsified by Lycamobile or a mobile telephone establishment authorized by that entity.

The personal data of the users of the prepaid cards which are registered in the Lycamobile register do not correspond to the data of the person who acquires the prepaid mobile phone card.

In addition, it was indicated that the use of the personal data of a third person that is not related to the facts stated in the complaint, has caused the complainant serious non-consensual patrimonial harm.

On 17 March 2020, the AEPD initiated the sanctioning procedure, transferred the documents to the defendant, and the latter sent allegations.","The AEPD considered that the defendant company carried out the treatment without having any legitimacy to do so.  The personal data were incorporated into the company's information systems, without it being proven that the company had legitimately contracted, had its consent to the collection and subsequent processing of its personal data, or that there was any other cause that made the processing carried out lawful.

In setting the amount of the penalty, the AEPD took into account: the link between the business activity of the respondent and the processing of personal data (83 (2) (k) GDPR); the fact that basic personal identifiers are affected (83 (2) (g) GDPR); the intentionality or negligence of the infringement (83 (2) (b) GDPR) and the lack of cooperation with the Spanish Data Protection Agency (83 (2) (f) GDPR).

Therefore, in view of the aggravating factors applied to the case, the Director of the Spanish DPA imposed a penalty of EUR 60000 on the company Lycamobile S.L.",NONCOMPLIANT,"Article 6, Article 83","[33,21,3,17,49]"
"A client of the defendant provided the Guardia Civil (Spanish Police) with a notebook that the defendant had forgotten in his home when he was there for repairs.

The document-agenda contained a large number of notes from clients with their name, surname, personal identification number, divided by parish and containing in many cases the address and telephone number.

The client also presented an invoice for the services provided by the company of the respondent, which did not inform the interested parties about the data protection regulations and their rights as data subjects.

The defendant did not make any allegations at any time during the sanctioning procedure.","The AEPD held it has been proven that the complainant violated Article 6 of the GDPR, as he had illegally processed the personal data of the persons concerned, and there was no legitimate basis for the processing of personal data.

The facts claimed also provide evidence of the violation of the Article 13 of the GDPR, by not informing about the processing of personal data with the requirements and pronouncements established in the mentioned article, materialized in the emission of the invoice to its clients not informing in the previous sense.

Among the factors that the AEPD took into account when setting the amount of the penalty, the following stand out:

-The purely local scope of the treatment carried out by the defendant. -Many people have been affected by the offending behavior. -There is no evidence that the defendant has taken steps to prevent similar incidents from occurring in the future, as he did not respond to the request for information. -Although there is no evidence that he acted fraudulently, his actions reveal a lack of diligence. -The accused has not been sanctioned previously. -The accused is a natural person, autonomous. A high penalty could therefore cause him excessive damage to his small business accounts.",NONCOMPLIANT,"Article 6, Article 13, Article 83","[39,33,11,31,8]"
"The complainant stated that he called Naturgy's commercial attention telephone number to ask for a price estimate of the air conditioning installation in their home.  Naturgy took the complainant's personal data and he was told that he would be contacted shortly by the company collaborator of Naturgy.

The complainant was contacted by two companies which both presented themselves as Naturgy partners. It is recorded in the file that the company that the claimant chose was G.L.P. Instalaciones 86, S.L.

As the complainant had numerous problems with G.L.P. Instalaciones 86, S.L. because of the installation, he complained to Naturgy, and their answer was that they had not sent G.L.P. Instalaciones 86, S.L and that this company was not their authorized installer. Naturgy declared to the Spanish DPA that the claimed entity is not a collaborating company of this company and, that Naturgy did not communicate any customer data to it.

Therefore, it is not known how G.L.P. Instalaciones 86, S.L obtained the complainant's personal data.","The Spanish DPA held that the documentation in the file provides evidence that G.L.P. Instalaciones 86, S.L violated Article 6(1) GDPR, since it processed the personal data of the claimant (name, surname, NIF, telephone number, correspondence address, address of the object of the contract, bank account, email), without a legal basis for processing it.

In this case, it was taken into account as an aggravating factor that there has been no cooperation by the complainant with the agency in order to remedy the infringement and mitigate its defects and that basic personal identifiers, as set out in Articles 83(2)(f) GDPR and 83(2)(g) GDPR, are affected.

In addition, the annual turnover of the company complained of was considered to be a mitigating factor, as set out in Articles 83(2)(k) GDPR and 76(2)(c) LOPDGDD.

Therefore, the Spanish DPA imposed a fine of EUR 60000 on G.L.P. Instalaciones 86, S.L.",NONCOMPLIANT,"Article 6, Article 83","[26,23,11,16,12]"
"ATPSA's union representative at ITP Aero in Aljavir had sent the electoral roll, which includes the data of the employees, by email to different people addresses inside and outside the company, without the consent of the employers.  The defendant did not make any allegations, nor did it demonstrate that it had fulfilled its proactive obligation to respect the GDPR when processing data.","For infringing Article 5(1)(f) GDPR, in conjunction with Article 72(1)(a) LOPDGDD, the Spanish DPA imposed the sanction of warning under Article 83(5)(a) GDPR.

The Spanish DPA required the claimed party to provide evidence within one month that appropriate technical or organizational measures have been taken to ensure adequate security for the personal data it is processing, including protection against unauthorized or unlawful processing and loss, accidental destruction, or damage.",NONCOMPLIANT,"Article 5, Article 83","[3,41,24,0,29]"
"The company has not provided to the Spanish DPA the information it requested in the course of an investigation following a complaint by Ms AAA. With the above-mentioned conduct of the respondent, the power of investigation that the Article 58(1) of the RGPD confers on the supervisory authorities, in this case, the AEPD, has been hampered.","The Spanish DPA imposed a fine of EUR 5 000 on the company under investigation, which was reduced to EUR 3 000 for the company's voluntary payment and acknowledgment of its responsibility for the facts (in turn waiving any subsequent appeal against the decision)",NONCOMPLIANT,"Article 57, Article 58, Article 83","[3,5,20,42,44]"
"In the context of a conciliation procedure, the Burgos City Council summoned the conflicting parties via email. In doing so, the Council did not use the BCC option therefore disclosing the email address of one of the parties involved and other personal data. The affected party filed a complaint with the Spanish DPA.","The Spanish DPA imposed a warning penalty on the Municipality of Burgos, under Article 83 (5) GDPR, for infringing Articles 5(1)(b) GDPR and 5(1)(f) GDPR. The Spanish DPA also requested Burgos City Council to prove within one month that it had adopted the necessary measures to comply with the principles of ""purpose limitation"" and ""integrity and confidentiality"" under Article 5(1)(b) and (f) of the GDPR.",NONCOMPLIANT,"Article 5, Article 83","[20,22,34,19,31]"
"The AEPD received a letter filed by the interested party against the respondent stating that on 20 March 2019, he addressed requesting information on the fingerprint clocking control in accordance with the provisions of the regulations on the protection of personal data, without having received a response to this request.

The AEPD initiated an investigation procedure, to which the City Council responded with a Security Document in which it reports in accordance with the provisions of the GDPR and points out, among other things, that the body used a fingerprint detection system to control presence and access to its facilities, which does not perform a biometric analysis at any time, but rather produces an identification algorithm based on a reading of several points of the personal fingerprint and that the algorithm data cannot be decrypted or disassembled by any unauthorized entity.

And in response to a new request for information, the Council sent a report including the impact assessment on the processing of fingerprint data for the control of employee presence.","The AEPD held that the facts complained of involving the violation by the City Council of the provisions of Article 13 of the RGPD, by not informing of the processing provided for in relation to the fingerprint clocking control.

As the investigated party is a public administration, the AEPD applies Article 77 LOPDGDD, according to which a warning sanction must be applied when the offence is committed by a public administration.",NONCOMPLIANT,"Article 4, Article 6, Article 9, Article 13, Article 83","[42,23,33,35,39]"
"A citizen filed a complaint with the AEPD after he was disconnected from his electricity supply at Endesa Energia and had been put in the name of another person at EDP without his consent. He was re-registered at Endesa, also without his consent, 15 days later.

EDP claimed to the AEPD that the complainant has not been their customer, so they did not have any data on him in their database.

Endesa argued that, in accordance with the guidelines of the National Securities Market Commission (CNMV), the company responsible for providing consent to the change of electricity supplier is the incoming company. In this case, therefore, it would be up to EDP to prove that the customer had given its consent to the processing of data.","The Spanish DPA held that the processing of data relating to electricity supply consists of processing personal data, and therefore they cannot be transmitted without the consent of the person concerned, or another legal basis where appropriate.

According to the case-law of the Spanish Supreme Court, the data called ""CUPS"" (""Codigo Universal de Punto de Suministro"") are encrypted personal data, since the identity of the resident can be ascertained through simple checks.

In this case, the aggravating circumstances (Article 83(2) GDPR) have been taken into account, namely, the fact that it was a negligent, unintentional but significant action and, furthermore, the evident link between the business activity of the person claimed and the processing of personal data of customers or third parties.

In view of the above, the Spanish DPA imposed a penalty of €50000 on EDP ENERGY S.A.U. for infringing Article 6(1) GDPR by processing personal data without a legal basis.",NONCOMPLIANT,"Article 6, Article 83","[4,9,16,18,33]"
"In December 2018 the Secretary and VP of a rare disease foundation resigned. They didn't hand over their computer files, documents and control for certain system accounts. The documents contained personal data processed by the foundation in its capacity of controller. In October 2019 the foundation notified the AEPD for the data breach.","The AEPD held that the facts revealed a violation of Article 33 GDPR. In particular, it noted that this provision ""explicitly establishes"" that security breaches posing a risk to the rights and freedoms of natural persons must be notified by the controller to the relevant data protection authority within 72 hours of becoming aware of the breach. Since the data in question included health data (such as patient diagnoses), a special category of data under Article 9(1), the AEPD concluded that in these cases a notification is always necessary. As a result, it concluded that the foundation was responsible for violating Article 33 GDPR, and issued it with a warning pursuant to Article 58(2)(b) GDPR.",NONCOMPLIANT,"Article 33, Article 58","[14,29,36,41,48]"
"The GCT’s 400 members received an email that includes personal data about a citizen (personal information about her private relationship, her home address, her pregnancy status). The email was originally sent to organise an assembly regarding the data subject. The data subject filled a complaint with the AEPD.","The AEPD found that the disclosure of her personal data to the 400 members violated Article 5(1)(f) GDPR. The AEPD stressed that Article 5(1(f) GDPR constitutes a basis for the ""proactive responsibility"" of the controller to demonstrate its compliance. The controller was fined € 3,000.",NONCOMPLIANT,Article 5,"[16,4,8,26,33]"
"Air Europa notified a data breach to the AEPD related to the unauthorized access to contact and bank cards information that affected to 489,000 data subjects and to 1,500,000 records. The unauthorized access was carried out via hacking and malware. One of the problems that were found in a posterior audit was the use of a weak password, among other vulnerabilities, some of which were technical, like the lack of a multi-factorial authentication system.

The bank cards data included the numbering, expiry date and CVV. These data of around 4,000 bank cards was used to commit fraud. However, Air Europa classified the breach as medium risk and decided not to inform the affected data subject, arguing that it would be impossible to identify all of the data subjects and that a public notification was not necessary because there was not a serious risk for the rights of the affected data subjects.

Additionally, the AEPD was notified of the data breach more than one month after Air Europa had knowledge of its existence (the data breach was notified by a banking institution to Air Europa on 17th October 2018; Air Europa notified the AEPD on 27th November 2018).","The AEPD, based on the posterior audits on the breach, concluded that there had been a lack of appropriate technical and organisational measures that derived in an inadequate level of security, and there had been therefore an infringement of Article 32(1) GDPR.

The AEPD remarks that the level of security for the protection of the data was not adequate by design and by default. They support this with the fact that Air Europa was not able to detect the data breach themselves, but they only had notice when they were notified by a banking institution.

The AEPD sanctioned Air Europa with a fine of €600,000:

* Due to infringement of Article 32(1), for the lack of appropriate technical and organisational measures and of an adequate level of security, the fine was €500,000.
* Due to infringement of Article 33, for the delay of more than one month in the notification of the personal data breach, the fine was €100,000.",NONCOMPLIANT,"Article 32, Article 33","[1,27,33,34,18]"
"On 14 January 2020, the Subdirectorate-General for Nationality and Civil Status notified the Spanish DPA (hereinafter AEPD) of a security breach of personal data dated 22/11/2019 after becoming aware through an e-mail by a citizen of notification of granting of Spanish nationality corresponding to another person.

The notified security breach concerned 34 affected persons and subsequently incorporated 2 more, up to 36. These breaches all related to decisions of nationality being unduly shared with third parties. The security breach was communicated to the interested parties on 16/01/2020.

The security gap had its technical origin in a modification in the process of generating decisions to grant nationality by residence that had been made in the application for processing nationality by residence files.","The Secretary-General for Innovation and Quality of the Public Justice Service (SGICSPJ) did not apply the appropriate technical and organizational measures to guarantee a level of security appropriate to the risk. This is evident as it has been proven that third parties had access to information reserved for the interested party (the applicant, a Spanish national) as a result of the malfunctioning of the new version of the application.

The AEPD considered Articles 25, 32 and 34 GDPR in relation to Article 5(1)(f) GDPR to have been infringed as a result of the security breach caused by the transmission of personal data to third parties in the processes of granting Spanish nationality and the residence permit of foreign nationals.",NONCOMPLIANT,"Article 5, Article 25, Article 32, Article 34","[26,11,6,9,27]"
"A member of the trade union representation committee distributed a census of the workers through a WhatsApp group, in which there were private non-corporate phones.

The data controller claimed that he did this so that employees could check whether their data were correct.

A worker, whose data had been disseminated in this way, complained to the Spanish DPA that the confidentiality of the processing had been breached.","The Spanish DPA held that were clear indications that the defendant infringed Article 5 (1) (f) GDPR, principles relating to processing with the duty of confidentiality.

This duty of confidentiality, previously a duty of secrecy, does have the purpose to prevent the leakage of data that is not consented to by the holders of the same.

Therefore, this duty of confidentiality is an obligation that does not only to the person responsible for and in charge of the processing but to anyone who any phase of the treatment and complementary to the duty of professional secrecy.

The fact that it was a non-intentional negligent action, that basic personal identifiers were affected, and that no subsequent prevention measures were carried out of the infringement was considered aggravating factors, determining the amount of the fine in €3000. This amount was reduced by the person responsible for benefiting from the corresponding legal reductions.",NONCOMPLIANT,Article 5,"[2,6,12,17,33]"
"A lawyer from the Cabrera y Gil law firm, sent a letter to a third company, providing the knowledge of the personal data and private address without the knowledge or consent of the data subject for that purpose, being that company totally unrelated to the applicant, without any corporate, labour or shareholder relationship or any other relation.

The law firm in question sent a reply to the AEPD's request for information, claiming that the procedure for security breach and/or leakage of confidential information and personal data of the company itself had been carried out.

They also justified that all processing of personal data was carried out for the purpose of providing legal defense and representation before the courts, as provided for in Article 24 of the Spanish Constitution. At the same time, they replied that the protection of information has been carried out in a correct manner, respecting the three basic principles: confidentiality. integrity and availability.

From the law firm, they defend that the processing of data serves a legitimate purpose as set out in Article 6 (1) (f) GDPR, since it is necessary to carry out their work of defence and legal representation.","On 20/07/20, the Director of the Spanish Data Protection Agency agreed to initiate sanctioning proceedings against the entity complained of for failing to comply with the provisions of the regulations in force and imposing on the entity complained of a sanction of EUR 2000  (two thousand euros) for the infringement of Article 6 of the RGPD.",NONCOMPLIANT,Article 6,"[17,24,26,29,11]"
"The complainant sent a complaint to the Castilla y León Basketball Federation (FEDERACIÓN DE BALONCESTO DE CASTILLA Y LEÓN) and this organization shared his personal data without his consent.

On 30 August 2017, the complainant filed a complaint with the AEPD against the FEDERACIÓN DE BALONCESTO DE CASTILLA Y LEÓN for the disclosure without consent of his personal data via the Internet and a newspaper.

It was demonstrated that the FEDERACION de BALONCESTO de CASTILLA Y LEÓN sent the document with the personal data of the claimant, and therefore it is responsible for the violation of confidentiality when sending this document with the personal data of the claimant to a newspaper.","The AEPD considered that the conduct of the defendant's employees - sending personal data from a complaint - infringes Article 6(1) GDPR, by unlawfully processing the complainant's personal data, in relation to Article 5(1)(f) GDPR, which governs the principles of integrity and confidentiality of personal data, as well as the proactive responsibility of the data controller to demonstrate compliance. This is an infringement punishable under Article 83(4)(a) GDPR.

Assessing the circumstances that modify the responsibility contemplated in Article 83(2) GDPR, in this case, the aggravating circumstances for being a non-intentional but significant negligent action (Article 83(2)(b) GDPR), and for being data known as basic personal identifiers such as name and address (Article 83(2)(g) GDPR).

The AEPD set the amount of the administrative fine at € 3000.",NONCOMPLIANT,"Article 6, Article 83","[36,46,8,11,13]"
"The Mancoumnidad de la Comarca de Pamplona (MCP) launched a pilot project in certain districts for a new waste collection system that involved the use of magnetic cards that corresponded with different waste containers for regular and organic matter. Following the trial run, participating households recieved a letter from the MCP stating that they would be sent information with the opening details of the cards, including some points on improving their usage of the new waste management system.  The complainant, Ms AAA, filed a complaint with the AEPD claiming that the actions of the MCP violated her right to information under Article 14 GDPR, because the MCP had failed to inform the participating households that their data was being collected, what data the MCP was collecting and how it was being processed. The MCP refuted the claim on the basis that no processing of personal data had taken place, meaning GDPR obligations did not apply.","The AEPD decided that the material on the bins was in fact personal data, because the cards used postal addresses of natural identifiable persons.  Subsequently, the AEPD decided that Article 14 GDPR had been violated during the implementation of the pilot test, as the MCP did not provide the parties affected by the processing with the necessary information to be provided to data subjects where their personal data is not obtained from them in the course of the processing. The AEPD then issued the MCP with a warning under Article 83(5)(b) and pursuant to Article 58(2)(d) ordered the MCP to adapt its information provision policy on the magentic cards in order to make it Article 14 compliant.",NONCOMPLIANT,"Article 4, Article 14, Article 58, Article 83","[16,45,48,23,12]"
"BBVA sent the claimant's personal data to a collection agency. The claimant had no relationship with the debt, as he was no longer the administrator of the company for which the bank was claiming the debt. Even so, the claimant was receiving mail and calls from the company hired by BBVA to claim the debt.

BBVA failed to verify the accuracy of the data relating to the claimant and the debt incurred by the debtor company, and therefore the claimant could not request the deletion of his personal data held by BBVA.","The AEPD held that BBVA processed the complainant's personal data in infringement of the principle of accuracy.

The AEPD took into account, in determining the amount of a significantly serious infringement, the lack of diligence in the conduct of BBVA and the volume of business of the complainant, and the relationship of its habitual activity in the data processing.

BBVA made use of two reductions in the amount of a sanction: voluntary payment (20%) and acknowledgment of responsibility (20%). So they finally paid €36000 after the application of the reductions.",NONCOMPLIANT,"Article 5, Article 17, Article 83","[10,41,36,38,8]"
"A former IBERDROLA client complained to the Spanish DPA (AEPD) that the electricity supply company did not respond to his requests to delete his personal data.

The claimant moved house and informed the company of the change of address for notification purposes. Even so, the company continued to send letters to the previous address.

The claimant, in the same letter notifying the change of address, requested the withdrawal of his details due to the cancellation of the service, which was not answered due to the error in updating the claimant's details mentioned above.","The AEPD held that IBERDROLA had failed to update the customer's data and that this resulted in the inclusion of the complainant's data in a creditworthiness file and in a failure to comply with its obligations regarding the request for deletion of personal data.

The application of the GDPR is determined because the maintenance of the incorrect address constitutes a continuous infringement that continues over time as long as the data quality problem, which caused the infringement in question, has not been remedied.

Therefore, in the present case, there is an infringement of Article 5(1)(d) of the GDPR because no payment order was issued due to a data quality problem.

The AEPD took into account the fact that it was a non-intentional, but significant negligent action (Article 83(2)(b) GDPR) and that basic personal identifiers were affected (Article 83(2)(g) GDPR).

The economic volume of the company is also taken into account in the penalty scale.",NONCOMPLIANT,"Article 5, Article 17, Article 83","[41,38,20,46,27]"
"On 23 July 2020, a citizen reported to the AEPD a harassment campaign that the company RECAMBIOS VILLALEGRE S.L. carried out through Facebook and WhatsApp against a homeless person who, according to the company, had stolen money from the office cash register.

The aforementioned company used images collected with security cameras that recorded the street pavement, without having an informative poster on the premises that mentioned the use of these cameras.

The same complainant presented another letter on July 25, 2020 to the AEPD informing that several newspapers had reported the alleged theft, that a quick trial had been held and that the indigent person had been acquitted for lack of evidence, since none of the published images could prove that the person had taken money from the offices.

Once again, the company published images of the person on Facebook with the aim of negatively affecting their reputation.","The AEPD decided to impose, for infringement of Article 6 GDPR, a fine of € 10000 and, for infringement of Article 13 GDPR, a fine of € 2000.

In addition, the company was required, within one month, to remove the Facebook posting and the comments affecting the homeless person who was harassed, to put up an information poster of the recording of images with video surveillance cameras, and to have the information for those affected required by the GDPR.",NONCOMPLIANT,"Article 6, Article 13","[36,20,15,39,31]"
"On 25 February 2019, an individual filed a complaint with the AEDP against the Department of Education of the Government of Navarra regarding a survey conducted by his son in class, asking him about intimate, family, and personal issues.

The respondent stated that the purpose of the surveys was to guide and inform schools and families about the level of education acquired by the schoolchildren. Together with these surveys, context questionnaires were provided to obtain information on the socio-economic and cultural conditions of the schools in order to contextualize the results obtained.

The respondent also explained in detail the respective organic laws that justified the collection of these personal data of the students, in order to know better the conditions of the students. At the same time, it also described the security and confidentiality measures that were being followed to protect this information.

The Department of Education of the Government of Navarra replied to the decision to initiate the procedure, agreeing with the allegations of infringement of Articles 5(1)(a) GDPR and 13 GDPR. On the other hand, they disagreed with the infringement of Article 5(1)(a) GDPR in relation to Article 9(1) GDPR with regard to the question of the gender identity of pupils.","The Spanish DPA confirmed that the defendant collected specific personal data that was not necessary for the purpose in question. Therefore, if they could have achieved the same purpose without processing those data, there is no legal basis for processing them.

Consequently, the infringement of Article 5(1)(a) GDPR in relation to Article 9(1) GDPR is established. Article 13 GDPR is also considered to have been infringed as regards the information to be provided when personal data are obtained from the data subject.

The Spanish legal system has chosen not to penalize public bodies with a fine, as indicated in Article 77(1)(c) LOPDDGG, and paragraphs 2, 4, 5, and 6 of the same article.

In view of the above, the Director of the Spanish Data Protection Agency decided to impose three different warning sanctions: one for infringement of Article 5(1)(a) GDPR, another for infringement of the same Article 5(1)(a) GDPR in relation to Article 9(1) GDPR, and a third warning sanction for infringement of Article 13 GDPR.",NONCOMPLIANT,"Article 5, Article 9, Article 13, Article 83","[29,12,4,33,48]"
"The Territorial Delegation of the Department of Health and Families of the Regional Government of Andalusia filed a complaint with the AEPD against ORGANIC AND NATUR 03 S.L. on the issue of a membership contract that incorporates pre-determined clauses regarding data protection, thus preventing effective negotiation and the express consent of the signatory client.

In the aforementioned contract it was indicated that the client authorised the transfer of all his/her data for the purpose of managing the credit, as well as, to send him/her commercial offers.

The fact that different data processing purposes were being accepted in the same clause without express consent for each one could mean a breach of the duty to inform the customer of the purposes of data processing.","To determine the amount of the penalty, the AEPD took into account three criteria in Article 83(2) GDPR: unintentional negligence (paragraph b); the categories of personal data affected by the infringement (paragraph g); and the way in which the AEPD became aware of the infringement, which was reported by the complainant (paragraph h).

Account has also been taken of Article 76 (2) (b) LOPDGDD concerning the link between the activity of the offender and the processing of personal data.

In view of the above, a penalty of € 4000 was set for the infringement of Article 13 GDPR and a warning sanction for the infringement of Article 7 GDPR.",NONCOMPLIANT,"Article 7, Article 13","[5,7,1,18,26]"
"The complainant used the services of the defendant to download weekly menus. The complainant discovered days later that this company has used their personal data, full name and profile picture, and information about her cholesterol tests and her heart disease (hypothyroidism) to advertise their products, without her prior consent.

The Spanish DPA tried to contact the company in question and there was no response so the sanctioning procedure was initiated.","The Spanish DPA decided to impose a fine of € 3000 on the company in question for breach of data processing duties, as the complainant had not given their consent for their personal data or data on their state of health to be used for advertising purposes.

In this case, the aggravating factors applied are that it is an unintentional but significant negligent action (Article 83(2)(b) GDPR) and that basic identifiers such as name, surname, and address are affected (Article 83(2)(g) GDPR), including also health data, when reporting the claimant's cholesterol tests, and their illness (hypothyroidism).",NONCOMPLIANT,"Article 5, Article 83","[25,38,1,42,31]"
"On 13/12/2018, the Spanish Data protection Agency (AEPD) noticed several news published on three different websites, which revealed a cyber-attack to the servers of the website of the Spanish political party VOX.  This attack resulted in the access to the data (name and surnames) of about 30,000 subscribers of the entity's newsletter, and its later publication on a twitter account in a partially anonymized manner. VOX also published in its Twitter account the existence of the attack and reported it to the state’s law enforcement agencies. One day after these events, VOX disabled the attacked equipment, informed about the incident to the AEPD and communicated to all its members the existence of the said attack.

Subsequently, VOX contacted the hosting company 1&1 and the entity S21Sec, specialized in cyber security, ordering a report from the latter to analyze the causes of the security breach. In this report an automated basic security analysis was conducted and a total of 22 vulnerabilities were found, one being of serious nature (validation of input parameters) and two of a medium nature. The report concluded by stating that although the tools used by the attackers could not be 100% secured, it considered likely that the attack consisted of a SQL injection via system vulnerabilities. In that regard, S21Sec recommended a series of technical measures and an analysis in depth of the web since it considered that it could continue being the target of hacking and spying campaigns.

Furthermore, on 13/06/2019, VOX provided the AEPD with a document containing the measures adopted following the S21Sec report and on 12/10/2019 presented two reports from the entities HADOQ IT, S.L, and SERVYTEC NETWORKS, S.L., which showed that the vulnerabilities detected were resolved and stated that an optimum level of security was achieved.","The Spanish DPA held:

The imposition on VOX ESPAÑA, for an infringement of Article 32 of the GDPR, as defined in Article 83.4 of the GDPR, of a reprimand sanction. When deciding not to impose a sanction consisting of an administrative fine and to replace it with a reprimand sanction in accordance with article 58.2 b) of the GDPR, the diligence carried out by VOX with regard to the rapid communication of the security violation to the AEPD, the actions taken to minimize the negative consequences of the security violation, the fact that the vulnerabilities detected were resolved and the fact that the security level of the affected website was improved were all highly relevant elements. -

As for the debate on whether the leaked data should be considered special categories of personal data under Article 9 GDPR, AEPD stated that it does not consider them to fall within this category. However, it interestingly establishes that a combination of the leaked data and certain results of a search on the internet may result in a disclosure of a certain political ideology not consented to by the data subject. The AEPD stated that this possibility is a risk that must be assessed by the data controller when processing certain data with these characteristics. That increases the demand for the degree of protection in relation to the security, integrity and confidentiality of the data.",NONCOMPLIANT,"Article 4, Article 32, Article 33, Article 58, Article 83","[30,5,47,12,9]"
"Ayuntamiento de Arroyomolinos was found lacking a Data Protection Officer (DPO).

The defendant has since adopted corrective measures. A DPO has been appointed pursuant to a service contract from 28.09.2020.","The Spanish DPA recalled that the public administrations act as controllers for the processing of personal data and on some occasions as processors. As a result, they are subject to the GDPR and must fulfill all its obligations, including the obligation to appoint a data protection officer (Article 37 GDPR). This obligation had to be fulfilled starting from 28.05.2018, the date of entry into force of the GDPR.

The Spanish DPA issued a reprimand against Ayuntamiento de Arroyomolinos for violating Article 37 GDPR. The reprimand was issued by virtue of the power conferred by Article 58(2)(b) GDPR.",NONCOMPLIANT,Article 37,"[27,20,11,21,31]"
"A data subject sent a complaint to the AEPD against a plastic surgery clinic because he had received unwanted publicity on his phone number. The data subject tried to find in the website of the clinic information about who to address his complaint to but he couldn't find it due to lack of a privacy policy in the website.

The AEPD sent a request for information to the clinic and they replied that they provide adequate information to their clients upon collection of their data when the clients go for the first time to the clinic. The clinic argued that in the data sheet where the personal data is collected, the data subjects are informed that their data will be used also for sending them publicity (such as discounts, offers, etc.).

The AEPD checked the website of the clinic (three months after the answer from the clinic was received) and they found that both the privacy policy and the cookies policy were missing.","The AEPD decided to impose a fine to the clinic: € 2000 for the lack of the privacy policy and € 2000 for the lack of  cookies policy on the website. The absence of a privacy policy infringed Article 13 GDPR and the absence of a cookie policy infringed Article 22(2) of the Spanish law on the Information Society and Electronic Commerce Services (LSSI).

However, the fine got reduced due to:

1. prompt payment;

2. acknowledgement of responsibility (that includes the commitment of the company not to pursue any further appeal against the decision).",NONCOMPLIANT,Article 13,"[49,16,18,29,10]"
"On 9 July 2019, a citizen filed a complaint with the AEPD because he continued to receive emails from Vodafone regarding payments despite the existence of an Arbitration Award prohibiting him from continuing with these communications.

On April 2, 2018, the Galician Institute of Consumer Affairs issued an Arbitration Award stating that Vodafone must stop issuing invoices and that the complainant had caused the definitive cancellation of any type of activated service and that Vodafone must eliminate the complainant's data from any type of database.

On 25 September 2019, the claimant once again sent a letter to the AEPD stating that Vodafone continued to violate its rights by failing to comply with the arbitration award and the order of execution of the arbitration award dated 25 March 2019, issued by the Court of First Instance No. 3 of Pontevedra.

On February 24, 2020, the respondent (Vodafone) stated that the measures set forth in the Arbitration Award were fully executed. Nevertheless, due to a computer error, they continued to send invoice notifications.","The AEDP considered that the documentation provides evidence that Vodafone infringed Article 6 (1) GDPR since it processed the complainant's personal data without having any legitimacy to do so.

Aggravating circumstances were taken into account when setting the amount of the penalty:

-this is an unintentional but significant negligent action identified (Art. 83 (2) (b) GDPR).

-basic personal affected (Art. 83 (2) (g) GDPR).

-Actions previously committed, as this is not an isolated case as Vodafone had committed similar offences previously (Art. 83 (2) (e) GDPR)

-The continuous nature of the infringement attributed to the defendant (Art. 76 (2) (k) LOPDGDD)

For all the circumstances described, the amount of the penalty was set at € 70000.",NONCOMPLIANT,Article 6,"[28,37,13,1,10]"
"A claimant, an individual, lodged a complaint with the AEPD because he/she found out from his/her bank account that a contract had been entered into in his/her name and with his/her personal data without his/her consent, and also because he/she had been included in a creditworthiness file for an unpaid debt related to the aforementioned contract.

The AEPD requested from YOIGO information on the contracts signed with the claimant, as well as information on the debt that led to its inclusion in a solvency list.  In the contracts provided by the claimant, there is no signature of the claimant accepting the content of the contracts.

The AEPD first proposed a sanction for infringement of Article 6 (1) GDPR but withdrew these charges due to the non-existence of the infringement when the complainant responded with allegations and documents which this time, unlike those provided in the evidence phase, were signed by the complainant.

Furthermore, the complainant argued that the events had taken place before the entry into force of the GDPR and the LOPDGDD and would therefore not be the applicable rules. On the other hand, it did not make any reference in its allegations to the breach of Article 31 GDPR in relation to its obligation to collaborate with the data protection supervisory authority.","Having assessed all the various documents provided by the complainant, it seems fair to conclude that, in view of the circumstances of the case, it exercised a minimum and reasonable diligence in identifying the person who signed the contracts and provided as her own the NIE and the name of the complainant.

Furthermore, as regards its duty to cooperate with the supervisory authority, the defendant did not comply with its obligation to cooperate and make allegations regarding the infringement of Article 31 GDPR in conjunction with Article 58(1)(e) GDPR.

The AEPD, therefore, agreed to impose a penalty of € 20000 under Article 83(5)(e) GDPR.

The fact that it acted with an extremely serious lack of diligence when it repeatedly refused to cooperate with the inspection function that the AEPD was carrying out (83(2)(b) GDPR) and the link between the activity of the respondent and the processing of personal data of customers or third parties (83(2)(k) GDPR) were taken into account as aggravating factors.",NONCOMPLIANT,"Article 31, Article 58","[38,39,34,37,12]"
"The claim was initiated by an employer who, when he wanted to register a worker in the Social Security system and requested the reduction of the contribution, was refused on the grounds that the claimant was not up to date with his tax obligations, since the tax agency's files contained the notation ""fiscal offense"".

The Tax Agency recognized that the lack of updating of data was due to an error, and proceeded to solve and update the data processing systems.","The AEPD agreed to impose a penalty for infringement of Article 5 (1) (d) for lack of accuracy in the processing of personal data, due to an out-of-date data processing system.

As regulated in article 77 LOPDGDD it will be agreed that the sanction corresponds to a ""warning"" when the entity sanctioned is a public administration.

Furthermore, due to the updating of systems and other measures that have been carried out in the processes carried out by the sanctioned entity, the AEPD did not consider it necessary to impose other types of corrective sanctions.",NONCOMPLIANT,Article 5,"[37,14,10,18,36]"
"On June 24, 2020, the claimant filed a complaint with the Spanish DPA (AEPD) in which he indicated that Iberdrola Clientes, S.A.U (the defendant) had contacted him through his mobile phone on three occasions despite being included in the 'Robinson list' (a.k.a Do not Call Register).

The first contact was made on 19/06/2020 from telephone number 'T1' to promote an offer on electricity services, the claimant inquired about the call and was informed that his telephone number was included in a database.  The second, on 19/06/2020 (a few minutes later after the first call) from telephone number 'T2', during this call, the caller tried to obtain further personal data about the claimant. The third contact was made on 22/06/2020 again from telephone number 'T2' to offer new electricity discounts.

The claimant submitted along with his complaint a proof of being included in the ‘Robinson list’ since March 2010 as well as proof of ownership of the receiver telephone number.

The AEPD, admitted the complaint of the claimant in accordance with article 65 of the LOPDGDD and proceeded to transfer the claim to the defendant stating that it must respond within a month.

In response to the claim, the defendant stated that

(i) it had no records on the claimant

(ii) it did not own telephone number 'T2' nor it had been used to make marketing calls

(iii) the telephone number 'T1' did belong to one of its processors, however, the call must have been made as a result of a human error since the claimant’s telephone number does not appear on the marketing campaign list.","Based on the facts presented, the AEPD considered that the actions of the defendant infringed the following articles and laws:

* Article 21 GDPR – Right to Object
* Article 48(1)(b) of the Spanish General Law of Telecommunications (LGT) - Right to object to receiving unsolicited communications
* Article 23(4) of the Spanish Data Protection and Digital Rights Law (LOPDGDD) - Failure to consult the ‘Robinson list’ prior to contacting the claimant.

The AEPD held that this offense is considered as ‘minor’ in accordance with Article 78 (11) LGT which may be sanctioned with a fine up to €50.000 as per article 79 (b) of the same law. However, based on the evidence obtained from the preliminary investigation phase, the AEPD decided that a fine of €10.000 may be imposed.

In determining the amount of the fine, the AEPD applied the criteria provided in article 80 (2) LGT which takes into consideration the economic situation of the defendant.

Iberdrola Clientes S.A.U acknowledged its responsibility in accordance with Article 85 (1) LPACAP which resulted in a 20% reduction of the fine. Furthermore, it carried out the voluntary payment of the proposed fine before the resolution of the procedure, so an additional reduction of 20% was applied as provided in Article 85 (2) LPACAP.

Therefore, Iberdrola benefited from the two 20% reductions and paid €6000 instead of the initial €10000 proposed fine.

In accordance with the above, the AEPD concluded the sanctioning procedure against Iberdrola Clientes, S.A.U.",NONCOMPLIANT,Article 21,"[40,41,21,26,49]"
"On 19/03/2019 the AEPD obtained knowledge from an amplification of a report from the Judicial Police Brigade, UDEV group, of a presumed crime of fraud, where two hundred and ninety-five photographs of contracts of companies and contract type forms were intervened. In this regard, a claim was sent to A.A.A for to provide information to the AEPD (clarifying aspects like legitimate cause of the data processing, purpose or aims of the processing, the origin of the personal data processed and the measures adopted to prevent the commission of an infringement of the data protection regulation).

On 22//05/2019, A.A.A submitted a written reply to the request, stating that some of the alleged documentation (the one belonging to the companies Distritohogar and Grupo Confort Editorial) was being transported in his vehicle to be destroyed, in accordance with article 32.1 of the GDPR. In words of the written reply, the legitimacy of the data processing was supported by the execution of a contract and, in its absence, the unequivocal consent of the interested parties.  As regards to the purpose, the personal data was being processed for the management of orders of products. In relation with the origin of the data, it was stated that these were obtained from accessible sources to the public and the interested party itself. Finally, with regard to the security measures adopted, the controller stated that technical and organizational measures had been taken to ensure the appropriate use and processing of personal data (only the controller has access to the personal data, given his professional relationship with the companies as a self-employed freelancer).","Firstly the AEPD decided to initiate a sanctioning procedure against the A.A.A for an alleged violation of article 6 of the GDPR typified as an infringement of basic principles for processing in article 83.5 GDPR.

In determining the amount of the fine, the following aspects were taken into consideration: the merely local scope of the processing carried out by the A.A.A, the fact that numerous people have been affected by the infringing conduct, the fact that the actions were aimed at elderly people (whose defense capacity is minor), the negligent character of the actions and the fact that A.A.A is a natural person. These considerations led to the determination of the amount of the fine in EUR 6000.

However, two attenuating circumstances of the Spanish Law on Common Administrative Procedure of Public Administrations (Article 85) can be applied, which may respectively reduce the fine by 20%. The first mitigating factor is to acknowledge the responsibility within the time allowed for the submission of claims. The second mitigating factor is, at any time prior to the resolution of the proceedings, to make voluntary payment of the proposed penalty.  In this sense, on 03//03/2020 A.A.A proceeded to pay the sanction in the amount of EUR 3600, applying therefore the two previously mentioned reductions. This implied the recognition of their responsibility and the resignation to any action or appeal in administrative channels against the sanction.  After these events, the AEPD decided to terminate the procedure.",NONCOMPLIANT,Article 6,"[1,14,19,32,40]"
The local authorities filed a complaint with the Spanish DPA against the complainant for an alleged violation of the GDPR by finding scattered on the street medical examination reports concerning workers of the respondent.,The Spanish DPA found that the respondent is responsible for not having made decisions aimed at effectively implementing appropriate technical and organisational measures to ensure a level of safety appropriate to the risk to ensure the confidentiality of the data.,NONCOMPLIANT,"Article 5, Article 32, Article 33, Article 34, Article 58, Article 83","[20,27,43,49,7]"
"A Secondary School reported to the Spanish DPA (AEPD) that they had found that several minors had a assaulted another student, and that they had recorded the assault and subsequently posted it on Instagram. This led to the distribution of the video, that ended in several newspapers and digital media.

Following an investigation, the police was able to identify the minor that created the Instagram account and uploaded the video. Afterwards, the minor deleted the video and the account, that later could only be found on the media.

All the minors involved were prosecuted and condemned for the assault by a criminal court.","The AEPD concluded that the minor involved in the assault that had recorded such acts and uploaded the video to Instagram had infringed Article 6(1) GDPR, for processing personal data without a legitimate basis (namely without consent).

They decided to issue only a warning for this behaviour, given that the violation was committed by a natural person, that was also a minor. They considered that a fine would have been a disproportionate sanction.

They also ordered the minor never to process data without a legitimate basis again.

The AEPD also discussed the interplay between the right to data protection and the right to information that the minor could have by posting the video on Instagram, mentioning the fact that, according to Spanish case law, the right to one's own image and the right to data protection is not an absolute right. However, for any of those rights to be overridden, there must be a public interest that prevails, what did not happen in this case.

The authority also discussed whether a minor could be sanctioned by administrative law, as there is not such a clear legal framework on the subject as it exists in criminal law. They concluded that, for minors aged 14 onward, legal responsibility could be claimed, and therefore they can be sanctioned, even if their parents are co-responsible.",NONCOMPLIANT,Article 6,"[33,20,8,10,21]"
"Following a complaint against the mobile network operator Xfera Móviles, S.A.U., the AEPD ordered the controller to provide all information that was necessary for the AEPD to investigate the complaint. The controller did not comply.","The AEPD considered all aggravating and mitigating circumstances in this particular case and imposed the fine of EUR. 5,000.",NONCOMPLIANT,"Article 58, Article 83","[10,13,15,19,20]"
"The Spanish controller of the web page banderacatalana.cat, informs on its website that a minimum age of 13 is required to subscribe to the company newsletter and, at the same time, also informs that the legal basis for the processing of personal data is consent (Article 6(1)(a) GDPR) given while registering to the newsletter.  Article 8(1) GDPR establishes the age at which a minor can legally give consent at 16 and provides that Member States can set a lower age as long as it is not less than 13 years. Based on this article, the Spanish law on the protection of personal data (LOPDGDD), in its article 7, sets the age at 14 years.","The Spanish DPA found that wrongly informing on the age required for a child's consent to be lawful, was a violation of article 13 GDPR in relation to articles 6(1)(a) and 8 GDPR and article 7 of Spanish Law LOPDGDD.  For this reason, with the power conferred by article 58(2) GDPR, the Spanish DPA imposed a fine of €10000 aggravated by article 83(2)(b) GDPR (intentional or negligent character of the infringement) and article 83(2)(k) GDPR in relation with article 76(f) of Spanish Law LOPDGDD which refers to the affectation of the rights of minors. The Spanish DPA, with the power conferred by article 58(2)(d), also ordered the controller to delete the wrongful privacy policy from the website.",NONCOMPLIANT,"Article 6, Article 8, Article 13","[9,16,22,30,44]"
"On 23/05/2019 it was published in the newspaper ""Segre"" that the Medical Association of Lleida is investigating a possible breach of ethics for the use of medical data to send advertising of a political party in an election campaign.

On 26/06/2019 the claimant filed a complaint denouncing that he had received advertising from the political party ""PARTIT DELS SOCIALISTES DE CATALUNYA (PSC-PSOE)"" addressed to a ceased relative and who was a patient of a doctor related to the denounced political party.

The political party states that the doctor, who had run in the municipal elections and was a counselor at the Town Hall, brought boxes with sealed envelopes. The administrative staff of the Political Party proceeded to send them.","The AEPD considered that the conduct of the defendant's employees - the sending of electoral publicity using personal data from a patient-doctor relationship - infringes Article 5.1 b) of the RGPD, an infringement punishable under Article 83 (4) (a) GDPR.

Assessing the circumstances that modify the responsibility contemplated in Article 83 (2) GDPR, in this case, the aggravating circumstances for being a non-intentional but significant negligent action (Article 83 (2) (b) GDPR), and for being data known as basic personal identifiers such as name and address (83 (2) (g) GDPR).

The AEPD set the amount of the administrative fine at €5000 (five thousand euros).",NONCOMPLIANT,"Article 5, Article 83","[14,22,8,26,41]"
"A law firm filed a complaint before the AEPD on 29 July 2020 against a real estate company for failing to comply with the GDPR on its corporate website (www.higclffeestates.com).

The complaint was based:

1. Firstly, on the lack of information regarding the processing of data collected by the form of the website.
2. Secondly, on the fact that the image and personal data of one of the partners of the complainant's law firm was displayed without their consent.
3. Lastly, on the fact that the privacy policy of the company's website made reference to the derogated Data Protection Act from 1999.","The AEPD found that publishing the image of the data subject without his consent was a violation of Article 6 (1) GDPR, and decided to fine the controller €8000.

Secondly, the AEPD decided that the lack of the necessary information and making reference to the derogated Data Protection Act was a violation of Article 13 GDPR and issued a warning to the controller.

The AEPD took into account the following aggravating factors (Article 83 (2) GDPR) to determine the level of the sanction:

* It is an intentional negligent action (art. 83 (2) (b) GDPR).
* The AEPD became aware of the infringement through the complainant's filing of a complaint (Art. 83 (2) (h) GDPR).",NONCOMPLIANT,"Article 6, Article 13","[39,19,2,34,17]"
"At the end of November 2020, the DPA discovered that after loging to Apotheka e-pharmacy(apotheka.ee) it is possible to get acquainted with the personal identification code of any other person by entering the code given on prescriptions. Additionally, all the other person's unpurchased prescriptions were immediately displayed. AKI assessed the risk to data subjects very high, which is why it exceptionally used § 40 (3) of the Administrative Procedure Act (HMS)1 that grants the right to issue an administrative act without hearing the objections of the participant in the proceeding.

According to the appellant, the DPA violated the principle of definition when issuing a precept without setting a clear deadline.  Moreover, the DPA infringed procedural requirements by failing to hear the e-pharmacy. The appellant also believed the DPA had a misconception as to what would happen when entering a personal identification code.","According to DPA, the resolution was short and clear: to suspend the processing of personal data in question by e-pharmacies. As the DPA argued, no one would imagine a situation where you could enter the Internet bank account with another person's personal identification number and both view his bank statement and make some transfers. If such an activity were to take place, no one would be surprised if the DPA stopped it from day one. At the same time, the bank account balance is not a special type of personal data, unlike prescription data.

According to the DPA, the above-described process is fully automated. Even if the appellant claims that a pharmacist was needed to manually display the prescription information, this does not change the fact that the prescription information was displayed only on the basis of the personal identification code without any further checks.",NONCOMPLIANT,"Article 5, Article 6","[0,27,31,37,44]"
A police officer requested information about his future spouse and his family from a healthcare provider three times without any legal basis for doing so. A healthcare professional then researched the information and provided the police officer with it. This was in breach of both of their obligations towards privacy.,Both the police officer and the health care worker were fined for their inappropriate behavior and for their 'curious inquiries'. The police officer was fined €48 and the healthcare worker €56.,NONCOMPLIANT,"Article 5, Article 6","[0,2,21,25,41]"
"After a complaint from a data subject, the Romanian DPA started an investigation against the controller Actamedica SRL. The investigation found that the controller, a medical centre, has previously informed the data subject about losing their biological samples and a sum of money sent by a courier. When the data subject sent a request asking which other personal data has been exposed and if the national DPA had been notified, the controller suggested that the data subject contact the company lawyer and address any other complaints with the courier company.","During the investigation, the DPA found that the controller did not take sufficient security measures appropriate to the risk of processing. This lead to a security incident, in breach of Article 28(1) and 32 GDPR, for which the controller was fined RON 9,836.6 (approximately €2,000).

Additionally, the DPA found that it had not been notified with regards to the security incident, in breach of Article 33 GDPR, for which the controller was fined RON 4,918.3 (approximately €1,000).

Furthermore, the DPA found that the controller did not respond to the data subject's request asking which other personal data has been exposed, in breach of Article 12(3) and 15(1) GDPR, for which the controller has been given a warning.

Finally, the Romanian DPA applied two corrective measures on the controller, asking it to implement appropriate security measures and to answer the data subject request.",NONCOMPLIANT,"Article 12, Article 15, Article 28, Article 32, Article 33","[39,6,21,32,37]"
"Following a complaint filed by a data subject, the Romanian DPA started an investigation against Banca Comerciala Romana S.A. (the Romanian Commercial Bank) and found that the bank unlawfully processed the complainant's personal data without his consent. As result, the complainant was wrongfully assigned as a financial guarantor for a company and later was subject to enforcement proceedings executed by a bailiff.",Banca Comerciala Romana S.A. was fined approximately EUR 2 000 (RON 9 855.8) and a corrective measure was imposed in order to assure future compliance with the GDPR.,NONCOMPLIANT,"Article 5, Article 6","[2,19,32,33,38]"
"A data subject filed a claim before the Romanian DPA (ANSPDCP) against Condor SA, a parachute and military flight equipment manufacturer, claiming that it had disclosed the personal data (including data on salaries) of its current and former employees to an unauthorised person.","The ANSPDCP found that someone had gained unauthorised access to a document containing the personal data of current and former employees, which included, inter alia, name and surname, role, salary, bank account and personal identification number.

The ANSPDCP held that the controller had not implemented the necessary technical and organisational measures to ensure the confidentiality of its current and former employees' personal data, and did not prove to have adequately trained its personnel regarding the protection of personal data. As a result, the ANSPDCP held that the controller had violated Articles 32(1), (2) and (4) GDPR, and issued a fine of approximately €2000 (RON 9.897,4).

Additionally, the as corrective measures, the ANSPDCP ordered the controller to implement appropriate technical and organisational measures to ensure compliance with GDPR, including the adequate training its personnel, and also to contact the individual who was granted unauthorised access to the personal data to make sure they delete it.",NONCOMPLIANT,Article 32,"[39,46,49,14,35]"
"The ANSPDCP started an investigation against the controller Glove Technology SRL, after a data subject filed a complaint. The investigation revealed that the controller used CCTV cameras inside its offices to surveil its employees and record their conversations with the intention to use the recorded files against them.","The ANSPDCP found that the surveillance took place without a legal base as required by Article 6(1) GDPR. Moreover, the controller did not respect the lawfulness, fairness and transparency principle laid down in Article 5(1)(a) GDPR. As result, the controller was fined approximately €5,000 (RON 24,745). Furthermore, using their powers laid down in Article 58(2)(d) GDPR , the DPA required the controller to ensure that further CCTV surveillance will be in conformity with the GDPR, stop any data processing that was made through non-compliant CCTV systems, and delete any subsequent data that might have been collected unlawfully through the CCTV systems.",NONCOMPLIANT,"Article 5, Article 6, Article 58","[33,28,17,36,48]"
"A former employee of IAMSAT Muntenia SA exercised their right to object under Article 12 GDPR by requesting the company to stop processing their personal data, since their contractual relationship had ended. The company, however, did not answer or grant this request, prompting the data subject file to file a complaint with the Romanian DPA.

During the investigation, besides the facts concerning the data subject's right to object, the authority also found out that the company was conducting video surveillance at its workplace.","The Romanian DPA held that the company had violated Articles 12(3) and 21 GDPR by not handling the data subject's request to exercise their right to object. It also held that the company had not adequately informed its employees on the processing of their personal data through video surveillance at the workplace, in breach of Articles 12 and 13 GDPR.

For the former violations, the DPA issued a fine of approximately €1000 (RON 4.946,2) on the company, and for the latter, a fine of approximately €2000 (RON 9.892,4). Additionally, as corrective measures, the DPA ordered the company to inform its employees about its data processing activities conducted through video surveillance in its workplace, as well as to reply and resolve the data subject's objection request accordingly.",NONCOMPLIANT,"Article 12, Article 13, Article 21","[13,29,3,9,41]"
"The controller IKEA Romania organised a drawing contest for the children of 'IKEA Family' members. To join the contest, the legal guardians of the children had to upload the drawings, their consent, and participation forms. These forms included their own personal data (name, surname, city, country, email, IKEA membership number, and handwritten signature), and their children's personal data (name, surname, and age).

The drawings were then published on the online platform, to vote for the contest winner. However, in doing so, IKEA also erroneously published the participation forms, which included the personal data of the participants (children and their legal guardians). This data breach was then notified to the Romanian DPA.","The DPA started an investigation and found that the personal data of 114 data subjects (out of which half were minors) was erroneously published and left available online for 40 hours on the dedicated platform for 'IKEA Family' members. Hence, this affected the confidentiality of the personal data, in breach of Article 32(1)(b) GDPR and Article 32(2) GDPR. The DPA emphasised, referring to recital 38, that children need specific protection of their personal data, and fined IKEA Romania for approx €1,000 (RON 4948.8).",NONCOMPLIANT,Article 32,"[7,11,38,39,48]"
"A data subject made an access request asking to receive a copy of the video recordings from when they visited a Kaufland supermarket.

Kaufland refused to offer all the existent footage that included the data subject, arguing that disclosing such material would affect the rights and freedoms of the other individuals who were also captured in that video footage.","The Romanian DPA decided that a controller should take all the necessary technical and organisational measures when answering an access request to make sure the personal data and rights of others are not affected. The DPA suggested that, in cases like these, in order to provide the claimant with the personal data in their access request, this could be solved by blurring the image of other individuals appearing in the footage.

Therefore, the Romanian DPA held that Kaufland did not fulfill their obligation to grant the data in the claimant's access request in breach of Article 15(3) GDPR, and imposed a fine of approximately €3000 in local currency on the supermarket chain.",NONCOMPLIANT,Article 15,"[7,25,0,45,38]"
"A data subject submitted an access request regarding their personal data appearing in video recordings captured through the surveillance systems in Kaufland, one of the biggest retail shops in Romania. In reply to the request, the Kaufland failed to send the full copies with all the available recordings which captured the data subject's personal data. As a result, the data subject filed a complaint with the Romanian DPA (ANSPDCP), which initiated an investigation against the controller.","The ANSPDCP's investigation found that Kaufland indeed did not fully answer the data subject access request, since it did not provide a full copy of the records concerning the data subject, although they were available at the time requested. Therefore the ANSPDCP held that the controller had violated Article 15(3) GDPR, and consequently issued a fine approximately €2000 (RON 98889,4).

Additionally, as a corrective measure, the ANSPDCP ordered Kaufland to comply with the data subject's access request by providing the copies of all the available recordings that included their personal data, blurring the personal data belonging to other individuals within these recordings.",NONCOMPLIANT,Article 15,"[42,49,10,1,34]"
"A data subject filed a complaint with the Romanian DPA (ANSPDCP) against the Owners Association from Str. Soporului 17, Cluj-Napoca Municipality. The data subject claimed that images from the video surveillance system managed by the association  in which he appears, were posted on the Facebook group of the neighborhood where he resides.

The ANSPDCP launched an investigation into the matter, and requested information from the Owners Association. However, although the association confirmed the receipt of the notification, it did not answer the ANSPDCP with the requested information.","The ANSPDCP held that the association had violated the provisions of Article 83(5)(e) GDPR, in conjunction with the provisions of Articles 58(1)(a) and (e) GDPR by not granting the information requested, and therefore imposed a fine of €500 against the association The ANSPDCP also ordered the association to provide this information within working 5 days.",NONCOMPLIANT,"Article 58, Article 83","[9,22,4,40,12]"
"A data subject filed a complaint against S.C. Dreamtime Call S.R.L, alleging that their personal data (phone number) was unlawfully processed by a company in order to make several unsolicited phone calls. The Romanian DPA started an investigation against the Dreamtime Call. As part of the investigation, it ordered Dreamtime Call to provide certain information under Article 58(1)(a). Dreamtime Call had not responded to this request for information.","By not responding to the DPA's request for information, Dreamtime Call violated Article 85(3)(e) GDPR. The DPA fined Dreamtime Call approximately €2000 (RON 9.852,2), as well as ordered it to answer the DPA's request within five working days following the communication of the decision.",NONCOMPLIANT,Article 83,"[19,22,38,24,20]"
"Following a data breach, the controller S.P.E.E.H. Hidroelectrica S.A. (a supplier of hydroelectricity) erroneously sent the personal data of 325 data subjects to the wrong recipients. The data breach was reported to the Romanian DPA. The subsequent investigation clarified certain elements of the breach and revealed that the controller had been processeing the personal data of 3 data subjects who previously exercised their right to erasure and withdrawn their consent for the processing.","The Romanian DPA completed an investigation and found a breach of several GDPR provisions, for which it sanctioned the controller as follows:

- a fine of approx €5,000 (RON 24,739.50) for breaching the Article 32(1)(b) and Article 32(2) GDPR;

- a warning for breaching the Article 5(1)(a) and Article 6(1) GDPR;

- a corrective measure ordering the controller to update its technical and organisational measures to ensure a level of security appropriate to the risk of processing;

- a corrective measure ordering the controller to implement a measure that will guarantee personal data is accurate and updated according to the purpose of processing.",NONCOMPLIANT,"Article 5, Article 6, Article 32","[8,28,34,45,35]"
The Romanian DPA started an investigation against the news website SC Grupex 2000 SRL after a regional Social Assistance and Child Protection Agency  notified the DPA that video recordings of some of their hospitalised patients were published on its website.,"The Romanian DPA held that the publishing of these recordings constituted an unlawful processing of personal data in breach of Articles 6 and 9 GDPR, with reference to the principles in Article 5(1)(a), (b), (c), (f) and 5(2) GDPR. Based on these considerations, the DPA issued a fine of approximately €1000 (RON 4943.60) against the website.

Additionally, the Romanian DPA also ordered the website to implement appropriate technical and organisational measures to ensure compliance with GDPR.",NONCOMPLIANT,"Article 6, Article 5, Article 9","[8,12,23,42,49]"
"A data subject filed a complaint against  wholesale pharmacist SC Nobiotic Pharma SRL because they received unsolicited commercial SMS messages and had their data processed for direct marketing purposes without consent. The Romanian DPA launched an investigation, and requested SC Nobiotic Pharma SRL to provide information regarding its processing operations and access to the processed personal data.","SC Nobiotic Pharma SRL did not answer the DPA's requests. Consequently, the DPA imposed a fine of  approximately €2.000 (RON 9.890) for a violation of Article 58(1) GDPR.",NONCOMPLIANT,Article 58,"[41,30,45,15,21]"
"The controller is a medical clinic, the Medical Civil Society Policlinica Tommed. The  Romanian DPA started an investigation against the medical clinic after a complaint was filed by one of its patients. During the investigation, the DPA found that the clinic unlawfully disclosed the personal data belonging to a patient, including their health data, to another controller. Moreover, the patient was not informed of this.","The DPA found that the controller violated Article 5(1)(a), Article 5(1)(b), Article 5(1)(f), and Article 5(2), in conjunction with Article 9 GDPR.

First, the DPA held that there was no legal basis to process the sensitive personal data. Moreover, the principle of purpose limitation was also violated. Lastly, the DPA noted that the controller failed to implement appropriate measures to ensure security and confidentiality. The DPA concluded this since there was no regular training of persons that process the data for the controller, nor was the data protection officer properly involved in accordance with Article 37 GDPR, Article 38 GDPR, and Article 39 GDPR.

As result, the DPA imposed a fine of approximately €2.000 (RON9.898) on the controller. Moreover, the DPA applied a corrective measure, ordering the clinic to bring its processing operations into compliance to prevent further unlawful disclosure and to apply adequate security and confidentiality measures.",NONCOMPLIANT,"Article 5, Article 9","[9,13,31,44,49]"
"A client of the “Sabou, Burz & Cuc"" law firm filed a complaint with the Romanian DPA against the firm, claiming that it had posted a case file containing their personal data on an external WhatsApp group with other lawyers, without their consent. The DPA subsequently initiated an investigation on this matter.","The DPA's investigation found that the case file which included the data subject's personal data  (including name, surname, home address, and information regarding a case pending before a court) was indeed shared on the external WhatsApp lawyer group, which contained 247 members.

The DPA held that the data processing in this case was carried out without a valid legal basis, and that it was excessive, incompatible with the initial purpose of collection, and lacking the necessary technical and organisational measures meant to ensure data confidentiality, in breach of Articles 6, 5(1)(a), 5(1)(b), 5(1)(c), 5(1)(f) and 5(2) GDPR.

Therefore, the DPA issued a fine of approximately €1000 (RON 4946) on the law firm. As corrective measures, the DPA ordered the firm to notify the members of the WhatsApp group about the unlawful disclosure, to request that the group administrator erase the case file, as well as to train its personnel in GDPR compliance and avoiding future unlawful data disclosures.",NONCOMPLIANT,"Article 5, Article 6","[48,41,33,42,17]"
"When terminating the contract with Telekom, a previous customer withdrew their consent for data processing. After this, they were  contacted again by Telekom for marketing purposes and the complainant exercised their rights to opposition and erasure. Despite this, complainant was further contacted by the controller for marketing purposes.","The DPA warned Telekom for the processing performed without legal ground, breaching Article 6 GDPR, and fined it approximately €2,000 (RON 9,851.40) for contacting a data subject subsequent to his/her opposition request, breaching Article 21 GDPR.",NONCOMPLIANT,"Article 6, Article 21","[5,38,1,49,18]"
"The controller is Telekom Romania, one of the biggest telecommunication providers in Romania. The data subject is a customer of the controller. They filed a complaint with the DPA after the controller erroneously sent them e-mail invoices and notifications that were issued for another customer. The DPA started an investigation and found that the situation was caused because the controller collected inaccurate data from one of its clients. Moreover, the DPA found that the controller did not take necessary measures to enforce an erasure request pursuant to Article 17 GDPR.","First, the DPA held that controller violated Article 5(1)(d), Article 5(1)(f) and Article 5(2), because it collected inaccurate data and sent invoices and notifications containing personal data to the wrong recipient. For these violations, the DPA imposed a fine of approximately €5.000 (RON 24.745). Second, the DPA found that controller violated Article 17 GDPR because it ignored the data subject's erasure request. For this violation, the DPA imposed a fine of approximately €1.000 (RON 4.949). Hence, in total, the fine was approximately €6.000 (RON 29.694).

Additionally, the DPA applied two corrective measures. The DPA ordered the controller to bring its processing operations into compliance with GDPR by implementing efficient measures which would guarantee the accuracy of personal data at the moment of the collection. Moreover, it ordered the controller to comply with data subjects' erasure and rectification requests, by adopting effective technical and organisational measures which will guarantee the correct implementation of such changes.",NONCOMPLIANT,"Article 5, Article 17","[30,32,8,36,12]"
"The Romanian DPA started an investigation after the controller Vodafone Romania notified several security incidents that involved personal data.

One of the incidents occurred between 04.11.2020 and 22.06.2021. In this incident, the personal data belonging to 6 data subjects were disclosed without authorisation, since their contracts were sent via email to the wrong recipients. Moreover, the controller's employees also obtained unauthorised access to the individuals' data. Another incident that occurred between 04.11.2020 and 22.06.2021, allowed the controller's employees to have unauthorised access to personal data belonging to 64 individuals.","The DPA found a violation of two legal acts concerning the security of processing.

First, the DPA found that the controller did not implement sufficient technical and organisational measures to ensure that any person acting under its authority with access to personal data will act according to the controller's instructions, Article 32(4) GDPR. The controller also failed to implement necessary measures meant to ensure the confidentiality of data, Article 32(1)(b) GDPR.

Regarding the incident that occurred between 04.11.2020 and 22.06.2021, the DPA held that the controller did not implement sufficient technical and organisational measures to ensure that personal data will be accessed only by the authorised employees (Article 3(3)(a) of Law no. 506/2004), failing to ensure protection against unlawful processing, access and disclosure (Article 3(3)(b) of Law no. 506/2004).

The violation of the provisions of the GDPR was sanctioned with a fine of approx €1,500 (RON 7,421.25) and the violation of the national Law no. 506/2004 with a fine of approx €1,400 (RON 7,000).",NONCOMPLIANT,Article 32,"[34,16,14,40,35]"
The controller World Class Romania S.A. made available a resignation request of a former employee on the employees' WhatsApp group.,"The Romanian DPA held that the controller did not implement appropriate technical and organisational measures to ensure an appropriate level of data confidentiality, considering that all the members of the WhatsApp group had access to the personal data included in the resignation request.",NONCOMPLIANT,Article 32,"[13,30,33,24,11]"
"A data subject filed a complaint against a property owners association from the Municipality of Iasi after it disclosed their personal data. While the DPA conducted the investigation, the association did not cooperate in providing the requested information.","The DPA fined the Property Owners Association for failing to provide the requested information, in violation of Articles 83(5)(e) and 58(1)(a) and (e), and asked for the relevant information to be sent within five working days following the communication of the decision.",NONCOMPLIANT,"Article 58, Article 83","[9,15,33,41,47]"
"Copies of a data subject's pay slips (including name, surname, CNP, place of employment, position, and salary), and the registration records of a kindergarten including the personal data of a minor (name and surname) were shared by a natural person on their personal Facebook profile as well as distributed through flyers.","Following several complaints, the DPA started an investigation and decided that the natural person was a controller unlawfully processing personal data, including a child's data, in breach of Articles 5, 6 and 14 of the GDPR.

In particular, the controller had not presented evidence that it had legally processed the personal data in the payslip thus violating Article 5(1)(a) and (b), Article 5(2) GDPR and Article 6(1) GDPR.

Moreover, the controller had not presented evidence to show he had provided information to the data subject about the processing of personal data contained in the registration records, thus violating Article 14(1)-(4) GDPR.

The natural person was fined:

* approximately €100 for violating Article 5(1)(a) and (b), Article 5(2), and Article 6(1) GDPR;
* approximately €100 for violating Article 14(1)-(4) GDPR.",NONCOMPLIANT,"Article 5, Article 6, Article 14","[6,16,23,12,32]"
"The controller is a bank that, inter alia, provides internet banking services. The processor is Valoris Center S.R.L., a company that provides call center services on behalf of the bank. In their communication with a customer of the bank, an employee of Valoris had, by mistake, attached an excel file containing personal data of the controller’s customers who used the internet banking service. Hence, pursuant to Article 33 GDPR, the controller notified the Romanian DPA of a personal data breach.

In the course of the investigation, the DPA found that this breach led to the unauthorised disclosure and access to personal data. The excel file contained e-mail addresses, user names, user ID’s, telephone numbers, customer names, customer codes, customer PIN’s, of the bank’s customers. In total, 11,169 natural persons were affected by the incident.","The DPA held that Valoris did not fulfill its obligations laid down in Article 29, Article 32(1)(b), and Article 32(4) GDPR. Even if the employee of Valoris was not allowed to share the personal data with the customer, this data breach could only occur because of Valoris negligence. In particular, the processor had not taken adequate measures to ensure that any natural person acting under its authority could have limited access to the personal data. Hence, the security of processing was not guaranteed, ultimately leading to a personal data breach.

The DPA considered the different aspects of the case, such as the amount of data subjects involved, the categories of personal data, and decided to impose a fine of 9898 Leu (the equivalent of €2,000) on Valoris.",NONCOMPLIANT,"Article 29, Article 32, Article 33","[20,8,23,21,12]"
"The owners association of an apartment building had extracted an image of a data subject from its video surveillance system, and then posted the image on the notice board of the building. Furthermore, an application made it possible for the images to be accessed remotely through the internet.","The ANSPDCP first held that the processing of the image coming from the video surveillance system occurred unlawfully, as it breached Articles 5 and 6(1) GDPR. For this violation, the DPA used its powers under Article 82(5)(a) and fined the association with €500.

Second, the ANSPDCP held that the controller breached Articles 25 and 32 GDPR by not adopting adequate technical and organisational security measures to protect the personal data captured by the video surveillance system. For this violation, the DPA referred to Article 83(4)(a) and issued a warning. In addition, the ANSPDCP ordered the controller to adopt appropriate protective measures, such as deactivating the application that allowed the images to be remotely accessed through the internet and limiting the number of people who have access to the system.

Third, the DPA held that the controller breached Articles 12 and 13 GDPR by failing to adequately inform data subjects who were filmed by the video surveillance system of the association. In this context, the ANSPDCP made a reference to Article 83(5)(b) GDPR and issued a warning. In addition, the DPA also used its corrective powers and ordered the controller to provide data subjects, within 15 days and in a visible place, with complete information with regards to the personal data processing of the video surveillance system.",NONCOMPLIANT,"Article 5, Article 6, Article 12, Article 13, Article 25, Article 32, Article 83","[3,21,47,32,0]"
The ANSPDCP was notified that the the Association SOS Infertility processed personal data without consent and it initiated investigation. It ordered the Association to to provide information and allow access to personal data according to Article 58(1)(a) and (e) GDPR. The controller did not comply.,"Since the data controller did not respond to the ANSPDCP's orders, the latter decided to impose a fine of 9529.2 lei (approx. EUR. 2,000) and to order the controller to provide all requested information within 5 days.",NONCOMPLIANT,"Article 58, Article 83","[9,30,39,23,38]"
"The National Supervisory Authority conducted an investigation into the Romanian National Post Company, and found that it did not implement adequate technical and organizational measures (such as pseudonymization) when processing personal data. This resulted in the unauthorized access of personal data like email addresses and telephone numbers of 81 different data subjects.","The National Supervisory Authority held that there was a breach of Art.32 and imposed a fine of 9,686.60 lei, the equivalent of 2,000 euros.",NONCOMPLIANT,Article 32,"[3,5,16,25,37]"
"The Romanian DPA (ANSPDCP) received several complaints regarding a security breach of personal data, where an employee of the bank (the controller) had shared a statement about a customer (the data subject) on how they intended to use a certain amount of money that they wanted to withdraw from their account.

This statement was distributed among several other employees on their work e-mail addresses. One of the employees listed the email containing the data subject's statement as well as the email containing the internal conversation between the controller's employees. Another employee photographed the listed statement with his mobile phone and distributed it via WhatsApp. Subsequently, the listed text wasalso  posted and distributed on Facebook and on a website.

Overall, the disclosed personal data belonged to four individuals (one customer and three employees) and included first and last names, email addresses, work phone number, job title and location, work address, behavioral data, personal preferences and financial transaction value.","The Romanian DPA held that sharing the personal data violated Article 5(1)(f) GDPR and proved the ineffectivness of the controller's employee compliance training, in violation of Article 32 GDPR.

The DPA also noted that the controller did not take sufficient measures to ensure that persons acting under its authority (namely their employees) and having access to personal data only processed them at the request of the controller. Finally, the DPA also took into account that the disclosure of personal data in the public space (on the internet) generated a series of moral damages, as well as other significant disadvantages of an economic or social nature for the data subject affected.",NONCOMPLIANT,"Article 5, Article 32, Article 29","[23,30,3,6,32]"
"The Romanian DPA started an investigation on Lugera & Makler Broker S.R.L. (a data processor), following a complaint of the controller Raiffeisen Bank SA. One of the processor's employees destroyed some personal data and consequently, the processor was not able to provide the controller with the required documents. This caused a security breach that affected 1508 data subjects.","The DPA held that the processor did not take appropriate measures in order to make sure that any natural person acting under its authority who has access to personal data does not process them except on the controller's instructions. Additionally, the processor did not implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk of processing, especially to prevent data destruction.

As an effect, the processor has been fined RON 7 331,85 (approx EUR 1 500).",NONCOMPLIANT,"Article 29, Article 32","[28,26,33,41,25]"
"The controller ran an online contest on Facebook to attract customers. There, a document was posted which led to unauthorized viewing and access to the personal data of 436 customers of the controller on its website  and to unauthorized disclosure of this data, contrary to the obligations provided for in Article 32 GDPR.

The controller notified the DPA of the data breach.","Following an investigation, the DPA found that the controller did not implement adequate technical and organizational measures as it had to.

In addition to the fine, the DPA imposed the corrective measure to review and update the technical and organizational measures implemented so that they are up to the GDPR standards.",NONCOMPLIANT,"Article 32, Article 58","[24,11,47,30,23]"
"Billing information of the affected data subjects was wrongfully entered into a database and sent to a third party. In addition, the controller did not implement appropriate measures in order to prevent unauthorised access to data stored in the personal accounts of data subjects.","The DPA fined and applied additional corrective measures to Telekom Romania for failing to implement appropriate technical and organisational measures to ensure an appropriate level of security. The failure resulted in a data breach and unauthorised access to the data.

The infringement of Article 32 of the GDPR led to a €10,000 fine (RON 48,748). The infringement of Article 3 of Law 506/2004 led to a fine of €3,000 (RON 15,000).",NONCOMPLIANT,Article 32,"[48,9,49,4,45]"
"The Romanian DPA (ANSPDCP) received a complaint regarding the online availability of a document containing customers personal data. On the DADA CREATION S.R.L.'s website, the following personal data were made available: e-mail addresses, telephone numbers, first and last names of customers (adults and minors), age minors, delivery addresses, order number, total order amount, products ordered and date of order. Approximately 1091 individuals were affected.","The ANSPDCP found that the controller did not implement adequate technical and organizational measures to ensure a level of security appropriate to the risk of processing, which led to the unauthorized disclosure and access to personal data of approximately 1091 individuals who had placed orders on the operator's website. In addition to the applied fine of EUR 5000, the Romanian DPA issued a warning for not notifying the security incident and also applied the corrective measure to review and update the technical and organizational measures implemented as a result of the risk assessment for the rights and freedoms of individuals.",NONCOMPLIANT,"Article 32, Article 33","[26,9,6,27,48]"
"The Romanian DPA (ANSPDCP) conducted an investigation into ING Bank N.V. Amsterdam – Bucharest Branch and found that, due to a system error, the request to close a current account of one former client did not operate and the client was considered ""active"". Because of this error, the controller continued to process the former client's personal data.","The ANSPDCP found that the controller sent, to the e-mail address of a natural person, messages regarding the updating of his personal data, although the data subject had requested on 24.11.2017 the closure of the last bank product held (a current account). Due to a system error, the data subject was still registered as client and the controller processed the following personal data: e-mail address, name and surname, expiration date of the identity card.

The Romanian DPA found that the controller processed personal data in violation with the provisions of Article 5(1)(a-d)GDPR (the principles of: lawfulness, fairness and transparency; purpose limitation; data minimization; accuracy) and without fulfilling the conditions of legality of the processing, as provided in Article 6(1)GDPR.",NONCOMPLIANT,"Article 5, Article 6","[10,17,19,27,30]"
"A controller's contractual partner received from a controller's processor, on two different dates, files containing outdated information in order to issue insurance policies. As result, 270 individuals were affected.","The ANSPDCP found that the controller sent (through its processor) to a contractual partner, files containing outdated information. The data were outdated because the employees of the insurance policy monitoring department did not check and process the insurance policies in accordance with the working procedure. A number of 270 data subjects were affected because the technical and organizational measures implemented by the controller before the incident were not sufficient and led to the violation of the confidentiality of personal data.",NONCOMPLIANT,"Article 29, Article 32","[21,10,15,36,32]"
The Romanian DPA (ANSPDCP) received many complaints regarding the fact that the controller sent information by e-mail to 295 persons revealing the e-mail addresses of the other recipients. The data subjects were candidates who provided their personal data for recruitment on the operator's website or through online applications.,"The ANSPDCP found that the controller did not implement sufficient security measures to ensure the confidentiality of the personal data of data subjects, which led to the disclosure of e-mail addresses belonging to a number of 295 persons to other recipients, breaching the provisions of Article 32 GDPR.

In addition to the applied fine of €1000, the Romanian DPA applied the corrective measure of implementing appropriate technical and organizational measures in the case of remote transmission of personal data, including regular training of the persons that process personal data under the controller's authority (employees or collaborators).",NONCOMPLIANT,Article 32,"[16,1,20,46,2]"
"The DPA conducted the investigation after being notified that on the website in question, some personal data of the website's customers were visible. If customers placed an order on the website, some of their personal data could be accessed without authorisation.","The ANSPDCP held that the controller failed to take appropriate measures and breached the storage limitation principle enshrined in Article 5(1)(e) GDPR, and also failed to fulfill its obligation under Articles 25 and 32 GDPR.

Consequently, the DPA issued a €3000 fine and recommended the website operator to establish a shorter storage period for the personal data associated with the accounts of its customers.",NONCOMPLIANT,"Article 5, Article 25, Article 32","[11,16,20,37,49]"
"A company was using CCTV surveillance in order to protect its assets and to prevent theft. The monitored area included spaces like offices, cloakrooms, or dining areas where employees would normally work, but also spend their breaks and free time. The data processing was based on the employees' consent.","The DPA found that there has been a violation of Article 5(1)(b), 5(1)(c), 5(2), 6 and 7, considering that recording employees in spaces like cloakrooms, or dining areas was not necessary for the purpose pursued, and the same result could have been achieved through other measures less intrusive in the employees' private life.

In addition, the DPA found that consent cannot be considered a valid legal base in the context of the imbalanced relationship between employer-employee. Consequently, the controller was not able to prove the lawfulness of the processing.

Finally, a fine of RON 24.362,50 (approx €5000) was imposed, together with two corrective measures:

- the controller must implement the data minimisation principle in its data processing activities;

- the controller must adjust the monitored area in order to prevent surveilling the employees in the cloakrooms, or dining areas.",NONCOMPLIANT,"Article 5, Article 6, Article 7","[32,29,8,6,18]"
"The National Supervisory Authority conducted an investigation into Viva Credit following a complaint by a data subject claiming that Viva Credit had not complied with their request to have their data erased under GDPR Article 17. It was also alleged that Viva Credit did not provide the data subject with information on the actions they had taken as per their obligation under GDPR Art.12(3) and 12(4). Viva Credit had an obligation to respond to the request of the data subject without unjustified delay, and to notify them if they chose to not take action. However, Viva Credit did neither.","The National Supervisory Authority found that there had been a violation of the GDPR and imposed a fine of 9680 lei, the equivalent of 2000 Euro, on Viva Credit, along with corrective measures requiring that they send a response to the data subject within 5 days.",NONCOMPLIANT,"Article 12, Article 17","[19,46,15,49,8]"
"The Romanian DPA required information from C C&V Water Control SA to conclude an investigation. The defendant, however failed to provide such information upon request.","The Romanian DPA (ANSPDCP) held that by failing to provide information in the context of a request by the investigating DPA, SC C&V Water Control SA violated the GDPR.

The DPA highlighted that failing to provide such information upon request was in breach of Article 83(5)(e) in conjuncture with Articles 58(1)(a), 58(1)(e) and 58(2)(i) GDPR. It therefore imposed a €2000 fine on the defendant and applied corrective measures to get SC C&V Water Control SA to transmit all information required by the DPA.",NONCOMPLIANT,"Article 58, Article 83","[30,48,25,10,7]"
The National Supervisory Authority conducted an investigation into Tarom's security measures and found that Tarom had not implemented adequate technical and organizational measures to protect the personal data of its passengers. This led to the unauthorized access and disclosure of data belonging to five of Tarom's passengers.,"Tarom was fined 24,182.50 lei (approx. 5,000 Euros). Tarom was required to take corrective measures, such as undertaking risk assessment procedures, reviewing and updating their security, and training its employees.",NONCOMPLIANT,Article 32,"[10,28,44,35,16]"
"The data operator sent successive notifications of personal data breach to ANSPDCP which initiated an investigation.

The operator signalled unauthorized disclosure and unauthorized access to personal data such as: name and surname, ID number, home address, correspondence address, telephone and e-mail, respectively data on the health status, sent to individuals other than the recipients, to their e-mail or postal address.

Following the investigation, ANSPDCP found that the controller did not implement adequate technical and organizational measures to ensure that any natural person acting under the authority of the controller that has access to personal data only processes them at the request of the controller, which led to unauthorized disclosure and unauthorized access to personal data transmitted to individuals other than the recipients, on their e-mail address or postal address.","The Romanian DPA found a violation of Article 32(1)(b), Article 32(2) and Article 32(4) of the GDPR and fined SC Medicover SRL €2,000.",NONCOMPLIANT,Article 32,"[1,14,24,40,49]"
"In the context of an online event that it was organising, the data controller erroneously sent the login data of 1300 participants to other email addresses than the ones that the users had created their accounts with. The data breach led to the unauthorised disclosure of the names and email addresses of the data subjects.","The DPA held that the controller had breached its obligations under Articles 5(1)(f), as well as 32(1) and (2). As a consequence, the ANSPDCP issued an administrative fine of €2000 against Sanatatea Press Group S.R.L.",NONCOMPLIANT,"Article 5, Article 32","[32,7,36,47,19]"
The ANSPDCP conducted an investigation into Vodafone România S.A. and found that the controller could not demonstrate compliance and prove that it had fulfilled access and deletion requests.,"The ANSPDCP held that the controller failed to meet its obligations, as it could not prove that it had replied to or complied with the requests from data subject. The DPA therefore fined Vodafone €4000 for breaching Articles 12, 15, and 17 GDPR.

Furthermore, the DPA imposed the corrective measure of ordering the controller to adequately respond to the data subject who submitted the requests.",NONCOMPLIANT,"Article 12, Article 15, Article 17","[44,35,25,29,36]"
The ANSPDCP carried out investigation against the Romanian telecommunication operator Vodafone România SA. The company transmitted personal data to inaccurate e-mail address while handling a data subject's complaint.,"The ANSPDCP found that the company processed personal data without having implemented sufficient security measures. Thus it violated the principles of accuracy, integrity and confidentiality as laid down in Article 5(1)(d) and (f) GDPR read in conjunction with the principle of accountability according to Article 5(2) GDPR. The ANSPDCP imposed a fine of 14308.8 lei (equivalent to EUR. 3.000) and pursuant to Article 58(2)(d) GDPR it ordered the complany to put in place efficient technical and organisational measures within 30 days.",NONCOMPLIANT,"Article 5, Article 58","[7,34,38,48,49]"
"The Romanian DPA (ANSPDCP) received a complaint regarding the violation of the GDPR by the General Directorate of 4th District Local Police regarding the personal data processed using portable audio-video surveillance means. The ""BADGE"" surveillance portable device was used by the staff of the Local Police in missions and activities carried out in the field.","The ANSPDCP found that the staff of the General Directorate of 4th District Local Police were hierarchically obliged to wear audio-video surveillance devices (""BADGE"" type) during their working hours, without any legal provisions in force to govern the use of portable audio-video surveillance systems in the activity of local police officers. Therefore, the personal data (image and voice) were processed without a legal basis by using audio-video surveillance devices (""BADGE"" type). The Romanian DPA issued the warning because the controller processed the personal data (image, voice) without fulfilling the legality conditions provided in Article 6(1) GDPR. In addition, the ANSPDCP applied a corrective measure through a remediation plan according to which the controller must ensure the compliance of the processing operations, performed by using the ""BADGE"" surveillance portable device, with the provisions of Article 5 and Article 6 GDPR.",NONCOMPLIANT,"Article 5, Article 6","[18,6,35,8,7]"
"The Romanian DPA (ANSPDCP) received a complaint regarding the violation of the GDPR by the General Directorate of Local Police Cluj-Napoca regrading the personal data processing using the ""Body-Worn Camera"" (which processes image and voice).","The ANSPDCP found that the staff of the General Directorate of Local Police Cluj-Napoca processed personal data without a legal basis by using the portable audio-video system type ""Body-Worn Camera"". The controller did not have a legal obligation for the processing and did not fulfilled any other requirement of Article 6(1) GDPR.

The General Directorate of Local Police Cluj-Napoca started the non-compliant processing on October 2019 when the ""Body-Worn Camera"" recording system was used by local police officers in the exercise of their duties to record the following categories of interventions and actions:

a) establishing the identity of persons;

b) driving people to the local police headquarters;

c) using force and weapons;

d) performing body or luggage search;

e) stopping vehicles;

f) finding flagrant offenses and misdemeanors;

g) preventing of an imminent danger to the life, health and physical integrity of a person.

The Romanian DPA issued the warning because the controller processed the personal data (image, voice) without fulfilling the legality conditions provided in Article 6(1) GDPR. In addition, the ANSPDCP applied a corrective measure through a remediation plan according to which the controller must ensure the compliance of the processing operations, performed by using the portable audio-video systems of the “Body-Worn Camera” type, with the provisions of Article 5 and Article 6 GDPR.",NONCOMPLIANT,"Article 5, Article 6","[18,21,40,37,41]"
The energy company Enel Energie Muntenia SA was investigated after a notification sent by a customer to the DPA.,"The ANSPDCP found that Enel Energie Muntenia SA transmitted a client's personal data to the e-mail address of another client. The DPA decided that the controller did not have adequate technical and organizational measures in place to ensure a level of security that corresponds to the risk of the processing.

Thus, the controller violated the security of processing as required by Article 32 GDPR and the DPA imposed the fine of 14,423.7 lei (approx. EUR. 3,000) and ordered the controller to take the necessary measures within 30 days.",NONCOMPLIANT,Article 32,"[22,29,41,43,48]"
"The data subject filed complaint regarding a violation to their right to rectification against a bank. The DPA launched an investigation which over time broadened its scope towards the role of the bank's DPO. The investigation revealed that there might be a conflict of interest since the DPO held a number of other functions, including leading the bank's Operational Risk Management, the Information Risk Management department and Special Investigation Unit.

The bank argued that the head of these services did not have decision-making power to determine the purposes and means of processing of personal data, but a purely advisory and supervisory role.","The Belgian DPA refuted the bank's argument, stating that the role was not 'purely advisory and supervisory'. Particularly, the DPA held that the DPO could still determine the means and purposes of processing of personal data. This was further proven by the bank's Record of Processing Activities, which listed a substantial number of categories of personal data which are processed by these departments.

Thus, because the DPO held the final responsibility over the referenced departments, the DPA held that there was a conflict of interest, in breach of Article 38(6) GDPR.

In light of this violation, the DPA fined the bank €75,000.",NONCOMPLIANT,Article 38,"[24,29,32,38,30]"
"The Brussels South Charleroi Airport (the controller in that case) monitored passengers' temperature via thermal cameras between June and March 2021. All passengers with a temperature over 38°C detected by the camera had their temperature measured again manually by a medical service. Passengers suspected to be infected by COVID-19 were asked to leave the airport and were not allowed to board.

After having been alerted by the press, the Board of Directors  asked the inspection service of the Belgian DPA to investigate the matter. The inspection service sent its report with the alleged violations to the litigation chamber.","The DPA issued a fine of €100,000 against the controller (0.34 % of the 2020 turnover).

Additionally, the DPA issues a reprimand for non-compliance  with Article 30 GDPR.

1. Sensitive data

First, the DPA clarified that the processing of temperature of passengers via thermal cameras is a processing of sensitive data (health data) and the airport is the controller.

2. Legal basis

The DPA held that the airport relied on Articles 6(1)(c) and 9(2)(i) GDPR to process the data. Regarding Article 9(2)(i) GDPR, the DPA recognised that the the protection against COVID-19 was a matter of public interest in the area of public health. The DPA considered that no legal obligation existed since the protocol invoked by the controller to justify the processing was not legally binding and did not contain the obligation to conduct a monitoring of the temperature of the passengers. Moreover, the protocol was not precise enough regarding the purposes pursued and the circumstances of the monitoring. Additionally, it was not published and therefore not accessible to the passengers. The DPA also decided that the necessity was not demonstrated since the protocol itself referred to the recommendations of the European Union Aviation Safety Agency and European Centre for Disease Prevention and Control that considered that the temperature control was not proven to be efficient.

3. Transparency principle

The DPA also concluded that transparency principle was violated (Articles 5(1)(a), 12 and 13 GDPR). The fact that thermal cameras were used was not mentioned in the privacy policy or any other document. Also, the controller cannot rely on press articles to consider that passengers were properly informed. There was not reference to the exact and precise legal basis to which the airport referred as being basis for the legal obligation to monitor the temperature of passengers. The mere fact that the legal basis was available at the official journal is not sufficient (and such publication occured after the beginning of the processing).

4. Purpose limlitation

The DPA found that the purpose was, though explained, not sufficiently and explicitly defined, finding a violation of Article 5(1)(b) GDPR.

5. Obligation to conduct a data protection impact assessment (DPIA)

The DPA agreed with the inspection service and considered that a DPIA was required prior to the start of the processing operation. The fact that there was an alleged emergency is not exception to this obligation. The DPA also concluded that the quality of the DPIA was not meeting the requirements of the GDPR since the consequences and risks for rights and freedoms for the data subjects were not mentioned. The DPA concluded that the DPIA did not assess correctly the necessity of the processing. The lack of tools provided by the DPA for DPIAs is not an excuse to have a DPIA that is not meeting the requirements of the GDPR. Consequently, the DPA found a violation of Article 35 GDPR.

6. Security and integrity of the data

The DPA did not consider that the security of the data was compromised due to the low risk of illegal access to the images. It still advised to hold the password and the login to access the images in a different document (Articles 5(1)(g) and 32 GDPR).

7. Data protection by default and data minimisation

The DPA concluded that there  was no violation of Articles 25 and 5(1)(c) GDPR, since the images were deleted every day, no names of the persons were stored, and the period of storage of the images was limited to what was necessary to find a person in the airport.

8. Records of processing activities

The DPA considered that the record of processing activities (Article 30(1) GDPR) was not complete enough, considering that the categories of recipient were not mentioned in the record.

9. Involvement and independence of the data protection officer (DPO)

Finally, the DPA did not share the conclusion of the inspection service that the controller's DPO was not independent enough (considering the position of the DPO in the hierarchy of the controller). The fact that the DPO needs to report every two weeks to the legal director is not incompatible with the requirement of independence, as it is accepted that a DPO has to report to a superior. However, the DPA expressed concerns regarding the suspension of the activities of the DPO due to the crisis, which could prevent the DPO from being fully involved in the in all issues relating to the processing operations of the airport. The DPA thus did not find a violation of Article 38 GDPR.",NONCOMPLIANT,"Article 5, Article 6, Article 9, Article 12, Article 13, Article 30, Article 35","[29,37,38,7,36]"
"The inspection service of the Belgian DPA conducted an inspection on the temperature checks carried out by the Brussels Airport, as instructed by the Board of Directors of the DPA.

As a first step, the passengers' temperature was measured with thermal cameras. In a second step, all passengers with a temperature above 38°C were invited to be examined by a medical service, to carry out a diagnosis (performed by a doctor and using a form). The information was stored on paper and electronically and potentially shared for contact tracing.","The DPA issued a €200,000 fine against the airport for violation of Articles 5(1)(c), 6(1)(e), 9(2)(g), 12, 13(1)(c), 13(2)(e), 35(1), 35(3) and 35(7)(b) GDPR. It also fined the medical service €20,000 for violation of Articles 5(1)(c), 6(1)(e), 9(2)(g), 35(3) and 35(7)(b) GDPR. Finally, it issued a a reprimand against the airport for violation of Articles 5(2), 24 and 35(1) GDPR.

1. Controllership

The DPA concluded that the airport was the controller for the processing of data in the context of the first step. The airport and the medical service were considered as joint controllers for the second line of processing. The DPA considered that the qualification under the contractual agreement was not binding upon the DPA (in accordance with the EDPB guidelines on the same).

2. The legal basis (Articles 6 and 9 GDPR)

During the procedure, the airport stated that it relied on Article 6(1)(e) and 9(2)(g) GDPR for the processing.

The DPA considered that the decrees and the protocol on which the airport relied as a legal basis were not creating any legal obligation to check the temperatures of the passengers. Moreover, the texts the airport relied upon did not refer, as required by Article 6(3) GDPR, to the purpose of the processing,  to the description of the processing operations, nor did the text mention the measures to ensure a lawful and fair processing of the data. The DPA also noted that the airport itself remarked in its data protection impact assessment (DPIA) that no legal text provides for an obligation to carry out temperature checks.

Finally, the DPA found that the necessity was not demonstrated since the protocol itself referred to the recommendations of the European Union Aviation Safety Agency and European Centre for Disease Prevention and Control that considered that the temperature control was not proven to be efficient. Also, the alleged legal basis did not contain any reference to a duration or retention period.

The DPA concluded to a violation of Articles 5(1)(c), 6(1)(e), 6(3) and 9(2)(g) GDPR both by the airport and the medical service acting as joint controllers.

3.  Transparency and information

The DPA found that the lack of reference to the specific legal provision(s) that allegedly created a legal obligation amounts to a violation of Article 13 GDPR. The DPA also emphasised that the legal basis should be announced in the privacy policy and not during the procedure before the DPA. It further pointed out that the lack of mention of the consequences for the data subjects also violated Article 13 GDPR.

The same lack of transparency could also be observed regarding the medical service, but since these elements were not investigated by the inspection service, the litigation chamber did not conclude in this regard.

4. DPIA

The DPA considered that the DPIA was not carried out appropriately since some information was missing, such as a clear legal basis for the processing (the DPIA even identified the risk that no clear legal basis existed) and the lack of risk assessment in the DPIA.

It also considered that the procssing of data in the second step (by the medical service) was different from a visit to the doctor, considering that a legal decision would be taken on the diagnosis from the medical service.

Moreover, the fact that the number of potential passengers who could have been subject to the processing was unknown at the time of the DPIA does not affect this conclusion. In order to assess that the processing would be done at a large scale, it should have been considered that all passengers could see their data processed.

5. Competence and independence of the data protection officer (DPO)

The DPA did not follow the inspection report regarding the alleged lack of competence of the airport's DPO and did not find a violation of Article 37(5) GDPR.

Regarding the independance of the DPO, the DPA considered that the position of the DPO in the hierarchy and the collaboration with other privacy experts within the airport were not to be considered as a violation of Article 38 GDPR since it was not demonstrated that the DPO could not act independently.",NONCOMPLIANT,"Article 5, Article 6, Article 9, Article 12, Article 13, Article 24, Article 35","[16,0,28,48,41]"
"The ADP/GBA conducted investigations into a webpage for violations of Article 6(1)(a), 12 and 13 GDPR.","After having conducted investigations, the GBA submitted a report in June 2019 regarding several violations:

* The company’s privacy statement and cookie policy did not comply with the GDPR and the national law implementing the ePrivacy Directive.
* The policies did not contain transparent information regarding the data subject’s rights and their exercise. Thus, the GBA considered that the company violated Article 12 GDPR.
* The company did not provide information regarding the legal basis for the processing, the data subject's rights nor the retention period, and was, thus, in breach of Article 13 GDPR.
* No consent was gathered for the use of cookies regardless the entity who installs them on the user’s terminal equipment. Indeed, the user’s consent to the installation of cookies was obtained via pre-ticked boxes. Therefore, this practice was contrary to the national law implementing the ePrivacy Directive and Articles 6(1)(a) and 7 GDPR, in the lights of Article 4(11) and Recital 32 GDPR.

Following this report, the GBA issued a decision confirming that the company did infringe the national law implementing the ePrivacy Directive and the GDPR on the grounds mentioned above. As a consequence, the GBA fined the company € 15.000.",NONCOMPLIANT,"Article 4, Article 6, Article 7, Article 12, Article 13","[4,27,44,29,20]"
"The plaintiff, a data subject which had seen themself being filmed on the street outside of the data controller's store, lodged a complaint with the Belgian DPA. They presumed the footage to be recorded and therefore reported the absence of a formal information as required by data protection law. After formal inquiry, it was found that the CCTV system had not been declared to the data privacy commission (commission pour la protection de la vie privée, CPVP) as required by article 6 §2(1) of the national videosurveillance law and that the record of processing activities was lacking information.","After stating the conditions for a CCTV system filming spaces open to the public to be legal (declaration to the national data privacy commission (CPVP), article 6 §2(1) of the national videosurveillance law), the Belgian DPA holds that not only the absence of declaration but also the lack of information about the data processing in the record of processing activities results in a breach of the GDPR and the national videosurveillance law. The data controller had to both declare the CCTV system and establish a detailed record of the videosurveillance activities in accordance with Article 30(1) GDPR, despite employing fewer than 250 persons, because of the risk to the rights and freedoms of the data subject (article 30(5) GDPR).",NONCOMPLIANT,"Article 5, Article 24, Article 30","[16,20,22,34,45]"
"Following the notification of a data breach, the Belgian DPA started an investigation into the practices of the company regarding its notifications and data protection program. The data breach was not notified to the DPA but the DPA decided ex officio to start an investigation on the basis of a note prepared by the Complaint department within the DPA.","On the procedural aspects of the case, the litigation chamber noted that the report was asked by the Management Board of the DPA and then sent to the defendant before the litigation chamber adopted its decision. There was therefore no violation of the applicable procedure.

On the merits of the case:

- The Disputes Chamber assessed the Inspectorate's findings in the light of the defendant's duty to cooperate and found that the Inspectorate had not sufficiently demonstrated that the defendant had not attempted to provide comprehensive and detailed answers to the questions raised by means of letters of reply. In addition, the defendant stated on several occasions that it was prepared to enter into additional consultations, which did not make it possible to establish that it did not comply with the obligation to cooperate with the supervisory authority.  The Disputes Chamber is therefore of the opinion that no breach of Article 31 of the AVG can be established.

- The Litigation Chamber stresses that, contrary to the defendant's contention, there is indeed an obligation on the part of the data controller to document any data leakage, whether presenting a risk or not, in order to be able to provide information to the DPA. In view of this clarification provided at the hearing, as well as the fact that it appears from the documents in the file that the defendant, despite contesting the litigation chamber's power to request detailed information, accepted the request to clarify the assessment process in order to allow the chamber to examine how the defendant reached a certain conclusion on risk in a concrete file, in particular the incident at stake, the litigation Chamber notes that the defendant has explained its methodology and procedure on infringements and the assessment of risk. The litigation chamber is therefore of the opinion that no breach of Article 5.2 of the GDPR, Article 24.1 of the GDPR and Article 33 of the GDPR can be established.

- As regards the involvement of the Data Protection Officer, according to the defendant for the purposes of Article 38.1 GDPR, it would be sufficient for the DPO to be informed, as part of involvement, Since this provision does not impose the specific obligation to be consulted, contrary to what is stated in the inspection report. The Disputes Chamber is of the opinion that the defendant's position is not in accordance with the intention of the legislator and does not constitute a meaningful interpretation of Article 38.1 GDPR, which stipulates that the DPO shall be duly and timely involved in all matters relating to the protection of personal data'. By reducing the involvement of the DPO to merely (ex post) informing him of a decision, his function is eroded. The Litigation Chamber decides that, on the one hand, the defendant misinterprets the position of the Data Protection Officer, but that, on the other hand, it is plausible that, in practice, the Data Protection Officer is sufficiently involved. Therefore, no breach of Article 38.1 AVG can be established. The Litigation Chamber decides that, on the one hand, the defendant misinterprets the position of the Data Protection Officer, but that, on the other hand, it is plausible that, in practice, the Data Protection Officer is sufficiently involved. Therefore, no breach of Article 38.1 AVG can be established.

- As regards the Inspectorate's finding that there is a conflict of interest under the Data Protection Officer considering that he is also responsible for compliance, risk management and internal audit. This responsibility for each of these three departments clearly implies that that person in that capacity determines the purposes and means of the processing of personal data within these three departments and is thus responsible for the data processing processes falling under the domain of compliance, risk management and internal audit as identified in the inspection report. Moreover, cumulating of these functions may lead to an insufficient guarantee of secrecy and confidentiality vis-à-vis staff members in accordance with Article 38.5 of the GDPR. Consequently, the Disputes Chamber is of the opinion that the infringement of Article 38.6 AVG has been proven.

- Considering the above, the litigation chamber ordered the company to take measures to resolve the issue within a period of three months and imposes an administrative fine of €50,000.

The fine is appropriate considering the following:

- The concept of a DPO is not new and has existed in various Member States and organizations for many years;

- The company should have been prepared for the introduction of the DPO role, in particular, considering that its core business activity involves processing of personal data on a large scale, including data of a sensitive nature. The infringement could have an impact on millions of individual.

- The duration of the infringement, which started in May 2018 and lasted until February 2020.",NONCOMPLIANT,"Article 5, Article 31, Article 36, Article 38","[34,5,31,32,36]"
"Facts :

1/ The defendant is an autonomous provincial public entity working in the sector of tourism for the province of West-Flanders.

2/ The defendant decided to place intelligent cameras in order to provide a passer-by counts at specific locations in the context of the Covid-19 epidemic.

3/ To this end, the defendant issued a public contract on behalf of the coastal municipalities, which was awarded on June 9, 2020 to company X, which acts as processor.

4/ An investigation was launched by the DPA to submit a file to the Inspection Service since the serious evidence that the use of intelligent cameras by the defendant could give rise to an infringement of the fundamental principles of the protection of personal data.

The DPA's inspection states the following :

1) Infringement by the defendant of the principles of lawfulness, propriety and transparency as well as the principle of purpose limitation and the principle of data minimization and accountability.

The Inspectorate states first of all that the defendant does not adequately demonstrate that the data subjects are properly and transparently informed and that the defendant insufficiently demonstrates that the processing of personal data by the relevant intelligent cameras is for specific, explicit and legitimate purposes.

The defendant insufficiently demonstrates that the personal data processed by the intelligent cameras is adequate, relevant and limited to what is necessary for the purposes for which the data is processed.

2) Infringement of Article 6.1 GDPR.

The Inspectorate is of the opinion that the defendant does not demonstrate why it is necessary for the achievement of its mission of public interest to process personal data via intelligent cameras.

3) The Inspection Service determines that the information provided by the defendant through the privacy statement published on the website www.westtoer.be/nl/data processing is not completely correct and  transparent.

4) The Inspectorate determines that the DPIA made by the defendant does not comply with the requirements of the GDPR and that the Data Protection Officer was insufficiently involved.

The Inspectorate also makes a number of additional observations, outside the scope of the serious indications, especially:

- consent for the use of cookies on the website of the Defendant does not comply with the GDPR.

- the register of processing activities of the defendant does not meet the requirements of the GDPR

- the data protection officer is not is employed full-time and does not report directly to the highest level manager of the defendant.","Holding :

1) Sufficient legal ground for the intended processing.

A complete examination of the legal basis is not conducted by the litigation chambers which finds that the defendant makes a plausible case for performing a task of public interest.

The litigation chamber states that it is primarily the task of the authorities at whose request the processing operations are carried out take place - in this case the province of West Flanders and the coastal municipalities involved to ensure that a legal basis iexists that meets the requirements of article 6.3 GDPR.

This does not alter the fact that a controller as the defendant has the duty to ascertain the extent to which an adequate legal basis is provided. In this decision, the Disputes Chamber limits itself to these general considerations the legal basis

2) The necessity and proportionality of the processing :

The defendant proves that the processing meets the necessity and proportionality principles with a view in its implementation and intended purpose and also proves sufficiently the absence of an alternative- less intrusive system that would similarly achieve the same goals.

3) Data protection by default and by design :

The chamber concludes that the defendant has included data protection by default and by design at early stage in the design of the processing operations through the use of the system of intelligent cameras has included the appropriate technical and organizational measures since the outset (launching of the public contract) regarding the passer-by census system.

In practice, the defendant opted for a stand-alone system, not connected to any network, whereby the processing of personal data by means of video equipment is kept to a minimum and no other personal data becomes collected.

4) Transparent information to data subjects :

The privacy policy and register of the defendant are not entirely complete but in view of the cooperation of the defendant and the amendment of the privacy statement during the course of the proceedings, the litigation chamber does not consider it necessary to issue a sanction but does recommend  to the defendant to take measure to comply with the GDPR.

5) Other remarks :

The litigation chamber does find that the way the defendant justifies the processing of personal data via cookies present on its website is not sufficient and that the data protection officer also does not report to the highest level of management of the defendant.

Decision of the DPA :

-  finds that the system of intelligent cameras implemented by the defendant does not violate article 5.1 a), b) and c) and is in accordance with article 25 GDPR;

- orders the defendant to complete the information that it provides about its processing operations in its privacy statement in accordance with Articles 12 and 13 GDPR, in particular with regard to the additional information requested from the data subject in the context of a request on the basis of Articles 15 to 21 of the GDPR.

- orders the defendant to align its register of processing activities with the requirements of Article 30 GDPR and in particular to specify to which third countries transfer of personal data takes place within the period of one month after the notification of this decision.

- Formulates a reprimand with regard to the defendant for violation of articles 6.1 a), 7.1, 7.3 (consent cookies) and 38.3 GDPR (data protection officer must report directly to the highest management level of the controller).",NONCOMPLIANT,"Article 6, Article 7, Article 12, Article 13, Article 25, Article 30, Article 35, Article 38","[28,43,12,41,48]"
"In May 2019 the Inspection service of the GBA started an investigation into the Federal Public Service Mobility and Transportation. GBA wanted to know about the information portal NV Informex, its access to the national data-bank of vehicles and the fact that data from this data-bank was shared with insurance companies for the purposes of creating personalized price offers to its potential customers. The report of the Inspection service found the following violations: 1. Breach of the principles of purpose limitation (Article 5) and lawfulness (Article 6) of processing; 2. Breach of the responsibilities of a controller (Article 24), security of processing (Article 32) and violation of the obligation to notify supervisory authority of the personal data breach (Article 33); 3. Breach of the requirements for designation (Article 37) and position (Article 38) of data protection officer; 4. Breach of the obligation to cooperate with the supervisory authority (Article 31); 5. Breach of transparency (Article 12) and information provision (Article 13) obligations.","The Dispute Chamber of the GBA found that the use of personal data obtained via the data-bank of vehicles by customers of NV Informex, in particular insurance companies, for the purpose of creating personalized price offers constitutes direct marketing and violates Articles 5 and 6 of the GDPR and Article 25 of the Royal Decree of 8th of July 2013. The Federal Public Service Mobility and Transportation was ordered to bring this personal data processing in compliance with GDPR within 6 months.

The Dispute Chamber also issued a reprimand against the Federal Public Service Mobility and Transportation for violating Articles 12, 13, 14 of GDPR and ordered to bring the relevant information provisions in compliance with GDPR within 3 months.",NONCOMPLIANT,"Article 5, Article 6, Article 12, Article 13, Article 14","[36,40,22,24,13]"
"The Dutch DPA ('AP') received a notification on 11 January 2019 that CP&A processes the health data of its employees. From this notification, the AP concluded that CP&A maintained an online register, containing data on the cause of absenteeism in its employees. In response, it launched an own volition investigation into CP&A's compliance with Article 9, as well as Article 32 GDPR. Since Article 9 GDPR prohibits the processing of special categories of data, including health data, it was necessary for the AP to determine whether one of the exceptions outlined in Article 9 applies. The AP also sought to determine whether whether CP&A had taken sufficient technical and organisational measures to ensure a risk-appropriate level of security for the health data under Article 32 GDPR.","The AP's investigation found that the relevant online register included employees' names, addresses, email addresses and social security number, which made employees directly identifiable. The register also included employees' reasons for absence (concerning both physical and mental health), including the names of illnesses, specific symptoms, and indications of pain. This constituted health data within the meaning of Article 4(15) GDPR. By digitally storing, updating, and making this data available, CP&A was processing health data.

The AP considered whether CP&A could process health data in line with the exception established by Article 9(2)(b), whereby processing is necessary for the carrying out of the controllers rights or obligations in the field of employment, so far as this is authorised by Union or member state law. In the Netherlands, Article 30(1) of the UAVG stipulates that the processing of personal data concerning health is permitted if this is necessary for the reintegration or guidance of employees in connection with illness or disability. With respect to this reintegration, further details are provided in the Section 658a(2) of the Dutch Civil Code, which requires employees to take the necessary measures to enable a sick employee to perform their work as soon as possible.

The AP found that the processing of the names of illnesses, specific symptoms, and indications of pain is not necessary for the reintegration of employees, in accordance with Article 30(1) UAVG, meaning it could not invoke the exception established at Article 9(2)(b) GDPR. Since no other exceptions were applicable, CP&A's processing of the health data was considered unlawful.

With regards to Article 32 GDPR, the AP found that CP&A's security measures concerning the online register were inappropriate. In particular, the register was accessible without any form of authentication. Given the sensitive nature of the data, the fact that the health data was processed on the internet, the CP&A should have taken further measures to mitigate the risk of unauthorised access to the data.

On account of the violations of Articles 9 and 32 GDPR, the DPA imposed a fine of €15,000.",NONCOMPLIANT,"Article 4, Article 9, Article 32","[10,41,40,37,3]"
"On 6 September 2017 the municipality of Enschede decided to start 24/7 WiFi tracking in the centre of the city. Its purpose was to measure the effectiveness of municipal investments, in view of the responsible use of public funds. The contract to execute this task was given to City Traffic B.V., now Bureau RMC. Bureau RMC then contracted an unnamed party to do the installation and maintenance of the sensors and to collect and validate the data gathered by the sensors. Information collected included hashed MAC-addresses, date and timestamp of exposure, signal strength and sensor ID. It was stored for a period between 6 and 7 months. Starting from 1 January 2019 the hashed MAC-addresses were also truncated. On 30 April 2020 the municipality gave an assignment to Bureau RMC to switch the tracking sensors off.","The AP concludes that the chosen anonymization method of truncating a small part of the hashed MAC address does not sufficiently exclude the risks of singling out, linking or deducing person’s identity based on a pseudonymous identifier + timestamp + location information (available via the sensor ID). Because of that the data processed by the municipality constitutes personal data. Because the data was stored for a long time and the truncated/hashed MAC-addressed were not rotated, clear life and location patterns could be deducted from the data set. These patterns could reveal, for example, someone's home or place of work, but also more sensitive data such as visits to medical institutions. Although it was not the municipality’s intention to track people’s life patterns and there is no evidence that that has factually happened, the AP considered these facts irrelevant for this case. According to the AP, the municipality was the controller because it has decided on the means and purposes of personal data processing; it had even issued orders to the Bureau RMC about the specifics of this processing on at least one occasion. Furthermore, the AP considered that there was no law that had obliged the municipality to do WiFi tracking in the city center. This processing also could not follow from a broadly formulated duty of care or a statutory obligation. Moreover, the conditions of necessity and proportionality have not been respected by the municipality as there were less privacy-intrusive ways to count the number of visitors of a city center, like infrared counters. In the view of the recital 47 GDPR, the AP considered that legitimate interest also could not possibly be a valid legal basis in this case because, according to its own arguments, the municipality had acted in the exercise of its official authority. The AP did not see any reason to reduce the fine, it considered the amount of the fine of €600,000 to be proportionate.",NONCOMPLIANT,"Article 4, Article 6","[4,13,14,17,38]"
"The Dutch Ministry of Foreign Affairs handled personal data in processing visa applications. That data included fingerprints, name, address, place of residence, country of birth, purpose of visit, nationality and a photograph. The DPA carried out an investigation of the New Visa Information System that the Ministry used for visa processing operations.","The DPA held that the New Visa Information System lacks sufficient level of security, giving rise to a risk that unauthorised persons can view and change files. It also increases the risk that other errors go unnoticed. Some of the issues concerned were a lack of a security plan, insufficient physical security safeguards, lack of formal registration and deregistration procedures in relation to the access to the system, and weaknesses in the procedure for reporting security incidents. These errors and abuses would have major consequences on applicants' rights. Consequently, the Ministry violated Article 32 GDPR and Article 24 GDPR.

The DPA also found that visa applicants were insufficiently informed about how their data was shared with third parties. Consequently, the Ministry violated Article 13(1)(e) GDPR.

The Ministry of Foreign Affairs was held to be severely negligent as it had been aware of these deficiencies for years. The DPA ordered the Ministry to rectify the situation. It imposed a fine of EUR 565,000 for the past violations. It also imposed penalty payments payable for as long as the violations continue, namely EUR 50,000 per two weeks for security breaches and EUR 10,000 per week for lack of transparency.",NONCOMPLIANT,"Article 13, Article 24, Article 32","[16,26,12,22,49]"
"The Dutch DPA (Autoriteit Persoonsgegevens, 'AP'), launched an ex officio investigation into the processing of personal data by TikTok Inc (TikTok), which is based in California, USA.

TikTok operates the TikTok app, which allows users to create, edit, and share short videos online. TikTok processes a large amount of personal data via the app, including: User ID, name/nickname, user settings, user generated content (e.g. videos, messages, contents), IP address, mobile carrier, time zone settings, App version, device model, device system, network type, device ID, screen resolution, operating system, and appID. A large group of Dutch children under the age of 16 use the TikTok app, some of whom are around 12 years old.

When a user creates a TikTok account, they are informed in Dutch that they are agreeing to TikTok's Privacy Policy. However, the AP's investigation revealed that between 25 May 2018, and 28 July 2020, TikTok provided its Privacy Policy to Dutch users - including children - only in English. This was true both during the registration process, as well as when a user is logged in and wants to consult the Privacy Policy in the TikTok app.

Since 29 July 2020, TikTok has provided its Privacy Policy to Dutch data subjects in Dutch. It also provides a separate document that is appropriate for Dutch speaking children in terms of language and form.","The AP found that TikTok Inc. infringed Article 12(1) GDPR during the period from 25 May 2018 to 28 July 2020, by only providing its Privacy Policy to Dutch children in English.

Article 12(1) GDPR provides that the controller shall take appropriate measures to provide any information relating to the processing of personal data to data subject's in a concise, transparent, and intelligible and easily accessible form, using clear and plain language, in particular for information addressed specifically to a child.

Under the WP29's Guidelines on Transparency, TikTok is required to know its intended audience and identify what qualifies as intelligible on this basis. Accordingly, it must be aware that a substantial part of its intended audience consists of children under 16 years old.

The AP highlighted that the requirement of intelligibility requires, as a minimum, that when the controller addresses data subjects who speak another language, it provides a translation into that language. This obligation applies in particular when the information is addressed to young children, so that they can easily understand this information. The AP emphasised that it is not relevant that a relatively large group of Dutch children may have a good command of English, especially as TikTok is used by many people under the age of 16. It cannot be taken for granted that data subjects in that age group will have a good command of English.

The Fine

The AP imposed a fine of €750,000 on TikTok for its violation of Article 12(1) GDPR.

The AP outlined that, in the event of an infringement of Article 12(1) of the GDPR, pursuant to Article 58(2)(i) and Article 83(5) GDPR, read in conjunction with Article 14(3) of the Dutch General Data Protection Regulation (Implementation) Act (Uitvoeringswet Algemene verordening gegevensbescherming), it is authorised to impose an administrative fine on TikTok Inc. of up to €20,000,000 or up to 4% of the total worldwide annual turnover of the preceding business year, whichever is higher.

The AP has adopted the Administrative Rules on Penalties 2019 (Beleidsregels bestuurlijke boetes 2019) in order to implement the power to impose an administrative fine, which includes determining the amount of the fine. In Annex 2, the infringement of Article 12(1) of the GDPR is classified into category III, for which the penalty range is €300,000 to €750,000 and the applicable base fine is €525,000.

The AP increased the basic amount of the fine pursuant to Article 7 (a) of the Administrative Rules on Penalties 2019 by €225,000 to €750,000, being the maximum of the penalty range in that category. It did so in light of the gravity and duration of the breach. In particular, the breach affected a large number of data subjects (an indicative study showed that approximately 830,000 Dutch children under the age of 18 were using TikTok at the time of the breach), many of whom are children, i.e. a vulnerable group of persons, who are less aware of the risks of the processing of personal data, as well as their rights in relation to such processing.

The transfer of findings to the Irish Data Protection Authority

The AP announced that it is transferring several other results from its investigation to the Irish DPA (the Data Protection Authority, or DPC), who will complete the investigation into TikTok's practices and take a final decision.

This is because, although TikTok was not established in the EU when the AP initiated its investigation (meaning that, under Article 55(1) GDPR, the AP was competent to decide on the case), TikTok established itself in Ireland on 29 July 2020, meaning that, from this date onwards, under Article 56(1) GDPR, the DPC is competant, and not the AP.

The AP was authorised to assess TikTok's privacy statement, as this infringement occurred between 25 May 2018 to 28 July 2020, meaning that it ended prior TikTok's establishment in Ireland on 29 July 2020.

The AP stated that in its role as a supervisory authority concerned and the requesting authority, will continue to be involved in the finalisation of the case and the realisation of the final decision.",NONCOMPLIANT,"Article 12, Article 14, Article 58, Article 83","[10,14,7,31,24]"
"In Oktober 2019, a malicious third party gained unauthorized access to (personal data contained in) the systems of Transavia Airlines C.V., which led to a data breach. In order to limit the damage and to determine what happened, Transavia engaged an external service provider to conduct a root-cause-analysis.

Circumstances of the breach:

By using (i) an automated method in which frequently used passwords are tried in a short time (password spray) and (ii) known user data from previous third-party data breaches (credential stuffing), the attacker succeeded in infiltrating Transavia's systems.

The generic user account that was used to gain unauthorized access had the highest privileges on certain domains of the system and was used as a link between Transavia's HR system and the Active Directory. This allowed the attacker to explore the systems and take a targeted approach by taking the following actions:

* On certain systems, log files were deleted to remove traces;
* Through a penetration test, the user was able to find vulnerabilities in the IT landscape of Transavia;
* Copying network documentation, business and other miscellaneous documents and six mailboxes

Impact of the breach:

a) Impacted data subjects: the personal data that had been compromised belongs to passengers, employees, suppliers and job applicants. The forensic report of the external service provider showed that approx. 80,000 passengers, approx. 3,000 employees, 200 suppliers and 10 job applicants were impacted by the breach

b) Sensitive data:  In addition to contact details of data subjects, the attacker also had access to sensitive data of the passengers. By using SSR codes (Special Service Request), Transavia tries to adapt its services to the needs of the passenger. From these codes, sensitive personal data (health data) can be indirectly derived (i.e., wheelchair user, blindness, or deafness). The forensic report showed that the health data of 367 people was leaked.

Notification to data subjects:

Fulfilling its obligations laid down in Article 34 GDPR, Transavia identified and notified in total 81,000 data subjects, as there may have been a high risk to the rights and freedoms of these data subjects.","As a result of the notification of the data breach, the DPA decided to investigate whether sufficient appropriate technical and organizational measures were in place at the time of the data breach. This investigation showed that Transavia did not respect Article 32(1) and Article 32(2) GDPR by not taking the appropriate technical and organizational measures.

First, the DPA considered that the passwords used, were considered as 'weak'. The DPA was informed that there is a password policy in which the requirements are stated per user profile. However, the DPA determined that the passwords used by the (generic accounts) in the attack did not meet these prescribed requirements. The reason for this was an incorrect risk assessment by Transavia (Transavia expected that the chance of a successful password spray attack or credential stuffing attack was greater with user accounts than generic accounts). Second, there was no well-implemented multi-factor-authentication (MFA). It was possible to access the CITRIX environment without MFA. Based on the above-mentioned risk assessment, Transavia decided to go for a phased roll-out of the MFA implementation, since the company asserted that these accounts had the highest priority. This means that, at first, MFA was merely to be implemented at user accounts, and later at the generic accounts. As a result, the multi factor authentication was not yet implemented for generic accounts at the time the data breach occurred

Third, the DPA considered the absence of network segmentation. This is the division of the network into functional segments. With network segmentation, only the systems that need to communicate with each other are placed together in separate segments, and users only get access to the segments they need. Taking this basic preventive measure lowers the chance of unauthorized access drastically. Fourth, the DPA considered the fact that certain log-files were removed, which made it considerably harder to have a complete image of the data breach, after it occurred. Although Transavia worked together with an external company, specialised in IT-security, which could track suspicious behaviour, inter alia, because activity was being logged, certain critical logging was not undertaken and it was also possible to remove certain log-files. Besides the fact that above-mentioned security measures were already the norm, the implementation costs were also not considered to be that high.

Then, the DPA considered that, the more widely the data is processed and the more sensitive it is, the greater the demands placed on data security. Now, Transavia engages in large-scale processing: the attacker had access to systems containing data of approx. 25 million passengers. Moreover, a part of this is also sensitive, since it is health data. Lastly, the DPA considered the risk of varying likelihood and severity for the rights and freedoms of natural persons. It concluded that this risk is particularly high since the malicious use of the personal data could have led to material and immaterial damage of affected data subjects.

In view of the lack of appropriate technical safeguards which were already the norm, the low implementation costs, the large-scale processing, and the fact that also sensitive data was exposed in the breach, the DPA imposed an administrative fine of €400,000 on Transavia Airlines for violation of  Article 32(1) and Article 32(2) GDPR.",NONCOMPLIANT,"Article 32, Article 34","[40,48,24,34,35]"
"The Dutch employer portal UWV, handling employee health data is investigated for use of single-factor authentication (email address and password) to grant access to the portal.","The Dutch Data Protection Authority considers the single-factor authentication insufficient given the nature of data (under article 32) and proposes multi-factor authentication as a safer alternative. The portal is fined 150,000€/month up to 900,000€ until the portal implements sufficient access control.",NONCOMPLIANT,Article 32,"[7,13,32,45,46]"
"Between 25-05-2018 and 28-04-2019, the BKR provided for two ways to gain access to their personal information.

1. Through a subscription to a customer portal (Basic €4,95/y, Plus €7,50/y, Premium €12,50/y).

2. By downloading, printing and filling out a form, attaching an ID copy and submitting it per mail.

On 29-04-2019 the BKR added free digital access requests.

Between 25-05-2018 and 12-03-2019, the BKR stated in their privacy policy and e-mails included in the investigation, that people ""have a right to free access to their personal information once per year"". This free access would be limited to requests made per mail. For more frequent access, it suggested to use one of the paid subscriptions.

On 13-03-2019 the way the BKR communicates their policy was updated.

The BKR made a statement that in practice, they allowed access more than once per year and don't charge for requests made per mail. Stating their intention was to prevent excessive access requests.","The DPA held, free digital access requests should be available and the BKR violated this up to 29-04-2019.

It also held, the BKR up to 13-03-2019 insufficiently facilitated people in exercising their rights, by actively communicating a policy that free access requests per mail was limited to once per year, creating an additional barrier and discouragement.",NONCOMPLIANT,"Article 12, Article 15","[9,11,25,31,41]"
"""Employees of a company have had their fingerprints scanned for attendance and time registration.""","""After investigation, the Personal Data Authority (AP) concluded that the company should not have processed fingerprints of employees. Indeed, the company cannot invoke an exceptional ground for processing special personal data. The company will be fined EUR 725,000 for this. [...] For the use of fingerprints, two exceptions to the prohibition could be possible in this case: if explicit consent of the data subjects is requested or if the use of biometric data is necessary for authentication or security purposes. The AP concluded that this company cannot invoke one of these two exceptions for the collection, storage and use of employees' fingerprints. [...] This company has not demonstrated that the employees have given explicit consent. Employees have also experienced the recording of their fingerprint as an obligation.""",NONCOMPLIANT,Article 9,"[13,18,26,46,24]"
"The AP received two data breach notifications from the OLVG Foundation about access by employees and work students to electronic patient records. In response to these data breach notifications, the AP initiated an investigation into OLVG's compliance with Article 32(1) of the GDPR by inspecting, among other things, authentication, and verification of the logging procedures.

The AP announced the investigation in a letter dated 17 April 2019, and asked questions to OLVG. These questions were answered by a letter dated 3 May 2019. On 22 May 2019, five inspectors from the AP conducted an on-site investigation at one of the locations of OLVG. During this investigation, the inspectors checked different components of the hospital’s information system. Oral statements were also taken from members of the Executive Board and various employees of OLVG. The AP sent the report of findings to OLVG on 10 February 2020. On February 17, 2020, the AP sent OLVG a letter to announce the intention to enforce. OLVG provided its views on this intention in writing on 27 March 2020 and orally on 25 June 2020.

Since 19 October 2015, OLVG has been using a new information system to store which electronic patient records. OLVG provided medical care to approximately 500,000 patients in 2018 alone, which leads the AP to conclude that the hospital processes personal data, including special category (health) data under GDPR, on large scale.

The AP found two potential issues.

1.	Two-factor authentication.

The AP found that employee authentication was done in two ways, depending on whether access is requested from inside or outside the OLVG network. When logging in from within the OLVG network, the employees must use their usernames and passwords to access their virtual workstations (VDI); a second factor like a staff pass or a token are not required in this case. A single sign-on functionality is also used, allowing the employee who is already logged in to the VDI immediate access to the hospital information system with the electronic patient records.

When logging into the VDI from a computer outside the OLVG network, employees must use a username and password in combination with a changing token which they received by SMS or via an application. OLVG linked a token reader to each computer on 9 March 2020, changing this method of authentication. This means that before they can access to the computer, employees must hold their employee card in front of this reader and enter a password.

OLVG has also indicated in its Information Security and Privacy Policy that that policy is based on: 1) the Dutch standard for information security in healthcare: NEN 7510, NEN 7512 and NEN 7513, and 2) the current laws and regulations, including the GDPR. OLVG has thus also committed to complying with the NEN security standards, which dictate that the identity of users must be established by means of two-factor authentication.

Given the sensitive nature of the data, the large scale of the processing by OLVG and the risks to data subjects, the AP has concluded that OLVG should have implemented two-factor authentication when accessing personal data in electronic patient records. However, this was not done when these records were from inside of the hospital’s network.

2.	Access logs review.

The AP found that during the period from 1 January 2018 to 17 April 2019, OLVG conducted two sample checks of “Break the Glass” behaviour across larger groups of employees and eight incidental checks of the logging of health records. Further, the AP found that OLVG did not conduct systematic checks of anomalies in the access logs to all electronic health records during the period from 1 January 2018 to 22 May 2019, nor did it allow for systematic or automated alerts when certain logging limits were exceeded.","The AP has concluded that OLVG has not applied an appropriate level of security for the processing of personal data in its hospital information system. The AP has determined that until at least 22 May 2019, OLVG has been processing sensitive personal data of hundreds of thousands of patients without adequate security. The AP considers the fact that the violation continued in a structural manner for a longer period, partly under the Personal Data Protection Act, which already required an adequate security level, to be serious. In view of the nature, seriousness, scope and duration of the infringement, the AP increased the basic amount of the fine by €80,000 to €390,000 under the 2019 Fine Policy.

OLVG is expected, partly in view of the sensitive nature and large scale of the processing, to ascertain the standards applicable to it and to act according to those standards. In addition, OLVG has indicated in its own Information Security & Privacy Policy that the policy is based on the Dutch standard for information security in healthcare, namely: NEN 7510, NEN 7512 and NEN 7513 and the current laws and regulations, including the GDPR. Which means that OLVG has committed itself to complying with those norms. OLVG also stipulated in its logging policy that it will take a representative sample every four weeks to analyse the log data. OLVG therefore also fails to comply with its own existing policy rules, which is considered by the AP to be extremely negligent. Given the negligent nature of the breach, the AP increases the base amount of the fine under Article 7(b) of the 2019 Fine Policy by €50,000 to €440,000.",NONCOMPLIANT,Article 32,"[6,7,4,32,40]"
"On 7 February 2019 Booking.com (Booking) submitted a data breach notification to the AP. An unknown person(s) gained access to the reservation system of Booking by pretending to be a Booking employee. About 40 accommodations in the United Arab Emirates Personal were affected. Personal data of guests from different EU and non-EU countries were exposed. Booking stated in the notification that they became aware of the breach on 10 January 2019, which triggered an AP investigation under Article 33(1) GDPR (obligation to notify the supervisory authority about a breach within 72 hours).

Booking maintains the reservation platform where the so called “Trip Providers” can offer accommodation, flights, car rentals and day trips to the users of Booking. These users have to give the contact-, reservation and payment data in order to complete the reservation. That information is then shared with the Trip Providers via Extranet, an online administration dashboard for reservations. Access to Extranet is secured: representatives of Trip Providers have to fill in a username, password and a “2FA pin code”.

This breach was a result of what is called by AP a social engineering attack: an unknown person contacted a Trip Provider by the phone and obtained a username, password and the “2FA pin code” necessary to access Extranet by pretending to be a Booking employee. Personal data of about 4109 guest got compromised, including first and last names, addresses, phone numbers, check-in and check-out dates, total price, price per night, reservation numbers, communication between hotels and guests, 283 credit card details with CVCs of about 97 of them.

Timeline on the breach.

19 December 2018 – social engineering phone call, start of the incident

9 January 2019 – 1st email to Booking from accommodation 1. A guest of that hotel had been approached by email sent from a Hotmail account by a “reservation employee”. The “employee” had asked for he guest’s birth date, which was necessary to complete the payment. The night rate was mentioned in the email, a PDF with the reservation details was attached to the email.

13 January 2019 – 2nd notification from the same accommodation: another guest got a phone call from “Booking”, asking for the credit card information and other personal data.

20 January 2019 – 3rd notification from accommodation 1, reporting another phone call to a guest, the caller had asked for the credit card details.

20 January 2019 – accommodation 2 reports multiple notifications from guests. All guests mention the attempts to get their credit card details, using hotel’s name, arrival/departure dates and other information.

31 January 2019 – Booking’s Security team gets involved.

4 February 2019 – Preliminary report of the security team, confirming the breach. Privacy teams gets involved, affected individuals get informed of the incident.

6 February 2019 – Privacy team qualifies the incident as a personal data breach that needs to be reported to the AP. 7 February 2019 – Breach is reported to the AP.

28 February 2019 – Final report of the Security team.","The AP concluded that Booking violated the breach reporting obligation under Article 33(1) of the GDPR. According to the Fine Policy of the AP, the basis fine for this violation is €525,000. The AP took into account the measures taken by Booking to minimize the consequences of the breach and reduced the fine to €475,000.",NONCOMPLIANT,Article 33,"[0,3,17,27,31]"
"Locatefamily.com is an organisation established outside of the European Union (EU) that with its website 'Locatefamily.com' offers a platform on which anyone can search for contact details of friends and family they have lost track of.

The AP stated that it received 19 complaints between 25 May 2018 and 25 July 2019 from individuals who had not registered with Locatefamily.com, but whose information, including full addresses and sometimes telephone numbers, had appeared on the website without their knowledge. The complaints concerned the failure of Locatefamily.com to respond to requests for erasure, and the lack of an official EU representative.

On 18 July 2018 the AP sent a request for mutual assistance under Article 61 GDPR to other EU DPAs, asking whether they had received similar complaints on Locatefamily.com. Ten DPAs responded confirming that they had, and the AP initiated an ex officio investigation into Locatefamily.com regarding a potential violation of Article 27 GDPR.

The dispute regarded whether it is necessary for locatefamily.com to appoint a representative in the European Union. Locatefamily.com argued it was not, as it has no office or representatives in the EU, and does not offer goods and services to the EU, preventing the application of the GDPR under Article 3.","The AP fined Locatefamily.com €525,000 for not appointing an EU representative. It further required Locatefamily.com to pay an exrta €20,000 for each two-week period it failed to appoint an EU representative, up to a maximum of €120,000.

The AP underlined that its investigation, which was carried out in collaboration with other EU supervisory authorities, revealed that locatefamily.com offered its services both in the Netherlands and in eight other EU countries. In accordance with Article 3(2) GDPR, Locatefamily.com's processing activities fell within the GDPRs territorial scope, and it was obliged to appoint an EU representative with whom EU citizens could exercise their privacy rights.",NONCOMPLIANT,Article 27,"[6,11,17,19,20]"
"The controller is an supermarket chain owner. The DPA received the data subject's complaint, which stated that employees of the controller, without authorisation and contrary to internal acts and instructions of the controller, recorded video surveillance footage with a mobile phone and distributed it to the public through social media. Moreover, this recording remained available on social media. The DPA then investigated the matter further.","The DPA found that the controller did not take appropriate measures to prevent its employee from filing the video surveillance with their phone.

The DPA considered that the controller took certain organisational measures, such as the education of employees, and the adoption of internal acts that prescribed the authorisation of access to video surveillance. Moreover, the controller required employees to sign a confidentiality statement. However, according to the DPA, this was not enough. First, the controller did not supervise, test, evaluate and determine the effectiveness these measures (Article 32(1)(d) GDPR). Second, the controller did not ensure the ongoing confidentiality, integrity, availability of personal data (Article 32(1)(b) GDPR). Hence the controller did not take appropriate organisational and technical security measures that could have minimised the risk of the same, or a similar violation. Therefore, the DPA concluded that the controller violated Article 32(1)(b), Article 32(1)(d), Article 32(2), and Article 32(4) GDPR.

Therefore, the DPA decided to impose a fine of HRK 675,000 (approx. €89,000).",NONCOMPLIANT,Article 32,"[28,32,38,17,33]"
"An IT company in Zagreb provides IT services to mobile operators, banks and government institutions in the Republic of Croatia, but also to companies abroad (USA, UK, Netherlands, etc.). Its main service is providing opinions, guidelines, and proposed solutions to data processing managers on the implementation of web applications. Data controller, telecommunications company in Zagreb informed the DPA, as well as the user of its services, that there had been a potential breach of personal data. In fact, hackers obtained the personal data of 28,085 data subjects.","Following an investigation, the Croatian DPA (AZOP) held that data processor, an IT company, did not take necessary measures to achieve an adequate level of security in accordance with existing and foreseeable risks, and that its records of data processing activities further violated Article 32(1)(b) and (d) GDPR. Accordingly, the DPA, in accordance with its powers under Article 58 (2) GDPR, imposed an administrative fine that it considered effective, proportionate, dissuasive and fully appropriate to the circumstances.",NONCOMPLIANT,Article 32,"[23,25,12,13,9]"
"The AZOP received complaints from citizens against private Bank. The complainants exercised their right of access under Article 15 GDPR and requested copies of credit documentation (e.g. book keeping card, repayment plan, an annex to the loan agreement, review of changes in interest rates).

The Bank refused to grant the access of the requested documentation. The latter stated that according to the Consumer Credit Law and other special regulations, the documentation requested did not contain personal data, only documents related to credits and loans.

Following to the complaint, the AZOP established that the requested documents contained personal data and investigated the matter, by virtue of Article 58 GDPR.","Despite several orders which have been previously issued (34 decisions), the Bank infringed the data subjects' rights. While deciding about the amount of the fine, the AZOP was applied Article 83 (1) GDPR: the described conduct of the Bank resulted in a serious violation of the data subjects' rights - regulated by art. 83 (5) (b) –.  It has been established that: the Bank knowingly and intentionally  acted; it has not been an isolated case; the longer duration of the violation; it has not made any efforts to mitigate any possible consequences and risks for rights and freedoms of data subjects; the access to personal data has not been made possible even after individual decisions. It was pointed out that by not responding to the requests, the Bank directly avoided certain financial expenses that could be considered to be material gain to the detriment of the data subjects. It was also taken into account that no violations of the Regulation have been established so far, as well as the degree of cooperation with the AZOP.",NONCOMPLIANT,Article 15,"[1,28,42,44,45]"
"After having conducted investigations in June 2017, the DPA found that the controller was structurally not deleting data in it's archive. The DPA requested to change the archive system for tenant's personal data under the previous German Data Protection Act. When the situation was reviewed after the coming into force of the GDPR, the DPA found that the company still did not comply.","The BlnBDI found that the archive system used for storing personal data of tenants, which did not provide for a possibility to remove the personal data violated Article 5(1)(e) and Article 25(1) GDPR. There was also no legal basis for the processing of personal data anymore. The fine was calculated at 14,5 Mio Euro.

In addition, the DPA found 15 other violations of the rights of individual data subjects, which lead to additional fines between 6,000 EUR and 17,000 EUR each.

In February 2021 the Berlin regional court has annulled the fine, on the basis that there was no specific act of the management of the firm that had led to the infringements.  The Berlin Public Prosecutor's Office has now filed an appeal against this decision, arguing that for the application of the GDPR the mere establishment of an infringement, without the establishment of a active act by management, is enough to justify regulatory action.",NONCOMPLIANT,"Article 5, Article 25","[8,21,27,37,38]"
"In 2015, SLIMPAY (a payment service provider) reused personal data contained in its databases for testing purposes, as part of a research project that ended in July 2016. The data used remained stored on a server without any particular security procedure and freely accessible from the Internet.

SLIMPAY was warned of the issue by one of its client (a legal person) in 2020.

Then, SLIMPAY took measures to put an end to the data breach and proceeded to notify it to the French Data Protection Authority (DPA), but decided not to notify it to the data subjects.

Afterwards, the DPA decided to carry out an investigation of SLIMPAY's GDPR compliance.","The DPA found out that SLIMPAY breached several GDPR provisions.

On the failure to comply with Article 28 GDPR

The DPA noted that some of the contracts concluded by SLIMPAY with its service providers (subprocessors) did not contain all of the clauses that would make it possible to ensure that these subcontractors undertake to process personal data in compliance with GDPR, whereas some other contracts did not even contain any of these clauses.

On the failure to comply with Article 32 GDPR

The DPA noted that the server in question was not subject to any appropriate security measures, and was freely accessible by anyone between November 2015 and February 2020.

Furthermore, the categories of data aggravated the case, considering that civil status data (name, surname, first name), postal and e-mail addresses, telephone numbers and bank details (BIC/IBAN) of more than 12 million people were compromised.

The DPA also held that the absence of proven harm to the data subjects has no bearing on the existence of the violation of Article 32 GDPR, contrary to what SLIMPAY claimed during the procedure.

On the failure to comply with Article 34 GDPR

The DPA considered that, given the nature of the personal data concerned by the breach, the number of data subjects affected (more than 12 million), and the possibility to identify them from the accessible data and the risks of phishing or identity theft that were implied because of the breach, the risk associated with it breach should have been considered high by SLIMPAY. Therefore, SLIMPAY should have informed all affected data subjects. For all of the above reasons, the DPA found out that SLIMPAY violated Articles 28, 32 and 34 GDPR, and decided to impose to SLIMPAY a fine of €180,000.",NONCOMPLIANT,"Article 28, Article 32, Article 34","[26,47,46,15,12]"
"The CNIL received several complaints from individuals and NGOs on the way Clearview AI's processing of biometric data. The company conducts facial recognition AI trainings  for law enforcement purposes mainly on a large database from public web sources, including social media. The CNIL started an EU-wide investigation in close collaboration with other competent EU DPAs.","The CNIL's investigations revealed two main breaches of the GDPR.

First, Clearview AI was illegally processing personal data. Indeed, as stated in Article 6 GDPR, a legal basis is required to process personal data. The company had no legitimate interest to collect and process such sensitive data and therefore had to rely on a consent-based approach (Article 6(1)(b) GDPR). Since the the company did not appear to seek any consent from individuals the processing operations were deemed unlawful.

Second, Clearview AI had been unlawfully hindering individuals from exercising their rights. On the one hand, insufficient information and accessibility regarding procedures were provided, thus in breach of Article 12 GDPR. On the other hand, the company had undermined individuals rights of access (Article 15 GDPR) and right to be forgotten (Article 17 GDPR) by:

* restricting access to data collected only in the 12 previous months;
* authorizing right of access only twice a year;
* answering requests only after several attempts from individuals;
* not effectively answering requests by providing incorrect and incomplete replies.

The CNIL sent Clearview a letter of formal notice asserting that Clearview must facilitate individuals rights exercising and stop processing data without relevant legal basis within a two months period, as well as delete any personal data collected previously.",NONCOMPLIANT,"Article 6, Article 12, Article 15, Article 17","[2,1,30,25,16]"
"On 13th November 2018, the French DPA (CNIL) carried out an inspection at the Brico Privé's premises, a DIY company, to inspect the company's data retention periods, the information it provides to data subjects, its compliance with requests for the deletion of personal data, data security, and compliance with the obligation to obtain data subject consent to receive commercial prospecting by e-mail.

In order to complete its investigations, the CNIL carried out an online inspection of all processing accessible from the bricoprive.com domain on 6 February 2020.

On 13 January 2021, as the company indicated that changes had been made to the methods of depositing cookies, a delegation from the CNIL carried out a new investigation of any processing accessible from the bricoprive.com domain in order to update the findings made on 6 February 2020.","The CNIL found that the controller had violated Articles 5(1)(e), 13, 17 and 32 GDPR by failing to comply with the obligation to determine and implement data retention periods, failing to inform web visitors about processing activities, failing to comply with the request for erasure of data, and failing to ensure appropriate security measures regarding authentication on the website and on the customer relationship management software used by the company's employees.

The CNIL also found that the controller had violated national provisions concerning cookies and unsolicited commercial communications.

With regards to Article 5(1)(e), the DPA found that the company did not have a retention policy in place for the deletion of data. The company had data from accounts as old as five years without any activity.

With regards to Article 13, the controller did not offer on their website information such as the contact details of the data protection officer, the retention periods, the legal bases for processing, and certain rights from which individuals benefit under the GDPR.

With regards to Article 17, the company did not delete the data when there were requests from users to delete their account, but only deactivated the accounts, preventing the person from connecting to the account and ending unsolicited commercial communications.

With regards to Article 32, the DPA found that there was not a sufficient level of data security to meet requirements concerning the robustness of passwords, both for users and employees.

With regards to cookies, the DPA found that several cookies that did not fall within the scope of the exceptions (necessary cookies) were placed on the user's terminal as soon as they arrived on the home page of the site, and before any action on their part.

Additionally, the company was sending unsolicited commercial communications to users who created an account for commercial purposes and without obtaining their consent.

Therefore, the CNIL fined Brico Privé €300,000 for violating Articles 5(1)(e), 13, 17 and 32 GDPR and €200,000 for violating Article 82 of the loi n° 78-17 du 6 janvier 1978 modifiée relative à l'informatique, aux fichiers et aux libertés and Article 34(5) of the Code des postes et des communications électroniques (CPCE) – the national provisions concerning cookies and unsolicited commercial communications.

The CNIL also ordered the controller to bring its processing operations into compliance with the obligations resulting from Article 5(1)(e) GDPR and Article 34(5) of the CPCE, and in particular:

* to cease to retain the personal data of former customers at the end of a set period of inactivity and proceed with the purging of such data retained by the company, 
* to provide evidence of an intermediate archive procedure for customers personal data, established after sorting out the relevant data to be stored and deleting irrelevant data, as well as the starting point of such storage (e.g. for invoices stored for accounting purposes),
* to cease unsolicited commercial communications to users who have not given their consent.",NONCOMPLIANT,"Article 5, Article 13, Article 17, Article 32","[8,21,33,31,48]"
"An on-site investigation carried out by the French DPA (Commission Nationale de l’Informatique et des Libertés – CNIL) in October 2019 revealed the following breaches:

First, the internal firm policy on data retention duration was only implemented in several areas of activities. In this respect, the company later indicated that it had undertaken a broad compliance plan and, in particular, that an IT project had been initiated in 2017 in order to achieve effective compliance with GDPR. However, the timetable of this project could not be met due to the complexity of the firm's information systems.

Second, it appeared that subcontractors performed all of canvassing operations without informing data subjects on the processing their personal data and their rights. In addition, subcontracting agreements did not contain any provision on the matter, and 30% of calls were recorded, without informing clients and prospects.

Since the on-site investigation, the firm had been implementing corrective measures. According to the firm, compliance with data retention legal duration will be complete by 2022 and canvassing operations are now carried out in accordance with Articles 13 and 14 GDPR.","On the duration of data retention

The CNIL found that the company had violated Article 5(1)(e) GDPR and several domestic provisions of the Insurance Code. Regarding the 3 years limit of retention of prospects’ data, the CNIL reiterates that its guidelines on data protection by insurance, capitalisation, reinsurance and assistance organisations, whilst non mandatory and dating back from 2013, still provide with the appropriate and proportionate duration of retention for this category of data.

Regarding the sanction, the CNIL took into account that the firm had been gradually implementing a complex compliance policy since 2017 and had undertaken corrective measures during the course of the proceedings that improved greatly its situation.

However, compliance measures adopted do not absolve the company of its responsibility for the past. Full compliance will not be achieved before 2022 and established violations are the result of a lack of anticipation that, with regard to the firm’s size and resources, could have been avoided.

Hence, the firm is fined to an amount of €1,75 million.

On the information of data subject in the context of canvassing operations

The CNIL found that the total lack of information to data subjects is contrary to Articles 13 and 14 GDPR.

Nonetheless, the firm had taken appropriate measures to achieve compliance with the aforesaid Articles during the course of the procedure.

The CNIL therefore decided not to impose a sanction on this matter.",NONCOMPLIANT,"Article 5, Article 13, Article 14, Article 83","[30,38,29,8,42]"
"In May 2019, several media outlets revealed that the Monsanto company was processing personal data of more than 200 public figures like politicians, journalists and scientists involved in the glyphosate debate.

At the same time, the French DPA CNIL received seven complaints from data subjects whose personal information was included in Monsanto's filing system.

The investigation revealed that (i) the filing system had been created on behalf of Monsanto by several companies specialized in public relations and lobbying; (ii) the filing system contained different information about the data subjects including job description, professional email address,  mobile phone number, and sometimes Twitter account. Furthermore, (iv) a rating was given to every data subject, to estimate their influence and their support to Monsanto's activities.","On the information of data subjects

The DPA found that the creation of contact files for the purpose of lobbying is not illegal in itself. However, the DPA found that the company had violated Article 14 GDPR for not having provided the data subjects with the mandatory information as soon as possible. Indeed, even if consent from those public figures was not necessary, they still had to be informed, so they could exercise their rights and especially their right to object.

The DPA found that data subject were informed of the existence of the filing system only in 2019, after revelations in the media, even though the Monsanto company had all of their contact information. The DPA also reminded that the fact of not informing the data subject of the existence of a processing harms the exercise of their others rights guaranteed under the GDPR.

On the absence of judicial document between the controller and the processors

The DPA found that the company had violated Article 28 GDPR. As a controller, Monsanto had to lead by a judicial document the processing realised by its processor, especially to guarantee security measures. The DPA found that no contract between the companies contained the terms provided by Article 28(3) GDPR.",NONCOMPLIANT,"Article 14, Article 28","[6,20,32,47,49]"
"The CNIL received 16 complaints between 2018 and 2019 specifying that users were facing difficulties for deleting or rectifying their data on the annuairefrancais.fr website. The website hosts information about companies registered in France that are published on the SIRENE database - a public database managed by the National Institute for Statistics and Economic Studies (INSEE). The website annuairefrancais.fr offers the possibility of creating an account allowing users to get information about registered companies and to subscribe to commercial offers from these companies. After an initial inspection, the CNIL found that the processing was not compliant with the GDPR and issued a formal notice giving the company two months to bring its processing practices into compliance by implementing a clear policy regarding data deletion and rectification, establishing a record of processing activities and dealing with the data subjects' requests.","Noting that the company had not actively cooperated and had failed to implement the required measures within the prescribed period, as spelled out in the formal notice, the CNIL imposed a fine of €3,000 on the company Société nouvelle de l'annuaire français.

More specifically:

* concerning Article 16 GDPR (right to rectification), it was found that the company had failed to follow up on a data subject's request to rectify his postal address from his personal to his professional address within the prescribed period. The deadline for rectifying the personal data of the complainant had been largely exceeded as the company's director implemented the required measures in July 2021, whereas the deadline expired in September 2020;
* concerning  Article 17 GDPR (right to erasure), it was also found that the erasure requests of several data subjects had not been processed within the prescribed period. Several requests which were supposed to have been processed had, in fact, not been followed up on, even after the formal notice period had expired. The CNIL considered that if the data controller had indeed reinitialized its database by taking only the INSEE data, this was not sufficient to ensure that the requests were taken into account;
* concerning Article 30 GDPR (record of processing activities), it was found that the company had failed to create and complete a record of processing activities although processing a large amount of personal data constituted the core of its activity.",NONCOMPLIANT,"Article 16, Article 17, Article 30","[6,16,31,42,46]"
"The CNIL received a complaint from several unions in May 2020 regarding the collection and storage of data on the number of days that RATP's agents had been on strike days. These data were kept in files normally used for careers advancement procedures. The RATP recognized that four bus transport units were concerned by this practice. The investigation conducted by the CNIL confirmed that this practice had been commonplace in at least three bus transport units of the RATP. During the investigation, the CNIL also found other breaches regarding storage limitation and data security.","The CNIL held that it was unlawful to process information on the number of days an agent had been on strike in the context of career advancement procedures because such information was unnecessary for the purpose of the processing. In particular, the RATP should have limited such information to the number of days of absence of each agent, regardless of the reason behind such absence(s). As a consequence, the CNL found that the RATP had been processing these data in breach of the principle of data minimization (Article 5(1)(c) GDPR).

The investigation also revealed other breaches with respect to the principle of storage limitation (Article 5(1)(e) GDPR). Indeed, the app used to monitor the work of RATP's agents was storing personal data for an excessive period of time. Moreover, agents' files were kept for more than three years after the commission on careers advancement had taken a decision. In the opinion of the CNIL, the RATP should have kept such files for 18 months maximum.

Finally, the investigation also revealed severe security flaws. In particular, it was found that authorized agents could access an excessive amount of data (including human resources files) regardless of their role, from all bus transport units, and could also extract all the data from the app, without any restriction. Because of this, the CNIL considered that the RATP had violated Article 32 GDPR.

Taking into account the scope and severity of these violations, the CNIL decided to impose a fine of 400,000 EUR on the RATP.",NONCOMPLIANT,"Article 5, Article 32","[21,17,4,45,5]"
"The defendant, FREE MOBILE, is a French mobile telephone operator. The CNIL opened an investigation into the company's processing activities after it received multiple complaints by individuals who had encountered excessive difficulties in obtaining responses to access requests they had filed with it, and had objected to receiving commercial prospecting messages from the defendant.","The CNIL found the company breached the GDPR by:

1. Failing to respect the right of access of individuals regarding their personal data (Article 12 and 15 GDPR), since the company did not respond to the requests made by the complainants within the time limits. Moreover, controllers should also inform data subjects within one month when they will not provide any data (for example because data is no longer processed); they also have to provide data that is held in archival databases.
2. Failing to respect the right to object of the persons concerned (Article 12 and 21 GDPR), since the company did not take into account the requests of the complainants that no more commercial prospecting messages be sent to them;
3. Failing to protect data by design (Article 25 GDPR), as the company continued to send invoices to complainants for telephone lines whose subscription had been cancelled;
4. Failing to ensure the security of personal data (Article 32 GDPR), since the company transmitted by email, in clear text, the passwords of users when they subscribed to an offer with FREE MOBILE, without these passwords being temporary and the company requiring them to be changed.",NONCOMPLIANT,"Article 12, Article 15, Article 21, Article 25, Article 32","[5,39,46,15,38]"
"Google LLC is a subsidiary owned wholly by Alphabet Inc. Google Ireland Limited ('GIL') ""presents itself"" as the headquarters for the Google group's operations in the EEA and Switzerland.

In March 2020 the French DPA (CNIL) carried out an online inspection of the website ""google.fr"" in the context of a previous procedure against Google LLC and GIL. The purpose of this inspection was to verify their compliance with the Loi 'Informatique et Libertés', and in particular with Article 82 thereof. This resulted in this decision, that Google appealed.

Following this decision, the CNIL received more complaints about the methods of refusing cookies from the website ""google.fr"". It therefore reopened the case and launched a new investigation.","On the request for a stay of proceedings

First, the companies requested that per Article 66 of the CNIL's rules of procedure, the CNIL stay these proceedings pending the decision to be handed down by the Council of State in the appeal against its first decision against Google and pending the conclusions of the new EDPB working group on cookies.

The CNIL rejected this request, as it considered that there were no acceptable grounds for staying the proceedings.

On the complaint alleging breach of the ne bis in idem principle

Second, the companies argued that the restricted formation cannot rule again on the same facts as those concerned by deliberations No. SAN-2020-012 and No. SAN-2021-004, without violating the ne bis in idem principle, as it considered the parties and material facts in those case to be identical.

The CNIL responded that the two procedures do not concern the same facts, as these cases included an injunction relating to the information of users on the purposes of cookies subject to consent and on the means available to refuse cookies, whereas the one at hand concerned the refusal methods themselves, and not only the information. It also highlighted that this procedure concerned both the websites ""google.fr"" and ""youtube.com"", whereas the previous procedure concerned only the website ""google.fr"".

As such, the CNIL rejected the complaint based on the violation of the ne bis in idem principle.

On the competence of the CNIL

The material competence of the CNIL and the non-application of the ""one-stop shop"" mechanism provided for by the GDPR

The processing operations investigated by the CNIL in this case were carried out in the context of the provision of publicly available electronic communications services via a public electronic communications network offered within the European Union. As such, it considered they fell within the material scope of the ePrivacy Directive. Article 5(3) of that directive was transposed into domestic law through Article 82 of the French Data Protection Act. The CNIL therefore considered itself materially competent under these provisions to monitor and sanction the access or registration of information by companies in the terminals of users of the ""google.fr"" and ""youtube.com"" websites in France.

The companies contested the jurisdiction of the CNIL. They argued they should be subject to the procedural framework provided for by the GDPR, or the 'one-stop shop' mechanism, under which the Irish DPA (DPC) would be the lead supervisory authority (LSA). They considered that the absence of specific rules on determining the competence of the supervisory authority in the case of cross-border processing operations falling within the scope of the ePrivacy Directive should be replaced by the application of the procedural framework provided for by the GDPR. Interestingly, the companies further argued that the EDPB's announcement regarding the creation of a working group on cookie banners in response to the significant number of complaints recently filed with supervisory authorities by noyb was evidence that the EDPB considers that cookie-related breaches fall directly within the scope of the GDPR and, therefore, the 'one-stop shop' mechanism.

First, the CNIL responded that a distinction should be made between, on the one hand, the operations consisting in depositing and reading a cookie on a user's terminal and, on the other hand, the subsequent use that is made of the data generated by these cookies (""subsequent/further processing""). The former are governed by special rules, set by the ePrivacy Directive - in this case, by its Article 5(3) - and transposed into national law, the latter is governed by the GDPR and, as such, may be subject to the ""one-stop-shop"" mechanism in the event that they are cross-border. This case only concerned the read and write operations carried out on the terminal of the user located in France visiting the Google Search and YouTube search engines.

Second, it held that where a processing operation may fall within both the material scope of the ePrivacy Directive and the material scope of the GDPR, reference should be made to the relevant provisions of the two texts which provide for their articulation. The rule laid down in Article 5(3) of the ePrivacy Directive, according to which reading and/or writing operations must systematically be subject to the prior consent of the user, after having been informed, constitutes a special rule with regard to the GDPR, since it prohibits the legal bases mentioned in Article 6 GDPR from being invoked in order to be able to lawfully carry them out. The control of this rule is therefore a matter for the special control and sanction mechanism provided for by the ePrivacy Directive, and not for the data protection authorities and the EDPB under the GDPR. It stated that the French legislator entrusted this task to the CNIL. Thus, the ""one-stop shop"" mechanism provided for by the GDPR could not be applied to the processing operations covered by the Directive, as the companies claimed.

Third, the CNIL confirmed that the 'one-stop-shop' mechanism is not applicable to facts that are materially covered by the ePrivacy Directive, by referring to the Opinion No 5/2019 of the EDPB and the CJEU decision C-645/19 (Facebook Belgium) upholding this opinion.

Finally, the CNIL stated that the creation of a working group on cookies in response to the large number of complaints filed by noyb did not mean that the EDPB considered that all violations related to cookies necessarily fall within the scope of the GDPR. Furthermore, pursuant to Article 70(1)(u) GDPR, one of the EDPS's tasks is to promote cooperation and the effective bilateral and multilateral exchange of information and best practices between supervisory authorities. The purpose of the working party was thus only to exchange views on the analysis of the numerous complaints lodged by noyb.

Thus, the CNIL held that the ""one-stop shop"" mechanism provided for by the GDPR was not applicable to the present procedure and that it was competent to control and sanction processing operations consisting of reading and/or writing information in the terminal of users located in France implemented by companies falling within the scope of the ""ePrivacy"" Directive, provided that they fall within its territorial jurisdiction.

On the territorial jurisdiction of the CNIL

The CNIL considered it was territorially competent under Article 3 GDPR since the processing that was the subject of the present procedure, namely consisting of accessing or recording information on the terminals of users residing in France when using the Google Search engine and YouTube, in particular for advertising purposes, was carried out within the ""framework of the activities"" of the company Google France, which constituted the ""establishment"" of the Google group in France. In response, Google argued that its establishment in the EU was located in Ireland. The CNIL considered a range of CJEU case law (included but not limited to Google Spain C-131/12, Weltimmo C-230/14) and its findings in the previous decision SAN-2020-012, which pointed towards a broad interpretation of 'establishment' and 'in the context of the activities' and rejected this argument. As such, it held that French law was applicable and that it was materially and territorially competent to exercise its powers, including the power to impose sanctions on processing operations falling within the scope of the ePrivacy Directive.

The determination of the controller

The CNIL held that Google LLC and Google Ireland Limited jointly determined the purposes and means of the processing consisting of accessing or recording information in the terminal of users residing in France when using the Google Search engine and YouTube.

On the failure to comply with the obligations relating to cookies

The CNIL finally assessed whether the companies had complied with Article 82 of the French Data Protection Act.

It noted that, in order to give consent to the reading and/or writing of information on their terminal, users visiting the home page of the sites ""google.fr"" and ""youtube.com"" only had to click on the ""I accept"" button on the pop-up window, which made the window disappear and allowed them to continue browsing. On the other hand, the users going to these same home pages and wishing to refuse cookies had to click on the ""Personalise"" button of this first window, which took them to an interface on both the ""google.fr"" and ""youtube.com"" sites, offering them the choice of activating or deactivating cookies, on which they had the possibility of carrying out various actions.

The investigator for the CNIL considered that making the mechanism for refusing cookies more complex than the one for accepting them amounted to discouraging users from refusing cookies and encouraging them to opt for the ""I accept"" button. This led to their conclusion that the methods of refusing cookies implemented by the companies on the sites ""google.fr"" and ""youtube.com"" did not comply with the provisions of Article 82 of the French Data Protection Act, as clarified by the enhanced consent requirements set out in the GDPR.

In response, the companies argued that neither the ePrivacy Directive, nor the RGPD, nor Article 82 of the Data Protection Act provided that the action of refusing cookies should be as simple as accepting them. ""They [also added] that, for many years, the CNIL itself had not deduced this principle even though the regulations in question had remained unchanged since the RGPD came into force. They point out that the CNIL cannot, through its guidelines and recommendations, introduce new requirements relating to the refusal of consent and consider that it is up to each data controller to choose the most appropriate method of obtaining consent.""

The CNIL rejected this, restating its powers, which include drawing up and publishing guidelines, recommendations or benchmarks intended to facilitate the compliance of personal data processing with the texts relating to the protection of personal data. It was in this context the DPA had issued its previous deliberations which provided guidance to stakeholders on the implementation of concrete measures to ensure compliance with these provisions, so that they implemented these measures or measures of equivalent effect. Indeed, the guidelines' main purpose ""is to recall and clarify the law applicable to the reading and/or writing of information [...] in the subscriber's or user's electronic communications terminal equipment, and in particular to the use of cookies"".

It thus considered that it had not created any new obligations for the actors in its recommendation, but has limited itself to illustrating in concrete terms how Article 82 of the law should be applied. The position according to which it must be as simple for users to refuse cookies as to consent to them was even endorsed by the French Council of State in CE, 19 June 2020, No. 434684, pt 15.

Further, the CNIL highlighted that users residing in France who visit the Google Search engine and/or YouTube had to perform a single action to accept cookies, whereas they had to perform five to refuse them. It was therefore not as simple to refuse cookies as to accept them. It referred to studies that showed that having a ""refuse all"" button on the first-level consent interface led to a decrease in the rate of consent to accept cookies. It therefore considered that making the mechanism for refusing cookies more complex than the one for accepting them actually discourages users from refusing cookies and encourages them to prefer the ease of the ""accept all"" button.

""In view of the above, the [CNIL held] that there [had] been a breach of the provisions of Article 82 of the [French] Data Protection Act, interpreted in the light of the GDPR, insofar as the companies [did] not provide users located in France, on the websites ""google.fr"" and ""youtube.com"", with a means of refusing to read and/or write information to their terminal that is as simple as the one provided for accepting its use.

Thus, the CNIL:

* imposed a fine of €90,000,000 on Google LLC for failing to comply with Article 82 of the French Data Protection Act,
* imposed a fine of €60,000,000 on Google Ireland Limited for failing to comply with Article 82 of the French Data Protection Act,
* ordered Google LLC and Google Ireland Limited to modify, on the websites ""google.fr"" and ""youtube.com"", the methods for obtaining the consent of users located in France to the reading and/or writing of information in their terminal, by offering them a means of refusing these operations that is as simple as the mechanism provided for their acceptance, in order to guarantee the freedom of their consent;
* attached to the injunction a penalty of 100,000 euros (one hundred thousand euros) per day of delay at the end of a period of three months following notification of this decision, with proof of compliance to be sent to the restricted panel within this period;
* made its decision public on the CNIL website and on the Légifrance website, which will no longer identify the companies by name at the end of a two-year period from the date of its publication.",NONCOMPLIANT,Article 56,"[17,33,26,45,13]"
"Dedalus Biologie is a software solutions provider for medical analysis laboratories. In February 2021, a press article was published which revealed that confidential information of 500,000 French patients had been stolen from laboratories and uploaded to an online forum. The French DPA subsequently carried out an online investigation, finding that the personal data of 491,840 patients had been published in a file that could easily be downloaded, including sensitive data such as health data concerning information relating to HIV infection, cancer or genetic diseases, pregnancy, drug treatments or genetic data.

Subsequently, the DPA carried out on-site investigations first at the premises of Dedalus Biologie and then in the two laboratories concerned by the data breach to see whether they were GDPR-compliant. At the end of the investigations, the rapporteur suggested to fine Dedalus Biologie based on the GDPR breaches he considered to have occured.","First, the DPA found that Dedalus Biologie was the processor pursuant to Article 4(8) GDPR as it provides laboratories with the tools to facilitate the implementation of processing and only acts in the name and under the responsibility of the laboratories.

Consequently, the DPA held that the processor had violated Article 28(3) GDPR because the contracts between it and the controllers did not provide the necessary information required by that provision. For instance, one of the contracts referred to obsolete provisions of the Data Protection Act. The DPA clarified that the mere existence of a section on personal data does not meet the requirements of Article 28(3) GDPR. The processor did  not dispute this violation. However, it claimed that it was not solely responsible as Article 28(3) GDPR imposes obligations on both the processor and the controller.

Then, the DPA found a breach of Article 29 GDPR. The processor had processed data beyond the instructions given by the data controllers by extracting more data than necessary for the commissioned data migration of software to another tool. The processor argued that its former extraction tool had only allowed for total extraction of patient files but that it had successfully migrated to a new tool in the meantime. However, since the controllers had asked only for certain data to be extracted, the DPA still found this violation. The processor should not have relied on an unsuitable tool to justify having exceeded the controllers' instructions. Instead, it could for instance have opted for another tool or at least deleted all the data that should not have been extracted.

Finally, the DPA held that the processor had violated Article 32 GDPR due to many technical and organisational shortcomings in terms of security of operations to migrate the software to another, including the lack of specific procedure for data migration operations, the lack of encryption of personal data stored on the problematic server, absence of automatic deletion of data after migration to the other software, absence of authentication required from the internet to access the public area of ​​the server, the use of user accounts shared between several employees on the private zone of the server, the lack of supervision procedure, and security alert escalation on the server.

Based on the seriousness of the breaches identified and also taking into account the turnover of the company, the DPA decided on the high fine of €1,500,000. It also criticised that the processor had not taken any specific measures to stop the dissemination of the file once it became aware of it. It was the DPA which seized the Paris court to block access to the site on which the leaked data was published. The court’s decision made possible to limit the consequences of the breach on affected individuals.",NONCOMPLIANT,"Article 28, Article 29, Article 32","[7,28,34,38,47]"
"In the context of the worldwide health crisis caused by Covid-19, the French Ministry of Health decided to make an application available to its citizens, aiming to improve the detection process of infections. The application ""StopCovid"" thus enables its users to inform their phone contacts, whom they have recently met or even only shortly been in contact with, if they have been infected with the virus. The users can also be informed by the application if they have encountered or found themselves at proximity of another user of the application who has declared having been infected. With regard to the nature of the data processing  and the important number of users, the CNIL decided to investigate in order to make sure that the processing be carried out in accordance with the applicable provisions.","The CNIL held that, in the main, the application ""StopCovid"" complied with the applicable data protection laws. However, the authority revealed a failure to comply with some of the provisions of the GDPR and the ""loi informatique et libertés"". Regarding, on one hand, the violation of the GDPR, the CNIL reminded the Ministry of Health that data has to be processed lawfully, fairly and in a transparent manner in relation to the data subject (Art. 5(1)(a) GDPR). The fact that when the information given by the user, indicating they had been infected by the Covid-19, was transferred to all their contacts and not only to the contacts they had recently found themselves at proximity of, was a direct violation of the principle of lawfulness and the Art. 2(5) of the national decree relating to the data processing carried out through ""StopCovid"". Moreover, the privacy policy aiming to inform the users of the data processing lacked precision regarding categories of data being processed and recipients of the data. A data processor being involved in the processing, the authority also found that the contract required by Art. 28 GDPR was missing dispositions as to the rights and obligations of the Ministry, assistance with data subjects requests, security of processing, documentation of processing and audit. Furthermore, the data protection impact assessment was considered incomplete, the data processing caused by the use of the ""Captcha"" verification solution not having been part of the assessment.  Regarding, on the other hand, the violation of the national data protection law, the CNIL pointed out that the Art. 82 of the ""loi informatique et libertés"" required that for any data processing resulting from the use of electronic services such as the Google Captcha solution, the user had to be informed and asked to give their consent prior to the processing. Yet neither were the users informed of the data processing by Google,  nor were they asked to give their consent.  That is why CNIL summoned the Ministry of Health to address those violations within a month and report back to confirm the implementation of all corrective measures.",NONCOMPLIANT,"Article 5, Article 13, Article 28, Article 35","[30,16,14,5,47]"
"Between June 2018 and January 2020, the French DPA (CNIL) received dozens of data breach notifications concerning a shopping website used by millions of customers. The CNIL decided to investigate the owning company (controller) and the processor in charge of managing the site.

The investigation revealed that the controller was developing a tool to detect and block credential stuffing attacks but did not implement any temporary measures to prevent further attacks from succeeding. As a result, personal data linked to about 40000 different customers were made accessible to third parties.

Credential stuffing is a type of attack where an assailant tries to login to a service by using in bulk logins/passwords retrieved from a previous data breach.","The CNIL ruled that the controller and its processor did not act diligently in implementing corrective measures. For this reason, the French DPA imposed a €150000 fine on the controller.

The DPA also ruled that even though the data controller is responsible for providing the processor with documented instructions on the measures to be taken, the processor must search for the appropriate measures as well and propose them to the controller. As a result, the CNIL imposed a 75000€ fine on the processor as well.

The CNIL underlined that the controller could have implemented quick measures to block further credential stuffing attacks, such as capping the number of login requests coming from the same IP adress or using a CAPTCHA.",NONCOMPLIANT,Article 32,"[47,17,7,24,19]"
"On 31 May 2018, CNIL initiated an investigation in the premises of SPARTOO SAS in order to investigate whether the processing of the personal data of its clients, prospect clients and employees, are compliant with GDPR. CNIL focused on several processing activities of SPARTOO SAS:  1) recording the customer service calls on a permanent basis, 2) storage of customers' bank details 2) no determination of retention period initially 3) determination of retention period of five years since the customer's last activity 4) establishing as last activity of the prospect customer the mere opening of an email 5) storage of personal data of more than three millions of non-connected customers for more than five years in a non-anonymised way 6) no erasure of personal data on a regular basis, 7) request the customer's health card in Italy in the context of the fight against fraud, 8) lack of strong password policy, 9) not adequate information provided to customers, prospect customers and employees regarding the processing of their personal data.","CNIL found that the collection of bank details and the recording of customer service conversations was excessive and not necessary for the purported aim, that is the training of employees, given that only one call per employee was examined per week. Also, the collection of the health cards in Italy was found excessive, and together with the above-mentioned activities, CNIL held that the data minimisation principle had been violated (5§1(c) GDPR). CNIL also found a violation of the storage limitation principle (5§1(e) GDPR), given the lack of retention period in the first place, the storage of data of many inactive customers for more than five years and the excessive storage of prospect customers' personal data, which should be limited to 2 years.  Furthermore, the information provided to the data subjects was found inadequate and contrary to the obligation of transparency (13 GDPR). More specifically, CNIL held that there are more legal bases for the processing of clients' personal data except for consent, such as the performance of a contract and the legitimate interest of the controller. Also, the information provided to the employees of the company regarding the recording of the customer service calls, did not include the purpose of the processing, the legal basis, the recipients, the retention period and their rights.  Finally, CNIL held that SPARTOO SAS failed to implement appropriate measures in order to ensure the security of the processing (art. 32 GDPR), as it did not impose a strict password policy.",NONCOMPLIANT,"Article 5, Article 13, Article 32, Article 56","[16,15,40,22,19]"
"Google LLC is a company headquartered in USA, California. Since its creation in 1998, it has developed numerous services for individuals and businesses, such as the Google Search engine, the Gmail email box, the Google Maps mapping service, and the YouTube video platform. It has more than 70 offices in some 50 countries and employed more than 110,000 people worldwide in 2019. Since August 2015, it has been a wholly owned subsidiary of Alphabet Inc, the parent company of the Google group.

Google Ireland Ltd, based in Dublin (Ireland), is the headquarters of the Google Group for its activities in the European Economic Area and Switzerland. Google France SARL is the French branch of the Google Group.

On 16 March 2020, the French DPA (CNIL) carried out an online check on the google.fr website. The CNIL then found several violations of the rules relating to cookies, contained in Article 82 of the French Data Protection Act (Loi Informatique et Libertés), as transposed from the e-Privacy Directive.","The French DPA fined GOOGLE LLC 60 millions euros and GOOGLE IRELAND LIMITED 40 millions euros, both of which were made public. Insofar as the practices of these companies have affected nearly 50 millions users, and the considerable profits that the companies derive from the advertising revenues indirectly generated from the data collected by these advertising cookies, the CNIL has issued an injunction under penalty so that the companies proceed to inform people in accordance with Article 82 of the French Data Protection Act within 3 months of notification. Otherwise, the companies will be liable to a penalty payment of 100 000 euros per day of delay.

In order to justify its decision, the French DPA has identified several failings in terms of cookie management, with regard to the provisions of article 82 of the French Data Protection Act.

On the material and territorial competence of the French DPA

In its decision, the CNIL’s sub-commission recalls that the French DPA is materially competent to control and sanction cookies deposited by companies on the computers of users residing in France. Indeed, the CNIL notes that when a processing operation falls within the material scope of both the ePrivacy Directive and the GDPR, reference should be made to the relevant provisions of two texts that provide for their articulation. Thus, recital 173 of the Regulation explicitly provides that it is not applicable to processing of personal data which are subject to specific obligations set out in the ePrivacy Directive.

The CNIL also stresses that this articulation was confirmed by the Court of Justice of the European Union in its PLANET49 decision of 1 October 2019 (C-613/17). In doing so, the French DPA concludes that the lead authority mechanism provided for by the GDPR was not intended to apply in this procedure since operations related to the use of cookies fall within the scope of the ePrivacy Directive, as transposed in Article 82 of the French Data Protection Act.

Also, the CNIL’s sub-commission considered that it is also territorially competent in application of article 3 of the French Data Protection Act because the use of cookies is carried out within the framework of the activities of the company Google France which constitutes the establishment on French territory of the companies Google LLC and Google Ireland Ltd and ensures the promotion of their products and services.

On the determination of responsibilities

The CNIL’s sub-commission notes that Articles 4(7) and 26(1) GDPR are applicable to the present proceedings because of the use of the concept of controller in Article 82 of French Data Protection Act, which is justified by the reference made by Article 2 of the ePrivacy Directive to Directive 95/46/EC on the protection of personal data, which has been replaced by the GDPR.

According to Article 4(7) GDPR, the controller is defined as the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data. According to Article 26(1) GDPR, when two or more controllers jointly determine the purposes and means of processing, they shall be joint controllers.

The CNIL considers that Google Ireland Ltd and Google LLC should be considered as joint controllers for the processing in question, since the companies both determine the purposes and means of the processing consisting of operations to access or deposit cookies in the terminal of Google Search users residing in France.

Indeed, Google Ireland Ltd is involved in the development and supervision of the internal policies that guide the products and their design, the setting of parameters, the determination of privacy rules and all checks carried out prior to the launch of the products, in application of the principle of privacy by design.

With regard to Google LLC, the CNIL considers that although it appears from the contract concluded with Google Ireland Ltd that Google LLC acts as a processor of Google Ireland Ltd, it appears that the actual involvement of Google LLC in the processing in question goes far beyond that of a processor that merely carries out processing operations on behalf of Google Ireland Ltd and on its sole instructions. Thus, Google LLC also determines the means of processing since, as mentioned above, it is Google LLC that designs and builds the technology of cookies placed on the terminals of European users. The CNIL therefore concludes that Google LLC must also be granted the status of data controller.

On the violation of provisions on cookies

During the online check carried out on 16 March 2020, the CNIL noted that, when users reached the google.fr website, seven cookies were placed on their terminal equipment, before any action. In its letter dated 30 April 2020, Google Ireland Ltd indicated that four of these seven cookies were used for advertising purposes.

In this context, the CNIL’s sub-commission recalls on provisions of Article 82 of the French Data Protection Act, according to which any deposit of cookies or tracers must be preceded by the information and consent of users. This requirement does not apply to cookies whose sole purpose is to enable or facilitate communication by electronic means or which are strictly necessary for the provision of an online communication service at the express request of the user.

As a result, the CNIL found several violations of these provisions: the lack of prior information to users, the failure to obtain the consent of individuals before depositing cookies on their terminal, and the impossibility for individuals to refuse the deposit of all cookies.

The lack of information to users

The CNIL notes that the information provided to users residing in France relating to operations to access or deposit information in their terminal when using the Google Search engine was insufficient and unclear, and therefore violated the provisions of Article 82 of the French Data Protection Act. More specifically, the CNIL emphasized that:

* Access or deposit of a cookie can only be made on the condition that user has consented to it after having received clear and complete information relating to the purposes of the cookies deposited and the means at his disposal to oppose. Firstly, the CNIL noticed that when a user reached the google.fr website, an information banner was displayed at the bottom of the page, containing the following notice ""Reminder regarding Google's privacy policy"", opposite which were two buttons entitled ""Remind me later"" or ""Consult now"". The CNIL highlights that the simple reference to the privacy policy is not explicit enough to enable the individuals to obtain information in accordance with the provisions of Article 82 of the French Data Protection Act. Then, the CNIL noted during the online checks that the privacy rules that opened in pop-up windows when people clicked on the “View Now” button still did not contain any developments dedicated to the use of cookies and other tracers, despite general information about the personal data processed by Google services. In addition, the data subjects were still not informed at this stage of their ability to refuse cookies on their terminal equipment. Consequently, the CNIL concluded that the information provided by the companies, both in the banner and in the pop-up window, did not allow users residing in France, when using the Google Search engine, to be priorly and clearly informed of the existence of operations allowing access and deposit of information in their terminal and, consequently, to be priorly and clearly informed of the purpose of such operations and the means made available to them as to the possibility of refusing them.
* The CNIL underlines that since the initiation of the sanction proceedings, the companies have undertaken a series of changes in the way they use cookies. Thus, since 20 September 2020, all users visiting the google.fr website now see, in the middle of their screen, before being able to access the search engine, a pop-up window entitled ""Before continuing"" which contains prior information relating to cookies. However, although the French DPA highlights a definite change compared to previous information banners, the CNIL considers that the information provided is still not clear and complete within the meaning of Article 82 of the French Data Protection Act, insofar as this information does not inform the user of all the purposes of the cookies deposited and the means at his disposal to oppose them. Indeed, the presentation of the different purposes mentioned in this banner remains too general for users to easily and clearly understand why cookies are deposited on their terminal. Furthermore, the information provided is incomplete as users are still not informed about their right to oppose to these cookies, nor about the means made available to them for this purpose (the terms ""Options"" or ""More information"" are not explicit enough to enable users to directly understand the extent of their rights).

The failure to obtain the consent of individuals before depositing cookies on their terminal

In this respect, after recalling the provisions of Article 82 of the French Data Protection Act, the CNIL concludes that since these four cookies do not have the sole purpose of enabling or facilitating communication by electronic means nor are they strictly necessary for the provision of an online communication service at the express request of the user, the sub-commission considers that the companies should have obtained the prior consent of the users, before depositing cookies on the user's terminal.

The Google’s partially flawed opposition mechanism

First of all, the CNIL underlines that the use of the expression ""withdraw consent"" is particularly abusive, insofar as the cookies were deposited on the user's terminal even before their consent was obtained (absence of opt-in).

Also, the DPA's sub-commission hold that, after having nevertheless deactivated the personalisation of ads on Google search, and while continuing its browsing on the site, several of these cookies for advertising purposes remained stored on user's computer and continued to read information for the server to which this cookie was attached (for example google.com or google.fr) during each new interaction with the domain concerned.

Consequently, the CNIL concluded that the system put in place by the companies to oppose cookies for advertising purposes placed on the user's terminal was partially defective, in violation of the requirements of Article 82 of the French Data Protection Act.",NONCOMPLIANT,"Article 4, Article 26, Article 56, Article 60","[46,49,25,42,22]"
"Between December 2019 and May 2020, the CNIL conducted three online and one on-site investigations on Amazon Europe Core (AEC), a subsidiary company of the Amazon group operating the shopping site amazon.fr. These investigations aimed at assessing the company's compliance with the French data protection law.

The French DPA reported several infringements of the data protection law by AEC when placing cookies. The company responded by contesting the competence of the CNIL on this matter due to the fact that its main establishment is located in Luxembourg and by challenging the legality of the investigation procedure.","The CNIL considered itself competent to investigate AEC and ruled that the company infringed on the French data protection law and on the Directive 2002/58/EC (ePrivacy) while placing cookies. As a consequence, the CNIL imposed a € 35000000 fine on AEC, coupled with an injunction to comply with the Law within three months with a € 100000 penalty per overdue day. Due to the seriousness of the wrongdoings and the high number of Amazon services' users, the CNIL decided to make this sanction publicly available for a two year period.

On the territorial competence of the CNIL

AEC argued that the French DPA is not competent to investigate on its activity due to the one-stop-shop principle of GDPR. To support this claim, AEC higlights that the CNIL's investigation initial purpose was, among other things, to ensure that the company complied with GDPR, meaning that the sanction could only be given by the authority relevant to the main establishment of the company in the EU.

Furthermore, AEC argued that even though the investigation dealt with cookies which are regulated by the Directive ePrivacy, cookies cannot be dissociated from personal data processing, meaning that the GDPR rules on national competence should prevail.

The CNIL rejected this interpretation and deemed itself competent as it was not only investigating GDPR infringements but also breaches of the Directive ePrivacy, transcribed into French law. It reminded that GDPR and ePrivacy each had their own investigating procedure when dealing with their respective requirements. Also, it clarifies that ePrivacy applies as a specialia generalibus derogant rule, based on the interpretation of Article 95 GDPR in the line of the Rec (173) GDPR and Article 1(2) and 15a of the ePrivacy Directive. The CNIL added that the investigation focused on the amazon.fr website targeting french customers.

On the legality of the investigation procedure

Regarding the legality of the procedure, AEC accuses the investigating party of submitting the company to questions without telling the purpose and legal basis of the controls carried out. This meant that the company could not exercise its right not to contribute to its own indictment .

AEC also argued that the investigating party's method, involving reproducing a user's path was inaccurate as it did not allow to differentiate between Amazon's cookies and the ones placed by third parties when visiting other websites.

The CNIL responded by quoting Article 18 of the French data protection law which states that the investigated body has to answer to the CNIL's questions without the CNIL having to justify them and that at the time of those questions no accusation was being made against AEC.

Regarding the investigation method, the CNIL argued that it reproduced several user's path in order to determine which cookies were placed when visiting the Amazon website and that it excluded from the perimeter of the investigation those that originated from a third party website.

As such, the CNIL considers its investigation procedure to be licit.

On the placement of cookies prior to any action from the user

While investigating, the CNIL noticed that more than 40 cookies for commercial purposes were placed on the user's device prior to any act of consent from its part.

AEC responded that its cookie practice is subject to the Luxembourg law and not the French law and that Luxembourg allowed to base the consent on the cookie parameters of the web browser. The company added that it changed its french cookie policy in September 2020, but affirmed that it never infringed on the Luxembourg law on cookies.

The CNIL rejected this argumentation, considering that the website targeted french customers, and that cookies for commercial purposes always require consent from the data subject as they are not part of the exemptions listed in Article 5(3) of the Directive ePrivacy transcribed in Article 82 of the French data protection law.

On the information of the user regarding cookies

The amazon.fr website displayed the following notice regarding cookies: ""By using this site, you agree to os ar use of cookies to provide and improve our services. Further information""

The DPA found that this wording is not sufficient in order to comply with the transparency principle as it did not provide the data subject with any information on how to exercise its rights or oppose cookies. It added that the expression ""to provide and improve our services"" does not inform the user of the commercial purposes of some cookies.

Finally, the CNIL reminded Amazon that it had already pronounced several sanctions on insufficient information regarding cookies.",NONCOMPLIANT,"Article 6, Article 9, Article 83, Article 94","[46,4,6,0,45]"
"During March 2020 , the press reported the use of drones equipped with cameras by the police forces in several places, in order to monitor compliance with COVID-19 lockdown measures.

The French DPA questionned the Ministry of the Interior on the subject. In absence of reply, the DPA initated an inquiry. The Ministry was summoned to answer a questionnaire. It stated that the drones had also been used for other purposes : scouting an area before an arrest, surveillance of a drug traficking,  of demonstrations and road transport. An on-site control then established that the camera used were efficient enough to allow for facial identification of individuals.

In this context, the report concluded to several violations of data protection law and proposed a sanction. The Ministry's main line of defence was that, since August 2020, a face-blurring program has been implemented. As a result, data were allegedly anonimized, and data protection regulation not applicable.","The DPA issues a public call to order against the Ministry of the Interior, on the following grounds.

On the processing of personal data

The DPA reminds the broad definitions of processing and personal data laid down by Article 4(1) and (2) GDPR. The DPA then quotes ECJ, 11 December 2014, Ryneš, case C-212/13 (point 22), EDPB Guidelines 3/2019 on processing of personal data through video devices, a ruling and an opinion by the French Supreme Administrative Court. It reiterates that personal data are processed whenever people can be identified on the basis of recorded images.

The DPA notes that the equipped cameras have a high resolution and a zoom capability, which allow for identification of faces.

Regarding the face-blurring program, it has only been implemented in some recent operation. Its utility is confined to prevention activities, where identification is not necessary. Furthemore, for safety reasons, the pilot's monitor screen is not subject to blurring. Lastly, unblurred recordings can be accessed by operational services, although it takes time. Indeed, despite the fact that only the technical service has control over the program, all services are placed under the same authority.

The DPA then decides that the program is of no effect on the definition of the subject matter of the inquiry as a processing of personal data.

On the violation of French Data Protection Act, implementing Directive (EU) 2016/680

Under French Data Protection Act (Loi n° 78-17 du 6 janvier 1978 relative à l'informatique, aux fichiers et aux libertés), the processing of personal data can only occur where authorised by a specific legal provision (Article 89). In the present case, the Ministry has ignored this obligation.

Furthermore, a data protection impact assessment is mandatory where the processing could create significant risks to the fundamental rights and freedoms. According to the DPA, drones generate such risks, especially because of the possibility given to the Ministry to acquire knowledge of beliefs and opinions of data subject participating to demonstrations. Those risks are increased by the fact that data subjects may not be aware of the drone operating and thus of the processing of their personal data.  The data protection impact assessment is also required where a new mechanism is implemented (Article 90). Drones being new to police forces, the assessment is required.

Lastly, the CNIL finds that the Ministry has failed to its obligation as data controller to provide data subjects with mandatory information.

As a result of these violations, the DPA issues a public call to order. It is however decided that the name of the Ministry of Interior will not appear publicly on the decision after a period of 2 years.",NONCOMPLIANT,Article 4,"[36,37,39,40,44]"
"In 2018, the Luxembourg DPA (the CNPD) initiated 25 different audit proceedings both in the private and public sector with regard to the role of the Data Protection Officer (DPO) under Section 4 of Chapter 4 of the GDPR (see in particular Article 37 GDPR to Article 39 GDPR).

One of these audit proceedings concerned a Luxembourg private company (hereafter, the controller). During the audit, it was found by the head of investigation of the DPA that :

1. the controller had failed to publish the contact details of its DPO in breach of Article 37(7) GDPR;
2. the controller had failed to ensure that the DPO was involved, properly and in a timely manner, in all issues which relate to the protection of personal data, in breach of Article 38(1) GDPR;
3. the controller had failed to ensure that the DPO could fulfill their mission with a sufficient degree of autonomy, in breach of Article 38(3) GDPR;
4. the controller had failed to ensure that the DPO could properly monitor the compliance of the controller's data processing practices with the GDPR, in breach of Article 39(1)(b) GDPR.

In their audit report, the head of investigation therefore recommended the DPA to impose a fine of €18,700 on the controller, and to issue an injunction against the controller to bring its practices in compliance with the GDPR.","Following the audit and the report from the head of investigation, the DPA found that the controller had been in breach of four distinct obligations relating to the DPO under the GDPR, as specified below.

Regarding the breach of Article 37(7) GDPR, the DPA noted that it had been found that the public website of the controller did not provide the direct contact details of the DPO. In case of questions or requests from data subjects, the website only provided a general online contact form, a postal address, or a telephone number. Based on these facts, the DPA found that data subjects were not able to directly contact the DPO (but only indirectly, via an other services within the controller). In the course of the proceedings, the controller remedied that breach by adding the contact details of the DPO in its online data protection notice (and in particular, in the section on the rights of data subjects). The DPA nevertheless found that, at the time of the audit, there had been a breach of Article 37(7) GDPR.

Regarding the breach of Article 38(1) GDPR, the DPA considered that the DPO had not been sufficiently involved in all issues relating to data protection law. In particular, the audit report pointed to the fact that the DPO was only being involved in various internal meetings or committees upon invitation or on an ad hoc basis, but there was no defined rule or frequency as to the involvement of the DPO in these committees. In the course of the investigation, the controller implemented new procedures according to which the DPO would become a permanent member of, or would be regularly involved in various committees meetings. Although welcoming these new measures, the DPA nevertheless concluded that the controller had been in breach of Article 38(1) GDPR prior to these changes.

Regarding the breach of Article 38(3) GDPR, the audit report pointed to the existence of several hierarchical intermediaries between the DPO and the highest level of management within the controller. Based on these facts, the DPA found that the DPO could not directly report to the highest management level of the controller, and did not have a sufficient degree of autonomy and independence, as normally required by Article 38(3) GDPR.

Regarding the breach of Article 39(1)(b) GDPR, the audit report pointed to the absence of any monitoring plan or procedures that would formalize and ensure that the DPO is able to duly monitor the compliance of the controller's data processing practices with the GDPR. Although the controller explained that monitoring procedures had been developed and finalised in December 2019, to be implemented in 2020. Because such control plan or monitoring procedures had not been put in place at the time the investigation was initiated, the DPA concluded that the controller had breached Article 39(1)(b) GDPR.

For all these reasons, the DPA issued an injunction against the controller to bring its practices in compliance with the GDPR for the remaining breaches (with a deadline of 4 months as from the date of the decision), and also imposed an administrative fine of  €18,700 EUR on the controller.",NONCOMPLIANT,"Article 37, Article 38, Article 39, Article 58, Article 83","[12,32,39,42,8]"
"The Luxembourg DPA launched an investigation on a controller that had implemented a geolocation system on their snowplowing and salting vehicles.

Such system used on-line software, although the data was not transferred via WiFi but via phone cards.

The employees participated in the activities relating such vehicles on a voluntary basis. They had only been informed about the system, however, orally.","The DPA argued that, even if Article 12 GDPR does not de facto exclude the possibility of providing the information from Articles 13 and 14 orally, it poses an accountability problem. The controller must be able to demonstrate that it has provided such information.

However, having provided the information in an oral manner, in this case the controller could not prove that had provided the information, and therefore the DPA concluded that the controller had violated Article 13 GDPR.

The DPA took into account that the controller had implemented, during the proceedings, adequate measures to fulfill their information obligation, following the authority's proposal.

Therefore, the CNPD decided to only warn the controller.",NONCOMPLIANT,"Article 12, Article 13","[48,47,3,32,14]"
"The Luxembourg DPA (CNPD) launched an investigation on a controller that was using videocameras on the entrance of their premises to protect their property and monitor the entrance, as well as for work security purposes and the prevention of accidents.

The controller held a pre-authorisation from the CNPD. However, their cameras were also partially capturing images of public space.","Even if the CNPD admitted that sometimes it is admissible to capture images of public surrounding, given the impossibility of the contrary, such images shall be blurred or masked. Therefore, the DPA concluded that the controller had violated Article 5(1)(c) GDPR, for processing data that is not relevant for the purposes of the processing.

Additionally, the DPA found that the controller offered limited information on the videosurveillance system, both to users and to employees, and failed to provide adequate notice about the system on their website. Furthermore, the controller had not adequately informed the employees about such system, not could prove that had provided relevant information.

Because of this, the DPA concluded that the controller had also violated Article 13 GDPR.

The DPA fined the controller €1000 for both violations and ordered the controller to implement any necessary measure to comply with Article 13. The authority took into account the measures that the controller had already taken during the proceedings to remedy the situation, following the DPA's recommendations.",NONCOMPLIANT,"Article 5, Article 13","[44,11,23,25,18]"
"The Luxembourg DPA (CNPD) launched an investigation on a group of companies with a subsidiary based in Luxembourg (Company A).

The central headquarters had a privacy office, while the Luxembourg subsidiary had a sole data protection lawyer. The group of companies had appointed a single Group DPO to handle the data protection matters of both the central company and the Luxembourg subsidiary. The local data protection lawyer was the single point of contact of the DPO with the Company A.","The CNPD determined that even if the DPO was participating in numerous meetings at a group level and regularly organized meetings with its local points of contact, that was not sufficient to demonstrate the direct, formal and permanent involvement of the DPO in Luxembourg.

The Group DPO received a monthly report from the local contact point relating to data protection issues (number of requests to exercise rights or complaints, possible impact analyzes etc.). The DPO was also systematically informed and consulted by the local contact point in case of security incidents likely to involve personal data and create a risk for the people concerned.

However, the DPA considered that such elements could not compensate for the absence of direct involvement of the Group DPO within Company A, which could create the risk that the DPO was not sufficiently involved at operational level in Luxembourg, being therefore in breach of Article 38(1) GDPR, as the DPO must involved, properly and in a timely manner, in all issues which relate to the protection of personal data.

There were not any measures to address that risk, such as for example regular visits of the Group DPO to Company A, that would allow the DPO to be able to discuss data protection issues and related operational issues directly with the management of the company.

There was no direct feedback of information from the Group DPO to the local department either. There are several levels of reporting, but the DPA considered that it was not sufficient to compensate for the lack of direct reporting from the DPO to the data controller in Luxembourg.

All questions relating to the protection of personal data that arose at the control level were received and first analyzed by the local point of contact who afterwards assessed the issue and contacted the Group DPO when they deemed it necessary. Therefore, the DPO was not informed and above all not consulted from the earliest stage possible of all matters relating to data protection.

Hence, a breach of Article 38(2) was also found, since the DPO was nor provided the resources necessary to carry out those tasks and access to personal data and processing operations.

This also led to a breach of Article 39(1)(a), due to the lack of direct feedback.

Additionally, during the course of the proceedings, the Company A appointed a new DPO. The DPA remarked that it must ensure that the newly appointed DPO is effectively involved in all matters relating to data protection.

For these violations, the DPA fined the controller €18,000. The DPA took into account the will to cooperate of the company.",NONCOMPLIANT,"Article 38, Article 39","[2,6,25,13,37]"
"The Luxembourg DPA (CNPD) opened an investigation on a controller and carried out an on-premises investigation.

The DPA found that the controller was using a surveillance system around and within its buildings. During the on-site investigation, the DPA noted that the scope of vision of a camera allowed the surveillance of part of the public highway adjoining the building.

According to the controller, the purposes of setting up the video surveillance system were the protection of property, the securing of the access to private places, user safety and accident prevention.

Additionally, the DPA found that there were ten cameras inside the building which scope of vision allowed for permanent monitoring of the workstations of employees working in the premises.

Regarding the information to third parties and employees, the DPA noted that there were posters showing a pictogram of a camera with the mention ""for your safety this site is under surveillance"" in the exits and entrances to the building.","With regards to the range of vision of the cameras, the DPA concluded that the principle of data minimization in video surveillance implies that only what is strictly necessary to achieve the purposes of the processing should be filmed and that the processing operations must not be disproportionate.

The CNPD noted that the cameras that were intended to monitor an access point (entrances and exits, thresholds, porches, doors, halls, etc.) must have only had a field of vision limited to the area strictly necessary to visualize people preparing to access it. The cameras that were filming exterior accesses must not have filmed the entire width of the sidewalk or the public roads adjacent to it. Additionally, the outdoor cameras installed near or around the building must have been configured so as not to capture the public thoroughfare, nor the surroundings, entrances, accesses and interiors of other neighbouring buildings.

The DPA considered that in view of the purposes of the video surveillance a system, it was not necessary to encompass parts of the public space or neighbouring grounds in the fields of view of the cameras, and that even if it would have been impossible to install the camera without including in its field of vision part of the public space, the controller should have implemented masking or blurring techniques in order to limit the field of vision of the cameras to what is strictly necessary.

With respect to the cameras allowing for a permanent monitoring of the employees, the DPA stated that a permanent monitoring of employees on their workstations is to be considered as disproportionate.

The DPA remarked that such permanent monitoring can create significant psychological pressure for employees who feel and know that they are being observed, especially since the surveillance will last over time. The fact that the employees do not have a way of avoiding this surveillance from time to time is also an aggravating factor to this pressure. Permanent monitoring is considered as disproportionate to the purposes of the processing and constitutes an excessive interference with the private sphere of employees.

In this case, the rights and fundamental freedoms of employees must prevail over the interests pursued by the employer. Even if it may appear necessary for a controller install a video surveillance system in the workplace, the controller must respect the principle of proportionality and must use the most protective means of surveillance for the employee's private sphere. For example, by limiting the cameras' fields of vision to the area necessary to achieve the perused purpose.

The CNPD therefore concluded that the controller had violated Article 5(1)(c), as it had not respected the minimization principle.

With regards to the obligation of information, the DPA found that the pictograms did not offer the necessary and basic information that shall be offered in the first level of information, such as details of the purpose of the processing, the identity of the controller and the existence of the rights of the data subjects, as well as the information with the greatest impact on the processing or any processing information likely to surprise the data subjects.

Additionally, regarding the second level of information the DPA stated that the controller must take concrete measures to provide the information to the data subject or to actively direct the persons concerned to the location of said information. For example, by means of a direct link, a QR code, etc., directing to the privacy policy of the company, or by sending an email to employees.

The controller had sent such email to their employees during the course of the investigation but had no complied with the rest of the requirements.

Therefore, the CNPD concluded that the controller had violated Article 13.

For all this, the DPA fined the controller €12,500 and ordered it to put in place adequate measures to comply with the information obligation and to process only data that is relevant, adequate and limited to what is necessary for the purposes of the protection of their property, the securing of access to private places, the security of users and accident prevention and, in particular, to adapt the system so as not to film employees at their workstation, for example by removing or reorienting some of the cameras.

At the end of the proceeding, the controller confirmed that they had changed the set up of the cameras so all cameras only target corridors, passages, freezers or raw material depots and that no employee is in the field of vision permanently.",NONCOMPLIANT,"Article 5, Article 13","[6,27,1,11,32]"
"In 2018, the Luxembourg DPA (the CNPD) initiated 25 different audit proceedings both in the private and public sector with regard to the obligations relating to the Data Protection Officer (DPO) under Section 4 of Chapter 4 of the GDPR (see in particular Article 37 GDPR to Article 39 GDPR).

One of these audit proceedings concerned a Luxembourg private company (hereafter, the controller). During the investigation, it was found that the controller had failed to communicate the contact details of its DPO to the DPA on time, in breach of Article 37(7) GDPR. Furthermore, it was found that the DPO appointed by the controller had other tasks and duties that could result in a conflict of interests, in breach of Article 38(6) GDPR.","Because the controller had communicated the contact details of the DPO on 28 September 2018 (that is, more than 4 months after the day of application of the GDPR), the DPA found that the controller had violated Article 37(7) GDPR.

Because the DPO of the controller was also ""Head  of  Compliance,  Money  Laundering  Reporting  Officer"", it was found that the DPO was involved in tasks that could result in a conflict of interest. As pointed out by the investigator of the DPA in his report, a DPO cannot exercise within the same company a function which allows him or her to determine the purposes and means of processing of personal data. In this case, the DPO was involved in the determination and implementation of personal data processing as part of his duties as Head of Compliance, and was therefore bound to assess the data processing practices which he/she had put in place himself/herself. None of the measures taken by the controller to mitigate the risk of conflict of interest  (such as the fact that, in the event of a potential conflict of interest, the processing practices concerned would need to be countersigned by the hierarchical superior of the DPO) were found to be sufficient. In  the course of the audit proceeding, however, the controller informed the DPA that it had appointed a new DPO to avoid any future conflict of interest.

For these reasons, the DPA found that the controller had violated  Article 37(7) GDPR and Article 38(6) GDPR. Since both violations had been addressed, however, the DPA did not impose any administrative fine on the controller but simply issued a warning.",NONCOMPLIANT,"Article 37, Article 38","[21,11,24,9,13]"
"The Luxembourg DPA (CNPD) launched an investigation on a company that was using a geolocation system in their fleet of vehicles. Such vehicles were used by their employees for home to office transport and to travel with clients.

According to the controller, the geolocation purposes were geographic identification, protection of company assets, tracking of transported goods, optimal fleet management, optimisation of the work process, responding to customer complaints, proof of service customer complaints, the provision of proof of services, invoicing of services, and the monitoring of the working time of employees on the move.

The DPA also found that the geolocation data had been stored for a period of 2 years and 4 months.","According to the CNPD, the retention period exceeded what was necessary for the purposes of the processing. Because of this, the CNPD considered that the controller had violated Article 5(1)(e) GDPR.

The DPA also noted that the storage period should not only be adequate in sight of the purposes of the processing, but should also be individualised per each purpose.

The authority also found that the controller had not properly informed their employees about the processing of geolocation data. The only information provided to the employees consisted on a sticker on the vehicles and a plastic sheet attached to the vehicle documentation. There was also not enough information about the system on their privacy note.

The CNPD therefore considered that the controller had infringed Article 13.

For these violations, the DPA fined the controller €2800, and ordered them to implement a policy for providing the necessary information to the employees, as well as to implement adequate retention periods. Additionally, the DPA ordered the controller to implement, in accordance with Article 32(1) GDPR, access measures to the geolocation data, with a system that allows the data subject to authenticate themselves in order to access it.",NONCOMPLIANT,"Article 5, Article 13, Article 32","[12,38,0,17,31]"
"The Luxembourg DPA (CNPD) launched an investigation against a corporate group for the use of videocameras in the premises of two of their companies.

The cameras were used for protecting company's goods and for security in the access, in the case of company A, and for the protection of company's property, control of the access, and to prevent work accidents, in the case of company B.

Two of the cameras included in their recording images of public spaces or buildings.

Additionally, the retention period of the images implemented by the companies was of 3 months.","The CNPD remarked, in the first place, that the cameras should not record images of public spaces or buildings. In case that such images had to be recorded due to the angle or placing of the cameras, that part of the image should have been blurred.

Therefore, the CNPD concluded that the controller had infringed Article 5(1)(c) GDPR by recording images of public spaces or buildings.

Secondly, the CNPD considered that the storage for 3 months was excessive in any case. The default period, according to the authority, should be of one week, that might be extended to 1 month, for specific purposes, when justified.

Therefore, the CNPD concluded that the controller had infringed Article 5(1)(e) GDPR by having a retention period of the recorded images of 3 months.

The authority took into account the will to cooperate of the controller and the fact that they had followed their recommendations to remedy the violations. The CNPD decided to fine the controller €1900.",NONCOMPLIANT,Article 5,"[7,16,27,34,20]"
The Luxembourgish Data Protection Authority (CNPD) conducted an investigation at a logistics company within the framework of a global investigation campaign on the function of Data Protection Officer (DPO) in both private and public sectors.,"Following their investigation at the company, the CNPD found:

1. that the company's DPO did not seem to be invited to all relevant meetings for them and that it therefore could not be considered that they were involved properly and in a timely manner in all issues which relate to the protection of personal data as required by Article 38(1) GDPR;
2. that the DPO did not report directly to the highest level of management at the company, thus not ensuring that the DPO could act without receiving any instructions regarding the exercise of their tasks pursuant to Art. 38(3) GDPR;
3. that, though it could reasonably be expected that the DPO did a formal and frequent reporting on their activities to the management, such a reporting had not been set up and that the company therefore did not meet the requirements of Article 39(1)(a) GDPR which states that the DPO should inform and advise the controller;
4. that the company had not been able to demonstrate that they had an audit plan for the year, thus violating Article 39(1)(b) GDPR regarding the DPO's duties to monitor compliance with GDPR.

In view of those violations, the CNPD:

* imposed an administrative fine of fifteen thousand euros (€15,000) on the company;
* ordered them to comply with Articles 38(1), 38(3), 39(1)(a) and 39(1)(b) GDPR within four months of the notification of the decision.",NONCOMPLIANT,"Article 38, Article 39","[49,37,21,41,6]"
"On 22 November 2018, the Luxembourg DPA (National Commission for Data Protection, ""CNPD"") decided to open an investigation on a group of companies and their GDPR compliance, especially regarding video surveillance and geolocation systems implemented by the affiliates.

During the on-site investigation of one of the companies, CNPD officers found that the range of vision of two cameras included parts of the public highway, while six cameras allowed for continuous monitoring of the workstations of the employees working there.

Afterwards, the NCPD received proof that the range of vision of the two cameras have been modified so that they no longer target the public highway.

Regarding Article 13 GDPR, the CNPD notes that during the on-site visit by the CNPD officers, third-parties and employees were informed of the presence of the video surveillance system by a pictogram consisting of a video-camera symbol and bearing the words ""Local under video surveillance"".

The CNPD received a document entitled ""Information to workers - Privacy protection"" as an appendix of a letter from the company indicating that it will be placed on the internal network so that it can be updated regularly.","Regarding the video cameras, the NCPD held that non-compliance with Article 5(1)(c) GDPR in respect of the two above-mentioned cameras was established on the day of the on-site visit, even if the controller changed the range of vision to make it compliant afterwards.

In the same way, the CNPD considered that non-compliance with Article 5(1)(c) GDPR in respect of the six other cameras was established too.

Regarding the information of the cameras, the CNPD held that the pictogram did not contain the required elements of the first level of information (essential information) for either employees or third-parties, since it only informed about the recording but did not provide any more of the information required by Article 13 GDPR. Furthermore, the CNPD held that the document entitled ""Information to workers - Privacy protection"" did not contain all the information required by Article 13 GDPR.

Therefore, the CNPD concludes that at the time of the on-site visit of the CNPD officers, the company was not compliant with Article 13 GDPR.

The CNPD held that the controller infringed Article 5(1)(c) GDPR and Article 13 GDPR and decided to:

- impose an administrative fine of €7,600 on the controller,

- issue an injunction to the controller to bring the processing into compliance with the provisions of Article 13 of the RGPD, within a period of two months following notification of the decision, with proof of compliance to be sent to the CNPD at the latest, within this period.",NONCOMPLIANT,"Article 5, Article 13","[40,8,22,48,12]"
"The CNPD carried out an audit on the premises of a company (the Company) to verify whether the latter was complying with the GDPR, in particular with respect to the installation of video surveillance cameras in the building and of geolocation tracking devices in the vehicles of some of its employees.","During the audit carried out by the CNPD, the CNPD found that the Company had failed to comply with several obligations relating to the principles of transparency and data minimization.

On the use of video surveillance cameras

Regarding the use of video surveillance cameras, first, the CNPD found that the Company had violated the principle of data minimisation as well as the obligation to properly inform data subjects about the processing.

Violation of the principle of data minimisation

According to the CNPD, the principle of data minimisation in the context of video surveillance implies that (i) the Company should only record what appears strictly necessary to achieve the purpose(s) of the processing, i.e. protecting the Company's  assets and securing access to the building and (ii) that the processing operations must not be disproportionate.

In this case, the CNPD found however that one of the cameras had been installed in such a way that the field of vision included the staff dining hall. Employees were thus potentially being monitored during their free time. The CNPD considered that installing cameras and filming the employees in places designed for private use is disproportionate. In particular, the CNPD pointed that the fundamental rights and freedoms of the employees (including their right to privacy) were prevailing over the legitimate interests of the employer to use video surveillance cameras foe security purposes.

The CNPD further found that the outdoor camera's field of vision included part of the public street as well as an adjacent site (i.e. the parking lot and the entrance of a shop located in front of the Company's building). The CNPD admitted that, depending on the configuration of the premises, it is sometimes impossible to limit the field of vision of the camera to private premises only. Sometimes, a small portion of the street or of the surrounding is also being recorded. In such a case, however, the CNPD considers that the data controller should implement masking or blurring techniques in order to limit the field of vision of the camera to its private property.

In view of the above, the CNPD concluded that the Company had been acting in breach of the the principle of data minimization (Article 5(1)(c) GDPR).

Violation of the information obligations

Informing the data subjects about the processing of their personal data is an essential element of the principle of transparency. The CNPD noted during the  on-site audit that the existence of the video camera surveillance system was not notified to visitors. Furthermore, the employees were not duly informed about all the points listed in Article 13 GDPR.

After the on-site audit, the Company adopted several measures in an attempt to remedy that breach, such as displaying stickers with a warning sign and an information sheet at the entrance to the building about video camera surveillance. The CNPD found however that these measures were not sufficient to fully comply with Article 13 GDPR. In this respect, the CNPD recommended to adopt a ""multi-layer communication approach"": (i) the first layer of information (e.g. a warning sign accompanied with a short text) should generally convey the most important information, such as the existence of a processing, the purpose of the processing, the identity of the controller, etc, as well as the way to obtain further information ;  (ii) the second layer of information, which must include the rest of the elements listed in Article 13 GDPR, should be made easily accessible to the data subject, for example in the form of a comprehensive information sheet available at a central location (e.g. information desk, reception or cashier) or displayed on an easy accessible poster. As mentioned above, the first layer of information should clearly refer to the second layer of information.

Based on these elements, the CNPD found that the Company had violated Article 13 GDPR.

On the use of geolocation tracking devices

During the on-site audit, the CNPD found that the employees were not informed of the presence of the geolocation system in some of the Company's vehicles, except in some instances orally. The CNPD referred to the guidelines of the Article 29 Working Group on the transparency principle, and in particular to the fact that to controllers should always keep a written record of the measures that they have adopted, so that they are able to prove compliance with the obligation set out in Article 13 GDPR. because the Company was not in position to prove that all its employees had been duly informed about the use of geolocation tracking device, the CNPD found that the Company had violated Article 13 GDPR.

Considering the severity and extent of those violations, the CNPD imposed a fine of €5300 on the Company. The CNPD also issued an injunction against the Company to adopt corrective measures in order to bring its processing operations into compliance with the GDPR within a period of two months. in particular, the Company was ordered to:  (i) modify the field of vision of the cameras, (ii) inform third parties in a clear and precise manner about the video surveillance system by providing them with all the information set out in Article 13 GDPR, (iii) inform employees individually in a clear and precise manner about the video surveillance system and tracking devices in their cars by providing them with the information set out in Article 13 GDPR.",NONCOMPLIANT,"Article 5, Article 13","[5,0,19,37,40]"
"Given the importance of the role of DPOs within organizations which need to appoint one, the Luxembourg DPA (the CNPD) launched an audit campaign on the DPO's function defining 11 audit objectives. As part of this campaign, the CNPD carried out 28 audits within different organizations.","During the audit proceeding carried out by the CNPD on the role of the DPO within a company (hereafter, the Company), the CNPD found that the Company had fail to comply with several obligations relating to the appointment and role of DPO. In particular:

* a violation of the obligation to appoint the DPO based on his/her professional qualities (Article 37(5) GDPR): according to the CNPD, this objective is met if the DPO to have at least three years of professional data protection experience. In this case however, the audit report pointed that the DPO did not have any particular expertise in data protection at the time of his appointment, but had been appointed because of he already had the position of ""Chief Compliance & Legal Officer” within the Company. In response to this finding of the audit report, the Company sent additional documents to the CNPD proving that the DPO had more than three years of professional experience in the field of data protection;
* a violation of the obligation to involve the DPO in all matters related to the protection of personal data (Article 38(1) GDPR):  according to the CNPD, this objective is met if the DPO is formally and frequently participates in the executive committee, project coordination committees, new product committees, security committees or any other committee deemed useful in the context of data protection. The audit report pointed that this was not foreseen in the Company's procedures . The Company took steps to formalize the involvement and presence of the DPO in the structural consultative bodies, as well as in internal procedures and policies as a measure to be in line with the legislation and the guidelines of the WP29.
* a violation of the obligation to provide the DPO with the necessary resources (Article 38(2) GDPR): according to the CNPD, this objective is met if at least one full time equivalent (FTE) is allocated to the DPO team (i.e. one person working full time as a DPO), and has the opportunity to rely on other services, such as the legal department, IT, security, etc. During the audit, it was found that the resources allocated to the data protection team were approximately 0.7 FTE. In addition, the time allocated to the DPO in terms of data protection task was not defined. In response to the audit report, the Company announced that the management had decided that the DPO would carry out his duties on a full-time basis (one FTE)
* a violation of the obligation to ensure that the DPO has the task to monitor compliance with the GDPR with the policies of the controller (Article 39(1) GDPR): according to the CNPD, this objective is met if the organisation has a formalized data protection control plan, where the monitoring tasks of the DPO team are defined. The audit report found that the Company had some specific procedures in place (such as for answering data subject requests), but did not have monitoring procedures in place. In response to this finding, the Company disclosed documents to show that internal compliance and monitoring procedures were implemented regarding the processing of personal data, and that those procedure were frequently revised.

Although the audit report had identified four data protection violations and had proposed to impose a sanction based on all four violations, the CNPD only upheld two breaches in its decision, taking into account the measures that were already implemented by the organization in the course of the audit proceeding to remedy the breaches of Article 38(1) GDPR and Article 39(1)(b) GDPR. The CNPD noted however that these measures were taken after the start of the investigation, and that the Company had therefore failed to be compliant beforehand. As a result, the CNPD imposed a fine of €13,200 on the Company.",NONCOMPLIANT,"Article 38, Article 39, Article 83","[0,20,21,14,19]"
"The controller in this case is a car dealership that installed video surveillance cameras in its garage.

In the context of a broader investigation into video surveillance practices in the country (see very similar case here), the Luxembourg DPA inspected whether the car dealership had installed such cameras in its garage. Prior to this inspection, the company declared it did not use such cameras. However, the DPA visited the garage and found evidence of the contrary.

It therefore opened an investigation to determine whether these were lawfully installed.","First, the Luxembourg DPA assessed whether the company complied with its information obligations under Article 13 GDPR. It started by affirming that only what is strictly necessary to achieve the pursued aims can be filmed, and that the processing operations cannot be disproportionate when assessed against their purpose. Companies seeking to lawfully install such systems are therefore required to set out the exact purposes of the processing prior to their installation.

During the investigation, the DPA found no information as to the existence of the video surveillance system had been provided by the car dealership. Additionally, the the employees were never notified of the existence of the video surveillance systems. The owner of the dealership argued they were not aware of the obligation to provide such information, and had only installed these to ensure customers would not have to wait if one of the receptionists were ever missing. The DPA nonetheless held the car dealership breached Article 13 GDPR by failing to provide information on the existence of the video surveillance systems.

Second, the DPA assessed whether the car dealership complied the principle of data minimisation per Article 5(1)(c) GDPR. The dealership stated the images captured by the camera were not recorded, but simply transmitted onto a screen for the owner to check whether customers were dealt with in time when the reception was not occupied. The DPA's inspector found that the field of vision of the cameras essentially allowed the constant surveillance of employees working at the reception, which they held to be disproportionate as said employees could feel constantly observed. As such, the Luxembourg DPA held the car dealership contravened Article 5(1)(c) GDPR because the cameras could be replaced with less invasive means to achieve the purpose pursued, such as a counter which welcomes customers.

Thus, the Luxembourg DPA held that the company (1) failed to comply with the principle of data minimisation by not limiting the field of vision of its video surveillance systems, and (2) failed to adequately inform its employees and third parties of their existence. It fined the dealership €1500 for these violations of the GDPR.",NONCOMPLIANT,"Article 5, Article 13","[6,16,39,45,46]"
"The processor is a transport company that installed video surveillance systems at its office. In February 2019, the Luxembourg DPA (CNPD) launched an investigation into the company's use of these video surveillance systems to assess its compliance with the GDPR.","First, the Luxembourg DPA assessed whether the company complied with the principle of data minimisation per Article 5(1)(c) GDPR. It started by affirming that only what is strictly necessary to achieve the pursued aims can be filmed, and that the processing operations cannot be disproportionate when assessed against their purpose. Companies seeking to lawfully install such systems are therefore required to set out the exact purposes of the processing prior to their installation.

During the investigation, the company argued the systems were installed to protect its goods and access to facilities, as well as to safeguard users and prevent accidents. The DPA nonetheless held that three cameras did not comply with the requirements under Article 5(1)(c) GDPR.

In particular, the camera aimed at the reception, which was unlawful because workers have a right to not be constantly monitored. The camera aimed at the ""smoker's corner"", which was unlawful because it monitored a space reserved to employees' leisure time. Finally, the camera aimed at the public road outside the office and neighboring land, which was unlawful because it was disproportionate when assessed against the purposes of the processing.

Second, the DPA assessed whether the company complied with its information obligations under Article 13 GDPR. It found that although the employees were notified of the existence of the video surveillance systems, visitors of the company's facilities had no access to this information.

Thus, the Luxembourg DPA held that the company (1) failed to comply with the principle of data minimisation by not limiting the field of vision of its video surveillance systems, and (2) failed to adequately inform its employees and third parties of their existence.",NONCOMPLIANT,"Article 5, Article 13","[14,26,39,38,48]"
"In 2018, the Luxembourg DPA (the CNPD) initiated 25 different audit proceedings both in the private and public sector with regard to the role of the Data Protection Officer (DPO) under Section 4 of Chapter 4 of the GDPR (see in particular Article 37 GDPR to Article 39 GDPR).

One of these audit proceedings concerned a Luxembourg public entity (hereafter, the controller). During the audit, it was found by the head of investigation of the CNPD that :

(1) the controller had failed to publish the contact details of its DPO on its website in a way that made them easily accessible for data subjects, in breach of Article 37(7) GDPR. In particular, the contact details were not easy to find and only accessible in English. The controller decided to address this issue in the course of the investigation and published the contact details of the DPO in another language on its website.

(2) the controller had appointed an external DPO - a lawyer specialized in data protection law - on the basis of professional qualities and, in particular, expert knowledge of data protection law and practices, in compliance with Article 37(5) GDPR;

(3) the controller had failed to ensure that the DPO was involved, properly and in a timely manner, in all issues which relate to the protection of personal data, in breach of Article 38(1) GDPR;

(4) the controller had failed to implement the necessary control procedures that would have allowed the external DPO to duly monitor the compliance of the controller's data processing practices with the GDPR, in breach of Article 39(1)(b) GDPR;

(5) the controller had failed to allocate to the external DPO the necessary resources for the latter to carry out his/her tasks, in breach of Article 38(2) GDPR;

(6) the controller was not responsible for (potential) conflict of interest of the external DPO under Article 38(6) GDPR, the latter being an external DPO and a lawyer subject to the Luxembourg law of 10 August 1991 on the profession of attorney and deontological rules.","Following the audit and the report from the head of investigation, the CNPD found that the controller had been in breach of four distinct obligations relating to the role of the DPO under the GDPR, as specified below.

Regarding the breach of  Article 37(7) GDPR, the CNPD considered that the contact details of the DPO were not easy to find on the website of the controller, and were only accessible in English, and not in any of the official languages of the Grand Duchy of Luxembourg. Despite this issue having been addressed by the controller in the course of the investigation, the CNPD considered that there had been a breach of Article 37(7) GDPR.

Regarding the breach of Article 38(1) GDPR, the CNPD considered that the DPO had not been sufficiently involved in all issues relating to data protection law. In particular, the  pointed out that the external DPO could not voluntarily intervene but only acted when requested to do so by the controller. The fact that the controller decided, in the course of the investigation, to also appoint an internal DPO who is more regularly involved in all issues relating to data protection, did not remedy this initial breach. The CNPD therefore concluded that the controller was in breach of Article 38(1) GDPR at the time of the investigation.

Regarding the breach of Article 39(1)(b) GDPR, the CNPD concurred with the opinion of the head of the investigation, according to which the controller had failed to implement the necessary control procedures that would have allowed the external DPO to duly monitor the compliance of the controller's data processing practices with the GDPR. The CNPD acknowledged that it is possible for an organization to rely on the services of an external DPO, such as a lawyer, for monitoring compliance with the GDPR. However, the CNPD specified that the role of the external DPO must then be formalized in the form of a control plan or monitoring procedures, to ensure that the DPO is able to effectively advise and accompany the organisation for the purpose of data protection compliance.  Because such control plan or monitoring procedures had not been put in place at the time the investigation was initiated, the  CNPD concluded that the controller had breached  Article 39(1)(b) GDPR.

Regarding the breach of Article 38(2) GDPR, the CNPD found that controller had failed to allocate to the external DPO the necessary resources for the latter to be able to carry out his/her tasks. In particular, the CNPD noted that the number of hours where the DPO worked for the controller did not amount to a full-time employee. Rather, the DPO usually worked between 20 and 108 hours every month, which amounts to 12,5 to 70% of a full time employee. Although the controller addressed this issue by hiring another DPO in the course of the investigation, the CNPD concluded that the controller had  been in breach of  Article 38(2) GDPR prior to this change.

For all these reasons, the CNPD issued an injunction against the controller to bring its practices in compliance with the GDPR for the remaining breaches (with a deadline of 6 months for remedying those breaches), and also imposed an administrative fine of €18,000 on the controller.",NONCOMPLIANT,"Article 37, Article 38, Article 39","[29,47,39,8,11]"
"A Portuguese municipality started to share on its page on Facebook information about Covid 19 contention measures since the beginning of the pandemic. This municipality shared that, in March 2020, a couple of citizens had been diagnosed with Covid 19 after traveling to France, also informing their place of residence and the period of the trip. The information was deleted from social media two months later.

The Portuguese DPA (CNPD) launched an investigation on the matter. The municipality was notified about the decision's project involving violation of the GDPR, specifically lawfulness, fairness and transparency principles and the possibility of a subjection to an administrative fines up to €20,000,000 in January.

In its defense, the municipality alleged the lack of legitimacy of the original person that brought up of the facts, the lack of guidance from the CNPD on the matter, the conflict between the rights of infected people and the rights of all other people, and the impossibility of identifying the infected holders between all the inhabitants of the place where they live with the information disclosed about the displacement to France.","The CNPD concluded that the municipality had violated the GDPR by processing personal data as it did, revealing people's health information, as well as information about the trip taken by the patients and the period in which it occurred. As a controller, the municipality should be aware of how to carry out the respective processing of personal data.

The Portuguese DPA considered that the case encompasses the biggest violation that can be made to the GDPR as it violates one of the basic principles of data protection, the principle of lawfulness, and also highlighted the fact that the infringement lasted two months.

The authority also highlighted the fact that as the case involved the processing of sensitive data, which constitutes a special category of personal data which processing must be based on one of the legal bases set out in article 9, since generic processing is prohibited, and remarked that such information shall remain confidential, since sensitive data can potentially cause discrimination and stigmatization for data subjects.

The CNPD fined the Municipality €2500. In order to determine the amount, the CNPD took into account the financial situation of the public sector and, also, as a mitigating factor, the absence of economic benefit in the performance of the infringement.",NONCOMPLIANT,"Article 5, Article 24, Article 83","[2,6,9,30,36]"
"The controller had installed in its facilities a video surveillance system with 9 cameras and 1 recorder. During an inspection to the facilities by the public police forces, officers found that no signage warning passers-by about the functioning of such a system was posted. The situation was reported to the Portuguese DPA.","The Portuguese DPA stresses that the controller should have known that it was obliged to post the aforementioned signage and that such signage should have contained all elements from article 13 GDPR.  When deciding on the amount of the fine, the Portuguese DPA considered that the controller fully cooperated with the police forces' and the CNPD's investigations.",NONCOMPLIANT,Article 13,"[13,26,2,42,40]"
"CNPD's investigation revealed that the hospital’s staff, psychologists, dietitians and other professionals had access to patient data, notably data which was part of the Electronic Patient Records (EPR) - which should only be accessed by doctors - through their information system accounts. The profile management system revealed other flaws, as the hospital had 985 registered doctor profiles, while only having 296 doctors. Moreover, doctors had unrestricted access to all patient files, regardless of the doctors' specialty.","While the controller argued that (i) professionals other than doctors needed access to health data to fulfill their roles and that (ii) system access permissions were not configured by the controller, but by the Health Ministry's shared services (SPMS), the Portuguese DPA found that it was the controller who voluntarily determined said professionals should have indiscriminate access to EPRs and that the controller never asked SPMS to adjust the hospital's professionals' access profiles.  When determining the amount of the fine, the Portuguese DPA took into account the number of affected data subjects (dozens of thousands), the nature of the personal data at stake (health-related data) and the intentional character of the breach by the data controller (who did not implement a reliable audit system after a prior instruction by the DPA).",NONCOMPLIANT,"Article 5, Article 32","[5,12,36,43,42]"
"In this particular case, the employee had no possibility to refuse or withdraw such consent without negative consequences, because without consent a person would not have been offered employment. In addition, the DPA considered that, in principle, consent should not be used as a basis for data processing in the relationship with the employee due to the imbalance of the parties. An employer should explore the specific exceptions in Article 9(2)(b) GDPR to Article 9(2)(j) GDPR to lawfully process health-related data of employees.

An employee who worked for the company Sea Chefs Cruises Ltd (the controller) lodged a complaint in Germany against the company. The complaint was transmitted to the Commissioner for Personal Data Protection (Cyprus SA), which was acting as the lead authority in this matter.

The complainant considered a document named “Authorization for release of medical records"" as violating the GDPR provisions. The above document is required by the company from its employees before beginning work on a ship to have access to their medical records to be able to assist the employees with medical care, arrange any associated travel and handle any medical claim, in the event of a medical incident taking place onboard.

The information provided by the company concerning the requirement to sign an authorization indicates that a person may refuse to give authorization, but it would then not be possible to employ that person on the ship due to the company's inability to fulfil its obligations under the collective agreement, to provide medical assistance if necessary, or to establish that the person is fit to work.","The DPA ordered the controller: a) to cease the processing of health data of employees based on consent, b) to bring the processing operations into compliance with the provisions of the GDPR and in particular to take actions as to process only those health related data in the employment context which are necessary for the discharge of obligations laid down by law or by the collective agreements for the purposes of the recruitment, the performance of the contract of employment, health and safety at work, and the exercise and enjoyment of rights and benefits of employees, c) to inform the Commissioner on the actions taken to comply with this Decision at the latest within one month from the date of this decision.",NONCOMPLIANT,"Article 4, Article 5, Article 7, Article 9","[14,44,19,30,28]"
"In April 2019, Client A asked Hellenic Bank to update his information. During the updating process, a typing mistake occurred with his passport number. At the time of the mistake, the wrong passport number didn't match with that of any client. In May 2019, Client B needed to verify his information, too, but his new passport had the number that the bank employee had mistakenly typed as Client A's passport number.

The result of the abovementioned timeline was that client B had partial access through the web banking platform to client A's personal and financial data. When B noticed that, he informed the Bank, and the access issue was resolved. But due to the passport number mistakenly matching, the Bank's system automatically merged the postal addresses of both clients. After two months, client B received a debit card with client A's name on it.","According to Article 33 of GDPR, in the case of a personal data breach, the Data Controller shall without undue delay and, where feasible, not later than 72 hours after having become aware of it, notify the supervisory authority of the personal data breach. The Cypriot Commissioner for Personal Data Protection held that that obligation also includes circumstances in which the Data Controller has the belief that these facts constitute a personal data violation. More specifically, and at least until September 2019, the bank did had not have the understanding that A's data exposure (to the B client) was as a business user. Is not a kind as to barred the duty to notify the DPA office, an ex-post evaluation that drives to findings which did not constitute a breach, especially if the beliefs changed after the period within which the duty should be carried out.

The Cypriot DPA took the opportunity and stressed the possibility for a notification in phases to the supervisory authority (Art. 33(4)). Each phase shall be defined on the basis of the speed with which the Data Controller becomes aware of the facts and the understanding of the issue.

The Cypriot Commissioner for PDP addressed another point, relevant to the risk to natural persons' rights and freedoms, regarding the view of when the General Data Protection Regulation shall be alleged or not. The Cypriot DPA finds that a two-step verification feature provides a sufficient level of protection, and under that case's circumstances, the only issue was the exposure of clients' data. In other words, these circumstances directly reduce the level of the risk.

The major part of the decision focuses on management rules, procedures and ethics, which the Bank has chosen to handle clients' personal data. The supervisory authority has noticed the inadequacy of the specific implementation of the four eyes principles by the Bank. The criticism is grounded in the system design; the workflow did not include an error-message for the second employee. The Cypriot DPA held that it is totally inefficient if the employee who is charged with the duty to double-check the client's data, is not similarly informed as the first employee who fulfils the form. Such ineffectiveness is incompatible with Article 32, which require that ""the controller and the processor shall implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk"", meaning measures such as ""the ability to ensure the ongoing confidentiality, integrity, availability and resilience of processing systems and services"".

Before her final conclusion, the Cypriot Commissioner for Personal Data Protection referred to a series of mitigating and aggravating factors, like the Bank's admissions, the lack of fraudulent intent, and the ineffectiveness of the safeguards. It's not clear if the Commissioner approaches these factors quantitative or qualitative. She didn't impose any fine but that demanded the Hellenic Bank re-evaluate and modernise its the data management.",NONCOMPLIANT,"Article 32, Article 33, Article 34, Article 38, Article 39","[31,17,26,42,4]"
"A series of media publications (printed and online press) mentioned the telecommunications company CYTA, the Social Insurance Services of the Ministry of the Ministry of Labour, Welfare and Social Insurance of Cyprus, and the Cyprus Police as data processors (due to their role regarding the mechanised system of the Social Insurance Services) involved in a scandal of leakage and/or violation of personal data of natural persons via this database, leading to the initiation of an investigation by the Office of the Commissioner for Personal Data Protection of Cyprus. The publications suggested that a member of the Police proceeded with searching for, printing and forwarding to a non-authorised recipient/third party of documents from the database.

The Commissioner brought the publications to the Police's knowledge and requested a detailed statement on its behalf regarding the alleged violations. In its statement, the Cyprus Police acknowledged that one of its members, whose professional duties included his ability to have access to the Mechanised Database on vehicle owners, acting beyond the orders of the Police, proceeded with specific searches (within the database), located and printed documents (from the database), and then passed them on to a third party (a retired Police Officer).","The Commissioner held that the existing supervising mechanisms of the Police were not operating properly at that time or at least they did not operate as efficiently as they should and, thus, were considered insufficient. The organisational and technical measures that the Police had taken were not effective and they proved themselves insufficient and unable to prevent the non-authorised forwarding of personal data to third-parties. The undertaking of further organisational measures and the frequent undertaking of internal controls of the tracking archives/history was deemed necessary. Thus, the Commissioner concluded that Cyprus Police was responsible for a violation of Article 32 par.1(b) & (d) and par.(4) GDPR, as a result of the acts and/or omissions of the Police, whose member proceeded with a non-authorised forwarding of personal data found within the Police's database of vehicle owners to a third party, thus exceeding their authority and the orders of the Police. The Commissioner then provided a specific time frame for the submitting of all the reasons for which no sanction of the GDPR Article 58 par.2(a), (b), (e) & (i) should be imposed on Cyprus Police. Eventually, the Commissioner decided to impose the proportional and logical administrative fine of € 6000. In order to reach this conclusion, the Commissioner took into account as positive actions of the Cyprus Police the following ones:

- The Police took a number of corrective measures in order to deal with the event and for avoiding similar events in the future.

- The Police proceeded with the informing of the natural persons whose personal data were involved in the incident.

- The Police proceeded with corrective measures regarding its member who perpetrated the already mentioned actions (suspension etc.).

- The Police proceeded with training of new members of its force regarding issues of security and confidentiality and with more intensive supervisory control over the database.

Additionally, to conclude to the imposed the fine, the Commissioner took not of the following events as aggravating circumstances: the fact that the Police initiated the process of investigating the incident only after the publication of said articles in the press.

Lastly, it should be underlined that with the issuance of this Decision, the process of the ex-officio investigation of the Commissioner regarding the leakage of personal data by CYTA (Decision 2017 administrative fine € 10000) and Social Security Services (Decision 2019 administrative fine € 9000) was completed.",NONCOMPLIANT,"Article 32, Article 58","[31,37,7,35,14]"
"In June 2018, the DPC initiated a connected series of own-volition inquiries under sections 110 and 123 of the 2018 Irish Data Protection Act. They concerned surveillance technologies deployed by state and local authorities and An Garda Síochána  (the Irish Police) for law enforcement purposes. The DPC inquiries were to establish whether any data processing was in compliance with the data protection laws and to ensure that sufficient accountability measures were in place before further investment into new technologies.

The DPC investigation unveiled the inventory of 401 CCTV cameras that were deployed in various locations across Limerick City and County, including bicycle and walkway routes, housing estates, traveller accommodation sites and public spaces. The cameras were subject to constant real time surveillance. Separately, the Limerick City and County Council (Council) had two drones in operation.","The DPC identified a total of 48 issues in the course of the inquiry. The most important issues determined that the Council:

a) had no lawful basis for the processing of personal data by CCTV cameras for traffic management purposes;

b) lacked a lawful basis for a number of CCTV cameras used for the purposes of countering crime;

c) lacked a lawful basis to carry out surveillance with CCTV cameras which employed Automatic Number Plate Recognition technology;

d) infringed Article 15 GDPR by rejecting subject access requests in respect of CCTV cameras used for traffic management purposes;

e) did not fulfil its transparency obligations under Article 13 GDPR by failing to erect signage in respect of its CCTV processing operations;

f) infringed Article 12 GDPR by failing to make its CCTV Policy more easily accessible and transparent.

The DPC exercised the following corrective powers:

a) A temporary ban on the processing of personal data with CCTV cameras at a number of locations used for the purposes of criminal law enforcement until a legal basis can be identified.

b) A temporary ban on the processing of personal data with CCTV cameras used for traffic management purposes until a legal basis can be identified.

c) An order to the Council to bring its processing of personal data into compliance taking certain actions specified in the decision.

d) A reprimand in respect of a number the Council’s infringements.

e) An administrative fine of €110,000.",NONCOMPLIANT,"Article 6, Article 12, Article 13, Article 15","[6,26,48,7,15]"
"The controller is Bank of Ireland (BOI). Between 9 November 2018 to 27 June 2019, the controller submitted 22 breach notifications to the Irish Data Protection Commission (DPC) in relation to the Central Credit Register (CCR). The CCR “is a centralised system that collects and securely stores information about loans” and is managed by the Central Bank of Ireland.

Every loan in upwards of €500 is to be reported to CCR. This information is then used to “generate individual credit reports on borrowers, which they and, in certain circumstances, lenders can access.”

The controller informed the DPC that inaccurate customer data was uploaded to the CCR by the controller “which gave an erroneous view of BOI’s customers’ finances and credit history.” Considering the nature of breach and possible contravention of Data Protection Act and GDPR, the DPC commenced an investigation, and framed the following four issues.

The Preliminary Issue was whether the incidents described in the breach notifications reported by the controller to the DPC fall within the definition of a “personal data breach” under Article 4(12) GDPR. Issue 1 concerned the question whether the controller had infringed Article 33 GDPR in the manner in which it reported personal data breaches (if any personal data breaches were found in this decision) to the DPC. Issue 2 concerned whether the controller had infringed Article 34 GDPR and Issue 3 considered whether the controller had infringed Article 32 GDPR.","The DPC examined each of the 22 breach notifications and determined that 19 of them constituted a personal data breach as per Article 4(12) GDPR as they included unauthorised disclosures of customer personal data to the CCR and accidental alterations of customer personal data on the CCR.

Moreover, the controller contravened Article 33 GDPR with respect to 17 personal data breaches as it failed to “report the personal data breach without undue delay” and “provide the information required” under Article 33(3) GDPR in respect of some personal data breaches. The controller also contravened Article 34 GDPR as it did not inform the data subjects about the personal data breaches without undue delay at least in 14 personal data breaches.

The DPC also determined that the controller's ""processing of personal data in relation to the CCR presents a high risk, both in likelihood and severity, to the rights and freedoms of natural persons.” However, it found that the controller “failed to implement robust validation procedures and quality assurance controls” and contravened Article 32(1) GDPR.

Considering the nature of the personal data breaches, which were caused due to negligence, and the mitigating factors of BOI having taken corrective steps, the DPC imposed an administrative fine of €463,000 on BOI.",NONCOMPLIANT,"Article 4, Article 32, Article 33, Article 34","[23,20,8,2,43]"
"The Council’s IT team was first alerted on 17 February 2020 via Office 365 of the suspected creation of a forwarding/redirect rule in relation to an account of a staff member. Between 17 February 2020 and 6 March 2020, 4 similar alerts were triggered with severity levels varying from low to high. The Council’s IT team reacted to these alerts by changing the staff member’s password and by checking the server for virus threats. The Outlook client or user’s OWA personal access (and the forwarding rule) were not initially checked. The issue was tackled as low severity until 6 March 2020, which was also the date when the Council’s DPO was first alerted.

The DPC received notification of a personal data breach from the Council on 9 March 2020. The breach notification indicated a potential contravention of the data protection legislation by the Council. The breach notification stated that a phishing email had been received and accessed by two members of staff in the Council.

Further investigation of the incident unveiled that two staff members responded to phishing emails by entering their passwords online. This caused a script to be activated that established an auto forwarding rule to an external Gmail account. The staff members were not aware that they entered their passwords online and perceived it to be a normal activity. In total, 323 email messages were forwarded to the external Gmail account.  Some of these emails contained the vetting status details of 9,735 teachers, including names, addresses, PPS numbers and vetting clearance status. The teachers’ personal details were shared internally via emails with unprotected excel spreadsheets.","The DPC imposed an administrative fine of €60,000 on the Council. The decision issued the Council with a reprimand in respect of the infringements.

The DPC identified, amongst others, several shortcomings of the Council's technical and organisational security measures:

Firstly, the personal data was shared via excel spreadsheet generated by one staff member and sent to another via email while a shared drive should be used instead.

Secondly, the Acceptable Usage Policy in place at the time of the breach contained a section on password usage, but only in respect of the circulation of external documents. The spreadsheet which was generated was therefore sent unencrypted and without password protection over an inadequately secured email system, which had allowed the creation of forwarding rules.

Thirdly, the Council did not have Advanced Threat Protection enabled in Office 365 due to licensing issues.

Further, the Council did not implement adequate technical and organisational measures to account for human error.

With regard to the delayed data breach notification, the DPC decided that the Council failed to appropriately investigate and follow all appropriate steps, and ignored the specifics of an alert when received. As a result, the Council failed in its obligation to notify the DPC of the breach within the prescribed time period of obtaining knowledge of a data breach.

With due regard to the measures already implemented by the Council since the personal data breach and during the inquiry, a deadline of 2 June 2022 was given to the Council to bring its processing operations into compliance with Articles 5(1) and 32(1) GDPR.",NONCOMPLIANT,"Article 5, Article 32, Article 33","[2,3,39,43,48]"
"The controller is Men Overcoming Violence Ireland (""MOVE""), a registered charity that works in the area of domestic violence, with a primary aim of supporting the safety and wellbeing of women and their children who are experiencing, or have experienced violence/abuse in an intimate relationship. MOVE does this by facilitating men (participants) in weekly group sessions.

The personal data breach concerned the loss of eighteen SD Cards that may have contained recordings of group sessions of MOVE’s programme where participants discuss their behaviour and attitudes with regard to domestic violence with a facilitator. Whilst the recording of group sessions focused on the delivery of sessions by the facilitators, some of the participants may have been seen and heard in the recordings; furthermore the personal data on the SD Cards included participants’ disclosure of behaviours, feelings and attitudes towards current or ex partners, other family members and friends, who may have been named by the participants. MOVE submitted that 80 to 120 men may have been affected by this personal data breach and, at least, one facilitator per each recorded session.","The Irish DPA (DPC) held that MOVE infringed Article 5(1)(f) GDPR and Article 32(1) GDPR by failing to implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk presented by its processing by means of recording group sessions on SD Cards containing participants’ and facilitators’ personal data.

The DPC imposed an administrative fine of €1500 on MOVE. Furthermore, it issued MOVE with a reprimand in respect of the infringements and ordered it to bring its processing activities into compliance with Article 5(1)(f) GDPR and Article 32(1) GDPR.",NONCOMPLIANT,"Article 5, Article 32","[24,38,39,18,46]"
"The Irish DPA (DPC) investigated a series of twelve data breach notifications it received in the six month period between 7 June 2018 and 4 December 2018.  The inquiry examined the extent to which Meta Platforms complied with the requirements of Articles 5(1)(f), 5(2), 24(1) and 32(1) GDPR in relation to the processing of personal data relevant to the twelve breach notifications.","The DPC fined Meta Platforms €17,000,000 for the violation of Article 5(2) GDPR and Article 24(1) GDPR for failing to implement appropriate technical and organisational measures which would enable it to readily demonstrate the security measures that it implemented in practice to protect EU users’ data, in the context of the twelve personal data breaches.

The DPC's decision was subject to the co-decision-making process outlined in Article 60 GDPR and all of the other European supervisory authorities were engaged as co-decision-makers since the processing under examination constituted cross-border processing.  While objections to the DPC’s draft decision were raised by two of the European supervisory authorities, consensus was achieved through further engagement between the DPC and the supervisory authorities concerned.",NONCOMPLIANT,"Article 5, Article 24, Article 32, Article 60","[26,14,31,38,10]"
"This DPC decision is the result of an own-volition inquiry pursuant to section 110 Data Protection Act 2018. It was prompted by various complaints sent by individual data subjects as well as a mutual assistance request from the German Federal Data Protection Authority concerning WhatsApp’s transparency obligations following the entry into force of the GDPR in May 2018.

The inquiry focused on:

1. WhatsApp’s transparency obligations in the context of non-users under Articles 14 and 12(1) GDPR
2. WhatsApp’s transparency obligations in the context of users under Articles 13 and 12(1) GDPR.
3. WhatsApp’s transparency obligations in the context of its relationship with other Facebook Companies and any sharing of user data in the context of that relationship.

Following an investigation lasting from December 2018 to December 2020, the DPC submitted a composite draft decision to other DPAs in accordance with Article 60 GDPR. On 24 December 2020, it referred the objections to the EDPB, as required by the Article 65(1)(a) dispute resolution mechanism. The EDPB then adopted its binding Article 65 GDPR decision on July 28 2021.

Consequently, the DPC amended its draft to take into account the EDPB’s determination of the various objections from the other DPAs which it deemed to be “relevant and reasoned” for the purpose of Article 4(24) of the GDPR. Notably, it required the DPC to find that WhatsApp failed to comply with the key principle of transparency set out in Article 5(1)(a) GDPR, a matter it had not originally assessed.","First, it found WhatsApp denied non-users their right to exercise control over their personal data by failing to provide them with the information prescribed by Article 14 GDPR.

Second, it held WhatsApp failed to provide users with sufficiently meaningful information regarding nearly every category of information to be provided under Article 13 GDPR, making it impossible for them to adequately consider and exercise their data rights.

Third, it included an infringement of the key principle of transparency under Article 5(1)(a) GDPR in its final decision following an objection to its original decision by the Italian SA and a decision by the EDPB.

WhatsApp’s transparency obligations in the context of non-users under Articles 14 and 12(1) GDPR

In its assessment of WhatsApp’s processing of non-user personal data, the DPC first analysed how the ‘Contact Feature’ operates in practice. It found that the data it generates, a table of lossy hashes together with the associated users’ mobile phone numbers, is personal data because non-users are identifiable. It held WhatsApp processed this personal data as a controller due to the degree of control it has over the purposes and means of that processing.

Having concluded WhatsApp processes non-user personal data as a controller, the DPC evaluated its compliance with the transparency obligations set out in Articles 14 and 12(1) GDPR.

WhatsApp argued that it took “appropriate measures” to inform non-users of the “very limited ways” in which it processed their personal data. This was supposedly done by stating users provide the company with all their contacts’ phone numbers in their Privacy Policy.

The DPC rejected this argument, pointing out the lack of a discoverable and accessible “public notice” that would provide non-users of WhatsApp services with the information they are entitled to under Article 14. For example, they should be provided with details about the “circumstances in which any non-user personal data is shared with any of the Facebook Companies”. It emphasised that the burden of preparing such information is outweighed by “the role and utility of the right to be informed”.

€75,000,000 of the total fine are attributable to the infringement of Article 14 GDPR.

WhatsApp’s transparency obligations in the context of users under Articles 13 and 12(1) GDPR

The DPC first considered WhatsApp’s submissions of a general nature, and divided them into four categories. Then, it in turn considered how WhatsApp conveyed to users the information required by the sub-clauses of Articles 13(1) and 13(2) GDPR, asking two questions as part of every assessment:

-“What information has been provided?”

-“How has the information been provided?

Submissions of a general nature

Submissions concerning WhatsApp’s willingness to amend its Privacy Policy and related material.

The company contended any changes it made to its policies in response to the Preliminary Draft it was provided should be taken into consideration when the DPC determined whether a breach of the GDPR occurred. The DPC rejected this.

Submissions concerning Legal Certainty

WhatsApp argued official guidance about transparency requirements was lacking and that its policies aligned with those of industry peers. It qualified the standard to which the DPC held them in the preliminary draft as “alternative and even higher” than what is required by the GDPR. The DPC rejected both these points, citing the Article 29 Working Party’s Transparency Guidelines to support their original assessment.

Submissions concerning Inconsistency

WhatsApp suggested there were inconsistencies in the DPC’s interpretation of the Transparency Guidelines, notably about the requirement of a “concise approach” to providing information about the company’s reliance on legitimate interests. The DPC rejected this, explaining its view that there was an “over-supply of very high level, generalised information at the expense of a more concise and meaningful delivery of the essential information” in the Privacy Policies.

Submissions concerning WhatsApp’s pre-GDPR engagement with the Commission

WhatsApp defended its position “in a limited number of respects” by pointing out that the DPC did not take issue with its policies at the time of its pre-GDPR engagement. The DPC rejected this, maintaining that its function is not to approve or review policy documents for individual data controllers

Articles 13(1) and 13(2) GDPR

Article 13(1)(a) -  the identity and contact details of the controller

The DPC held this information was provided in a clear and predictable way.

Article 13(1)(b) – the contact details of the data protection officer

The DPC held this information was provided in a clear and predictable way.

Article 13(1)(c) – the purposes of the processing for which the personal data are intended as well as the legal basis for processing

The DPC stated that data subjects must be provided with meaningful information such that they know (i) which of his/her personal data are being processed, (ii) for what processing operation(s), (iii) for what purpose(s), and (iv) in reliance on which legal basis. Such information should be presented in a way that clearly links each of these elements. This “Proposed Approach” represents the minimum information required to adequately give effect to the rights of the data subject.

It analysed whether WhatsApp achieved this in regard to the individual legal bases it identified in its Privacy Policy and found the company did not.

Article 13(1)(d) – where applicable, the Legitimate Interests being pursued

The DPC originally held this information was provided in a clear and meaningful way, but amended its finding to comply with the EDPB’s binding decision.

Article 13(1)(e) – the Recipients or Categories of Recipients

The DPC held “the information provided does not enable the user to understand what categories of personal data will be sent to which category of recipient, [nor] why such transfers are being carried out and, therefore, [their] consequences”.

It criticised the excessive links between different WhatsApp documents and “scattered” manner relevant information is spread throughout them, and stated it should be presented in a clear and concise format instead.

Article 13(1)(f) -  Transfers of personal data to a third country

The DPC held controllers are required to provide information such that data subjects are informed either (i) that transfers are subject to an adequacy decision; or (ii) that transfers are not subject to an adequacy decision. The link to “a generic European Commission webpage” WhatsApp provided did not meet this standard. Instead, the DPC stated the “specific set of standard contractual clauses or specific adequacy decision” should be directly accessible.

Article 13(2)(a) – Retention Criteria/Retention Periods

The DPC held WhatsApp failed to provide meaningful information (i) in relation to the criteria that will be used to determine if, and for how long, a user’s personal data will be retained following the deletion of their account; (ii) concerning the fact that certain information will be retained, even after deletion; and (iii) to explain how such retained records are “disassociated from personal identifiers”.

Article 13(2)(b) - the existence of the data subject rights

The DPC held this information was provided in a clear and concise way.

Article 13(2)(c) – the existence of the right to withdraw consent

The DPC held whilst WhatsApp’s Legal Basis Notice referenced the right to withdraw consent, the required extent of information was not included. Further, users were not informed about how to exercise this right.

It again criticised the “piecemeal approach to the provision of the required information”, which made any effort to provide information about this right pointless.

Article 13(2)(d) – the right to lodge a complaint with a supervisory authority

The DPC held this information was provided in a clear and concise way, albeit in a confusing place.

Article 13(2)(e) - whether the provision of personal data is a statutory or contractual requirement, or a requirement necessary to enter into a contract, as well as whether the data subject is obliged to provide the personal data and of the possible consequences of failure to provide such data

The DPC originally proposed no finding under this heading, but amended its finding to comply with the EDPB’s binding decision.

Article 13(2)(f) – the existence of automated decision-making, including profiling

The DPC proposed no finding under this heading because WhatsApp does not engage in such activities.

WhatsApp’s transparency obligations in the context of its relationship with other Facebook Companies and any sharing of user data in the context of that relationship

The DPC specifically assessed the extent to which WhatsApp explained its relationship with the Facebook Companies and any consequent sharing of data.

It again criticised the manner in which the information is spread out ""across a wide range of texts"", and how a significant amount of it is so high level as to be meaningless. It pointed out how the Facebook FAQ is only linked to WhatsApp's Privacy Policy in one place. The information being provided is characterised as ""unnecessarily confusing and ill-defined"".

As such, the DPC held that WhatsApp failed to comply with its transparency obligations per Articles 13(1)(c), 13(1)(e) and 12(1) in relation to how the company works with other Facebook Companies. It notably added that ""unless WhatsApp has a concrete plan in place, that includes a definitive and imminent commencement date, to commence the sharing of personal data on a controller-to-controller basis with the Facebook Companies for safety and security purposes, the misleading elements of the Legal Basis Notice and Facebook FAQ should be deleted to reflect the true position"".

Whilst the DPC originally found WhatsApp complied with Article 13(1)(d), it changed this assessment following the EDPB's binding decision.

WhatsApp's compliance with the Principle of Transparency per Article 5(1)(a)

The DPC did not include an assessment on this issue in its original draft, but found a violation of Article 5(1)(a) following the EDPB's binding decision.

Exercise of Corrective Powers

The DPC exercised the following corrective powers:

* A reprimand pursuant to Article 58(2)(b).
* An order to bring processing operations into compliance, pursuant to Article 58(2)(d) within 3 months.
* An administrative fine, pursuant to Articles 58(2)(i) and 83, addressed to WhatsApp, in the amount of €225,000,000.

The total fine reflected these individual infringements.

i. In respect of the infringement of Article 5(1)(a) of the GDPR, a fine of €90,000,000

ii. In respect of the infringement of Article 12 of the GDPR, a fine of €30,000,000

iii. In respect of the infringement of Article 13 of the GDPR, a fine of €30,000,000

iv. In respect of the infringement of Article 14 of the GDPR, a fine of €75,000,000

It arrived to these figures after first taking a number of submissions by WhatsApp into consideration, then assessing the Article 83(2) criteria, and finally adopting the EDPB’s binding decision.

Submissions

'New and Subjective Views' Submissions

WhatsApp argued the DPC’s assessment turned on “new and subjective interpretations” of relevant GDPR articles, and that “unprecedented fines” should not be imposed where it was not aware of such a higher standard. The DPC rejected expecting this much, and gave a concrete example of how the company did not meet the standard it claimed to by citing the Transparency Guidelines’ advice on the use of “language qualifiers such as ‘may’, ‘might’, [etc]”.

'Nuanced Nature of Assessment' Submissions

WhatsApp argued that the “nature” of assessing transparency requirements is “subjective and nuanced” and that this made the DPC approach to this investigation inappropriate, pointing to the “material differences” between the views of the original Investigator and Commissioner as evidence. The DPC rejected this, arguing they were the mere “result of a divergence in approach to the inquiry itself”.

'Binary Approach' Submissions

WhatsApp argued that the DPC should not have found “either full compliance or complete non-compliance with each provision”. In response, the DPC repeated much of its earlier justifications for the findings it made to illustrate that it only assessed whether “all” the required information under every article had been provided.

'Careful and Good Faith Efforts' Submissions

WhatsApp, amongst other things, argued it considered that it met the required transparency standard because “its approach [to transparency] is aligned with the approach adopted by many industry peers”. The DPC rejected this, stating that “while an industry-wide failure (if this is, in fact, the case) to achieve compliance with the transparency requirements is a poor reflection on that industry, it is not, however, evidence of a position whereby data controllers in this particular sector are unable to identify what is required of them, in terms of transparency”.

'Willingness to Change' Submissions

WhatsApp argued that because it actively ‘volunteered’ to change the information it provides in response to the preliminary draft decisions it received, the use of corrective powers is inappropriate. The DPC rejected this, highlighting that the company’s express disagreement with the DPC’s points at previous points during the investigation “creates certain limitations, in terms of the weight [it] might attribute to WhatsApp’s willingness to change”.

'Theoretical Risk' Submissions

WhatsApp argued the DPC could not demonstrate that its approach to transparency “has in fact had any negative impact on data subject rights”. The DPC reminded the company it has no duty to demonstrate “evidence” of damage to data subjects.

Article 83(2) criteria

The DPC considered each of the Article 83(2) criteria (subsection a-k) to assess the nature, gravity and duration of the infringements as well as the duration of the infringements. The purpose of this assessment was to determine the sums to be fined in order for them to be “effective, proportionate and dissuasive” as required by Article 83(1) GDPR.

It held a fine is warranted where:

* All four infringements are very serious in nature and severe in gravity. This was the case as WhatsApp only provided ""41% of the prescribed information to users and none to non-users""
* The number of affected users was very large. The exact figure of users was redacted in the report, but this was the case. The number of affected non-users was described as ""unquantifiable"" but likely to be extremely high.
* Users are not able to meaningfully consider and exercise their data subject rights. The DPC held there was a very serious information deficit that led to this.

Further, it took consideration of the limited nature and scope of the processing in question, but stated it could not give it significant weight as a mitigating factor because of the seriousness of the infringements. It characterised all of them as negligent and the Article 14 GDPR one demonstrating ""a high degree of negligence"", which was taken into account as an aggravating factor.

The only mitigating factors it recognised as valid were the limited categories of personal data processed by WhatsApp and the company's willingness to amend its Privacy Policy and related material.

EDPB’s binding decision

See decision here for commentary.

Appeal

The decision by the EDPB underlying this case has since been appealed by WhatsApp, which brought an action to the CJEU on 1 November 2021.",NONCOMPLIANT,"Article 4, Article 5, Article 12, Article 13, Article 14, Article 58, Article 60","[20,14,49,47,26]"
"A personal data breach has been notified by the HSE to the DPC on 1 May 2019. The personal data breach occurred when a member of the public found documentation that contained the personal data of 15 data subjects, including data relating to clinical information and treatments received. The documents were created in Our Lady of Lourdes Hospital, but were discovered by a member of the public in their front garden.",The decision found that the HSE infringed Articles 5(1)(f) and 32(1) of the GDPR by failing to implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk presented by its use and disposal of hardcopy documents containing patients’ personal data.,NONCOMPLIANT,"Article 5, Article 32","[8,10,12,33,42]"
"The Irish Data Protection Commission (DPC) commenced inquiry IN-19-9-1 in respect of one personal data breach notified by the HSE to the DPC. The personal data breach occurred when documentation containing the personal data of 78 individuals, including special category personal data in respect of 6 of those data subjects, were disposed of in a public recycling centre. The list was created in Cork University Maternity Hospital, but was discovered by a member of the public in a public recycling area in Cork County.One personal data breach has been notified by the HSE to the DPC. The personal data breach occurred when documentation containing the personal data of 78 individuals, including special category personal data in respect of 6 of those data subjects, were disposed of in a public recycling centre. The list was created in Cork University Maternity Hospital, but was discovered by a member of the public in a public recycling area in Cork County.",The decision found that the HSE infringed Articles 5(1)(f) and 32(1) of the GDPR by failing to implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk presented by its use and disposal of hardcopy documents containing patients’ personal data.,NONCOMPLIANT,"Article 5, Article 32","[17,27,31,26,37]"
"Through its their bug bounty program, Twitter received a tip which classified as a vulnerability the potential impact of the breach on a world-wide user's personal data, including users around the European Union.

Although Twitter's employees and other contractors classified that incident as low risk, the tip was registered to an internal database. Due to the staff's negligence, the data protection officers of Twitter were not assigned to the ticket. That was the official reason for the delay in notifying the Commissioner of Data Protection, as Article 33(1) of the GDPR requires. That particular software is for monitoring bugs and dysfunctions, and when assigning a ticket to an employee, he or she would also receive an automated relevant notice. Under Twitter's organisational structure, only a Data Protection Officer is allowed to notify the Data Protection Commissioner.","The Recital 87 of the GDPR clearly reflects that the issue of Controller ""awareness"" and its role in terms of defining the timeframe within which notification is required to take place, must be seen through the context of the broader obligation to ensure that it has appropriate measures in place to facilitate such awareness, including an overarching responsibility to ensure that there is compliance even within the far broader principle of accountability. The term of accountability shall not be any surprise in a personal data framework. The corpus reasoning line can be visualised under the guideline that if controllers or processors need to ensure a level of security directly appropriate to the risk posed to the personal data being processed, then they should take into account the state of the art, the nature, scope, context and purposes of processing, especially where risks exist risk of varying likelihood and severity of the rights and freedoms of natural persons. Under guidelines, a combination of technical and organisational measures is at least unavoidable or foreseeable. The 87th recital exactly states that it ""should be ascertained whether all appropriate technical and organisational measures have been implemented to establish immediately whether a personal data breach has taken place and to inform promptly the supervisory authority and the data subject […]"". The bug was identified as occurring when users unknowingly disabled the protected account's setting when adding a new email to their account using the Android Mobile App.That description for the Data Protection Commissioner was not inadequate; for example, it does not reference how the bug was assessed as satisfying the criteria for being a personal data breach within the meaning of that term under the GDPR.

Article 4(12) requires existing information relating to assessing how this event led to one of the vulnerabilities. In that case, the folder of the incident was deficient by not providing further details of the personal data affected by the bug. The Company explains that as: ""A tweet is a free text field. By its very nature it may potentially contain any type of data, depending on how the user uses their account. If only one account were exposed, it might be worthwhile carrying out a specific review to determine […]. With a large number of potentially exposed accounts, one would simply assume that the exposed data could include any category of personal data"".

DPC was not satisfied by the abovementioned answer of the Company and made a reference to Article 24 which states that is ""shall implement […] measures to […] be able to demonstrate that processing is performed in accordance with [the GDPR]"". DPC summarises the legal framework and states that the requirement of a well-documented event arises by the wording of Article 33(5) and from the obligation therein to document the ""effects"" of the breach. In addition, a Data Controller must document its assessment in order to be able to demonstrate its compliance with the general requirement of Article 33(1).

On the 18.10.2021, the DPC announced a €450,000 fine under Section 143 of the Data Protection Act 2018 was confirmed by the Dublin Circuit Court.",NONCOMPLIANT,"Article 4, Article 24, Article 33, Article 65","[49,20,38,47,24]"
"The DPC commenced an inquiry after Tusla notified the DPC of three data breaches.

The breaches all involved a failure to redact personal data when providing documents to third parties, including:

-giving the father of two children in care their foster carer’s address

-giving a person who was accused of child sexual abuse the address of the child who made the complaint and the telephone number of the child’s mother

-giving the grandmother of a child in care the address and contact details of the child’s foster parents and the location of the child’s school.","The DPC held that Tusla infringed Article 32(1) GDPR by failing to carry out measures that would have ensured an appropriate level of security of the data, such as redacting the names and contact details of the children.

The DPC also held that the third breach also violated Article 33(1), because of a failure to notify the DPC without undue delay.

Aside from the €75000 fine, the DPC also ordered Tusla to bring its processing operations into compliance with Article 32(1) and issued reprimands in respect of the infringements, pursuant to Articles 58(2)(b), (d), and (i) GDPR respectively.",NONCOMPLIANT,"Article 32, Article 33, Article 58","[7,23,27,26,34]"
"A betting company is running a video surveillance system with two cameras that are mounted next to the entrance of the location. The cameras are filing a wide area of more than 20 meters that goes beyond the immanent entry area, including a public parking facility. There was no marking of the camera system and the videos were not deleted after 72 hours (as required under § 13 of the Austria Data Protection Act, ""Datenschutzgesetz""). No protocol of the video usage (as required under § 13(2) Austrian Data Protection Act) was made.","The legitimate interest for video surveillance under Article 6 GDPR has to take into account (1) the relationship between the data subject and the controller, (2) the expectation of the data subject that he may be under surveillance. People in the public space (including drivers of passing cars) do not have the expectation to be filmed by the owner of the location. Principles in Article 5(1)(a) and (c) and Article 6(1)(f) GDPR are therefore violated.

In addition there were violations against § 13 Austrian Data Proteciton Act (""DSG"") by lacking a deletion period, processing protocols and warning signs.

As parts of the violations happened before 25. 5. 2018, parts of the penalties are based on the previous national law.

The maximum fine for the first count was € 20 Mio under GDPR, while the maximum fine for the other counts was € 50.000 under national law. The fines were calculated in the following way:

* € 2.400 under Article 6(1)(f) and 83(5)(a) GDPR (illegal surveillance)
* € 800 under §§ 52(2)(6), 62(1)(4) and 69(5) DSG 2000 (missing protocol)
* € 800 under §§ 52(2)(7), 62(1)(4) and 69(5) DSG 2000 (missing deletion)
* € 800 under §§ 52(2)(4), 62(1)(4) and 69(5) DSG 2000 (missing signage)
* +10% administrative fee
* € 5.280 TOTAL",NONCOMPLIANT,"Article 5, Article 6","[46,9,31,5,45]"
"As part of its own initiative, the Latvian DPA assessed the website of HH Invest SIA. In particular, it found that HH Invest's privacy policy had not been provided to the data subjects in a systematic and comprehensible way, as required by Article 13 GDPR.","The DPA imposed an administrative fine of €15,000 on the online store, taking into account that it had actively cooperated with the DPA during the investigation and had made an effort to remedy the issues identified by the DPA. The DPA has claimed that ""as a result of this inspection, one of the largest online stores in Latvia has improved the information provided to data subjects regarding the processing of personal data"".",NONCOMPLIANT,Article 13,"[2,6,35,31,8]"
"SIA “Lursoft IT” (Lursoft; the controller) processed personal data on its website (lursoft.lv) by (1) publishing information from the ""Insolvency Register"" which relates to a data subject although it had been more than a year since the termination of the insolvency proceedings concerned. Lursoft also (2) published data that is to be submitted to the ""Register of Enterprises"" (including non-public data such as the number of registration of legal entities and legal facts).","(1) Information from the ""Insolvency Register""

The Latvian DPA (Datu valsts inspekcija) considered Section 132(3) of the Latvian Insolvency Law which states that information relating to natural persons involved in insolvency proceedings shall be made public in  the Insolvency Register, including up to 1 year after the termination of an insolvency proceeding. Therefore, there was a violation of the law on the basis that the termination of the insolvency proceeding concerning the data subject had been terminated for more than one year. The DPA reiterated that Section 132(3) targets the responsible institution for the Register of Enterprises, but that although Lursoft is not the responsible institution, the Section of the law still applies to them. Information on an insolvency proceeding cannot be published if the proceeding has ended over a year ago.

The Latvian DPA also held that the controller must have an appropriate legal basis for proceeding personal data under Article 5(1)(a) GDPR. Lursoft claim to be have such a legal basis under Article 6(1)(c) GDPR. However, this was rejected by the Latvian DPA, which stated that for Article 6(1)(c) to apply, the obligation must be stipulated in law, and not just in a contract. The DPA clarified that a legal obligation under Article 6(1)(c) GDPR must be clearly stated in the legal provision.

The DPA also held that Section 4 of the Law on the Register of Enterprises of the Republic of Latvia regulated the right of persons to use information on the Enterprise Register. Paragraph 2 of that Section states that everyone has the right to request and receive information kept in the Register of Enterprises. However, the DPA clarified that this right to access and request the information does not give Lursoft the right to publish this information on its website. Therefore, Lursoft failed in claiming that there was a legal basis for processing the data under Article 6(1)(c) GDPR.

The Latvian DPA also held that Article 6(1)(e) GDPR could not be relied upon as a legal basis, despite Lursoft's arguments. The DPA clarified that Article 6(1)(e) is a valid legal basis if ""processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller"". Such tasks would be conferred by Union or the Member State law as per Article 6(3) GDPR. The DPA went on to outline that Article 6(1)(e) can only be relied upon in two situations: (1) if the controller has a formal mandate or carries out the processing because it is necessary in link with a task in the public interest or (2) where the controller, despite having no official authority, is required to disclose the data to a third party who has such powers. This formal mandate or task will be in the public interest specified in a legal instrument. The DPA clarified that there is no official obligation imposed on SIA “Lursoft IT” to publish information regarding the historical insolvency proceedings of a data subject a result of Section 132 of the Insolvency Law mentioned above.

Therefore, the DPA held that Articles 6(1)(c) and (e) GDPR were not valid legal bases for the data processing conducted by Lursoft.

(2) Information on the ""Register of Enterprises""

The DPA outlined that Lursoft received information, including non-public data, from the Register of Enterprises on the basis of an agreement concluded between the two. The information provided was limited and it was stipulated in the agreement that sharing the information with third parties was not authorised. The DPA also held that Lursoft could not re-use the information provided and that the legal basis for the publication within the Data Regulation [comment: automated translation is unclear, this presumably refers to the GDPR] expired. Therefore, Lursoft could not publish these documents and continuing to process that personal data without a legal basis was unlawful. The DPA clarified that Article 6(1)(e) could not be considered a valid basis, as argued by Lursoft, as there was no legal instrument permitting the publication of the information.

The Latvian DPA also held that Lursoft could not rely on Article 6(1)(f) GDPR. The DPA clarified that a legitimate interest must be ""legitimate - implemented in a way which complies with data protection and other legislation"" (i.e. it must be a legitimate interest acceptable under the law). The DPA concluded that the legislation in this sector precluded the publication of non-public data sent to Lursoft. There was therefore no legitimate interest.

Various other arguments put forward by Lursoft under the Latvian Commercial Law, Section 4 of the Latvian Law on the Register of Enterprises of the Republic of Latvia, the Latvian National Sanctions Law and Section 26 of the Latvian Proceeds of Crime Act were rejected by the DPA as unfounded.

The DPA then went on to confirm that there was no legal basis for processing (publishing) the non-public information on the ""Register of Enterprises"" under Articles 6(1)(e) and (f) GDPR. It went on to add that this entailed a breach of Articles 5(1)(a), (b) and (c) of the GDPR.

Outcome

Finally, the DPA imposed a fine of €65,000 on Lursoft for breaching Article 5(1)(a), 5(1)(b), 5(1)(c) and 6(1) GDPR. Lursoft has since appealed the decision, meaning the fine is not final.",NONCOMPLIANT,"Article 5, Article 6","[9,11,7,30,45]"
"The Swedish DPA finalised an audit of Google’s handling of individuals’ right to have search result listings for searches that includes their name in 2017. In its decision, the DPA concluded that a number of search result listings should be removed and subsequently ordered Google to do so.

During the DPA’s follow-up audit in 2018, it was critical to the fact that Google did not properly remove two of the search result listings that the DPA had ordered them to remove back in 2017. In one of the cases, Google has done a too narrow interpretation of what web addresses need to be removed from the search result listing. In the second case, Google has failed to remove the search result listing without undue delay. Google claimed it had followed the order and that the handling of the delisting requests had been lawful.

Further, when Google removes a search result listing, it notifies the website to which the link is directed in a way that gives the site-owner knowledge of which webpage link was removed and who was behind the delisting request. This allows the site-owner to re-publish the webpage in question on another web address that will then be displayed in a Google search. The DPA criticised this practice, alleging it puts the right to delisting out of effect. However, Goggle claimed this practice has been in accordance with Article 6.1(f) GDPR.","The DPA held that Google had not complied with the previous order by the DPA by failing to remove search links sufficiently and within a reasonable time. Google had, therefore, processed personal data in violation of the GDPR.

The DPA also held that Google had processed personal data in violation of Articles 5(1)(b) and 6 GDPR by sending notifications to webmasters that search results had been deleted. Furthermore, the notice given to data subjects concerning these notifications was found misleading in a manner contrary to Article 5 (1)(a) GDPR.",NONCOMPLIANT,"Article 5, Article 6, Article 9, Article 10, Article 17","[1,3,34,38,43]"
"The Karolinska University Hospital gave the healthcare personnel different access to patient journals based on whether they were doctors or nurses. Thus, this system enabled access to almost all the medical care records regardless of necessity.",The DPA held that the Karolinska University Hospital had not restricted access to patient journals based on a necessity for performing the individual healthcare personnel’s work. The hospital had thus not taken appropriate organisational measures under Article 5(1) and 32 GDPR to limit access to personal data. The hospital had therefore also failed to ensure appropriate security for personal data under Article 5(2) GDPR.,NONCOMPLIANT,"Article 5, Article 32","[43,4,42,10,40]"
"In April 2019, the DPA conducted an on-site inspection at Sahlgrenska University Hospital (Sahlgrenska universitetssjukhuset). The hospital is part of the Västra Götaland region. Four years earlier, the DPA had issued a supervisory decision concluding that the hospital had failed to carry out a necessity and risk analysis in accordance with the legal requirements.

The hospital maintains the medical records of about 900 000 patients. There are about 25 000 user accounts with access to the medical records system, although the hospital has only about 18000 employees. The hospital cooperates with other branches of the Västra Götaland region and assumes that the employees in the departments with which it cooperates have a legitimate need for direct access to the medical records. For the purposes of Chapter 4(1) of the Swedish Patient Data Act, the hospital considers this information to be lawfully shared within the same inner private zone (inre sekretess zon).

All health care workers, including medical secretaries, have general access to all medical records, including those outside their department. If the patient has restricted access to his or her record, only those who work in that department can see the record. Doctors and nurses have general and emergency access. This means that they can access restricted medical records outside their department in a situation where the patient is unable to give consent.

The hospital also maintains a log when a medical record is accessed. The log shall include the name of the health care professional, the portion of the record that was accessed, and the date and time of the last access.","Has the hospital broken the law by not taking sufficient technical and organizational measures?

The DPA considered that the hospital had failed to implement adequate organizational and technical measures to protect medical records

Lack of risk and necessity analysis

In Sweden, sector-specific legislation consists of the Patient Data Act and the National Board of Health and Welfare's rules and general guidelines on the keeping of medical records and the processing of personal data in the health care system (Socialstyrelsens föreskrifter och allmänna råd om journalföring och behandling av personuppgifter i hälso- och sjukvården, HSLF-FS 2016:40).

Chapter 4(2) HSLF-FS 2016:40 requires that the hospital, as a care institution, carries out a so-called risk and necessity analysis before giving its staff access to different parts of the system for keeping medical records. In addition, Chapter 4(2) of the Patient Data Act stipulates that the hospital (caregiver) must limit employee access to the extent necessary for the performance of their duties. The Patient Data Act also permits the so-called coherent keeping of medical records, which means that a caregiver has direct access to the medical records of another caregiver. Before the caregiver grants his or her employees access to a coherent medical record, it must carry out a risk and necessity analysis.

The DPA considered that the hospital's current risk and necessity analysis was fit for the purpose of IT - security with a focus on the employee - which is a different form of risk analysis from that required by HSLF-FS 2016:40. The DPA was looking for a risk analysis that would assess the risks to patients as data subjects. For example, if patients who are famous, have a protected identity, or have a special diagnosis, are at risk of harm if access authorization is too relaxed. In addition, the DPA held that the hospital had not properly evaluated how permissions should be defined so that employees only have access to the information they need to do their jobs.

Access rights to medical records were too extensive

The DPA recalled that the risk and necessity analysis should determine how the caregiving institution assigns health care workers permission to access medical records. In this case, about 25 000 people had access to medical records, although the hospital only had about 18 000 employees. The hospital assigned permissions in such a way that health care workers, regardless of which department they worked in, could access the medical records of all departments within the hospital, except one. On this basis, the DPA concluded that the majority of the hospital's employees had access to more medical records than they needed to do their jobs. The DPA did not take a positive view of the fact that the hospital gave direct access to medical records to persons working in other governmental branches of the region of Västra Götaland.

Is the hospital a data controller regarding medical records it retrieves from other caregivers?

The Swedish Patient Data Act states that a caregiver is the data controller for the medical records that it creates. The hospital therefore did not consider itself a data controller of medical records that are retrieved from other caregivers through the coherent medical record system. However, the DPA considered that the hospital is a data controller for the specific data it retrieves in relation to an individual patient from a medical file kept by another caregiver.

Based on this finding, the DPA concluded that the hospital had once again failed to conduct a risk and necessity analysis and had not properly limited the permissions regarding access to the system for coherent medical records

Access logs

The DPA considered the current level of logging when an employee accesses a medical record to be insufficient. The DPA clarified that the purpose of the logging is not only to check for unauthorized access to the medical record. The log is also used to trace which actions were performed in connection with access to the medical record, such as printing, copying, or deleting personal data.

Sanction fee

The Swedish Data Protection Act (implementing the GDPR) provides that public bodies that violate the GDPR can be fined up to SEK 10 million. The DPA imposed a sanction fee of SEK 3.5 million on the hospital.

Firstly, the hospital processes a large amount of sensitive personal data of many affected patients (approximately 900 000).

Secondly, the hospital did not have a sufficiently granular access control system: health care staff could easily access documents from other departments. Also, the hospital had granted direct access to medical records to a large number of people working in other governmental branches of the region of Västra Götaland (outside the health care system).

Thirdly, the DPA considered that the hospital had not carried out a proper needs and risk analysis, as required by the DPA decision of 27 March 2015. According to the DPA, the hospital had been aware for several years that it was not complying with the law and deliberately decided not to take corrective measures.

Commands for making changes

Finally, the DPA instructed the hospital to take the following measures:

1. Properly analyze the risk to the patients and analyze what access each employee needs.
2. Assign each employee an individual access tailored to what he or she needs to do his or her job.
3. To extend the logging of access to medical records to include information on what actions an employee has taken in relation to access to them.",NONCOMPLIANT,"Article 5, Article 24, Article 32, Article 58, Article 83","[10,49,28,7,21]"
"The DPA opened an investigation against the Västerbotten Region Healthcare committee (Hälso- och sjukvårdsnämnden) on 22 March 2019. The DPA wanted to investigate whether a risk and needs assessment was carried out before healthcare workers were given access to patient files from their own department and files from other healthcare departments. The DPA had already found in 2015 that the Region of Västerbotten’ s needs and risk assessment did not comply with the requirements of the law and had instructed them to carry out a new assessment.

Swedish healthcare regulations require that a caregiving institution conducts a risk and necessity analysis before granting its employees access to medical records. The caregiving institution must analyze what privacy risks patients face and what information employees need access to. The caregiving institution must use the analysis as a tool to ensure that each employee has access only to what he or she needs to do his or her job.

The Healthcare committee is the executive body running the region's health care system. The committee's guideline on information security made the operational manager of each health care unit responsible to conduct a needs and risk analysis prior to giving a user account to a health care worker access to patient records.","Risk/needs analysis and system privileges

The DPA held that the Västerbotten Region Healthcare committee did not have a needs and risk analysis that met the statutory requirements. The DPA did not accept the view of the Healthcare committee that it was the responsibility of the head of each health department to carry out the analysis. The DPA took the view that the central management of the healthcare committee was responsible for carrying out such an analysis and that it was an organizational measure carried out at a strategic level for the healthcare system it operated as a whole.

In addition, the DPA had comments on the risk and needs analysis outline that the healthcare committee gave to each health unit manager. The outline was intended as a practical tool to help the health unit determine how authorizations should be designed before creating an account for an individual health care worker. First, the DPA held that this document only addressed the needs of the health care provider to access certain data but lacked consideration of the risk of invasion of patient privacy. Second, the DPA pointed out that the needs and risk analysis is a strategic document that is needed as a tool in deciding the overall structure of granting privileges in the computer system. Third, the DPA concluded that instructions to the person creating the user account do not constitute the risk and needs analysis that the law requires.

The DPA also found that the health care committee did not limit individual health care workers' access to medical records to that which was necessary for the performance of their duties. The DPA found that the Healthcare committee violated Article 5(1)(f), Article 5(2), Article 32(1) and Article 32(2).

Access logs

The DPA investigated the logging practices of the healthcare committee and determined them to be compliant with the statutory requirements.

Order to take compliance measures

The DPA directed the Healthcare committee to conduct and document a needs and risk analysis as required by law. The analysis must include access to medical records from records held by the Healthcare committee as well as coherent medical records from other health care providers. The DPA directed the Healthcare committee to redefine health care worker access to medical records based on the analysis so that each health care worker has access only to the medical records they need to perform their job.

Sanction fee

The DPA imposed a fine of SEK 2.5 million on the Healthcare committee (Hälso- och sjukvårdsnämnden) of the Region of Västerbotten. The fine was based on several factors: patient data is inherently sensitive, approximately 650,000 patients were affected, and the DPA considered that the Healthcare committee knowingly failed to follow its instructions from 2015.",NONCOMPLIANT,"Article 5, Article 32","[16,40,24,14,30]"
"The audit to Aleris Sjukvård AB from the Swedish DPA was initiated in May 2019.  Aleris is a healthcare provider and uses a system named ""TakeCare"" as the main journal keeping system where they store and maintain the patients' journals. According to the Patient Data Act, a caregiver must conduct a needs and risk analysis before allocating access rights in the patients' journals.","The DPA found that Aleris Sjukvård AB did not carry out these assessments and it has granted access to patients' journal to all employees apart from the technicians. By doing so, Aleris Sjukvård AB breached the obligation to apply appropriate technical and organisational measures to ensure the security of the personal data, imposed to controllers by Article 32 GDPR.

The DPA imposed a fine of 15 millions SEK (approximately €1466000).",NONCOMPLIANT,"Article 5, Article 32","[16,10,29,3,7]"
"The caregiver Kry, provides health services via video calls. The patient downloads an app that is available for iOS and Android. The app allows the patient to have a video call with the doctor and renew certain prescriptions without a video call. At the time of the inspection, the caregiver's internal medical record system contained approximately 450,000 patient records accessible by 490 of the caregiver's employees.

The DPA initiated the investigation on March 22, 2019 and conducted an on-site inspection on April 4, 2019.

The inspection concerned:

Risk-needs analysis

* whether the caregiver had analyzed the risks to which data subjects were exposed as a result of the caregivers processing of personal data
* whether the caregiver had properly assessed which of its employees needed access to which data

How access to medical data was defined

* how employees were granted access to the caregiver's internal medical records
* how staff were granted access to other caregiver's medical records through the coherent medical record system (sammanhållen journalföring).
* whether access and permissions were properly defined based on the risk-needs analysis.

Logs

* How the caregiver logged whenever a staff member accessed a patient's data.","Risk- needs analysis

The DPA concluded that the risk and necessity analysis did not meet all statutory requirements at the time of inspection. During the supervisory investigation, the caregiver submitted a revised risk analysis twice. The DPA considered the revisions to be significant improvements, but an even more thorough analysis was needed to meet the statutory requirements. The DPA said there was a need to assess risks based on categories of personal data, such as addictions, mental health, domestic violence.

Access to medical records

Although a caregiver has a legitimate interest in processing a lot of personal data about a person's health, permission to access personal data must be limited to what a healthcare worker needs to do their job. The risk and needs assessment is the caregiver's tool to determine who gets access to what. At the time of the inspection the caregiver had not implemented any technical means to limit what their staff can access within internal files or the coherent records (from other caregivers). The caregiver implemented organizational measures to prevent unauthorized access. The caregiver manually reviewed each instance in which a staff member had accessed medical records of a patient he was not currently treating. In addition, once a month the caregiver blocked a doctor's access to medical records if they were not due to attend work for the next 4 weeks.

The DPA considered the lack of technical restrictions on access to patient records as a breach of Article 5(1)(f), Article 32(1) and Article 32(2).

During the supervisory inspection, the caregiver made changes to restrict her employee's access to internal and coherent medical records. The changes resulted in the employee only being able to access the records of a patient for whom she had an appointment, and this access would be revoked four months later. The DPA considered these changes to be positive improvements but reminded the caregiver that the technical measures would need to be reevaluated once the risk and necessity analysis was completed, as required by the DPA.

Logging of unauthorized access

The caregiver logged access to internal medical records and the coherent medical records. After the inspection, the caregiver informed the DPA that he found that his system did not log when someone deleted an unsigned journal entry. The caregiver remedied this on May 16, 2019, and the DPA considered the caregiver's logging practices following the law as of that date.

Sanctions charge

The DPA considers violations of Article 5(1)(f), Article 32(1) and Article 32(2) to be sufficiently serious in most cases that a caregiver should be fined. In this case, the DPA found that the caregiver had made efforts to comply before and during the inspection. The DPA decided not to impose a financial penalty on the caregiver. Instead, the DPA directed the caregiver to take certain compliance measures.

Instruction to implement compliance measures.

The caregiver revised their needs and risk assessment twice during the inspection. The DPA considered these revisions before deciding to instruct the caregiver to make changes. The DPA found that the caregivers risk assessment had improved since the inspection began and it was now better at addressing the risks required by the law.

The DPA directed the caregiver to undertake a more detailed analysis of the risks to the rights and freedoms of data subjects. According to the DPA, this analysis should form the basis of a new assessment of the way in which access rights to patient records are defined for the caregiver’s staff. The DPA required that these changes be implemented by the end of February 2021.",NONCOMPLIANT,"Article 5, Article 32","[29,38,47,33,26]"
"Two researchers from Umeå University in Sweden acquired copies of all preliminary investigation reports in Sweden for 2014 on cases of rape of male victims from the police. In July 2016, the Swedish Police Authority sent paper copies of the investigation reports to the researchers by mail carrier.

In November 2017, the researchers contacted Swedish Police Authority and asked for additional information about one of the cases. The researchers attached a scanned copy of one of the investigations to an email sent unencrypted. When the Swedish Police Authority pointed out the inappropriateness of sending sensitive material via unencrypted emails, the researchers claimed it was an unintentional act and blamed the human factor. In February 2019, the research team wanted more information on the same rape case and sent the same investigation report again in an unencrypted email to the Swedish Police Authority. The researchers also claimed the second email to be an accident. After this incident the Swedish Police Authority wrote an official letter dated April 3, 2019, which was sent to the Swedish DPA (Datainspektionen).

The DPA launched an investigation to determine whether Umeå University had breached the GDPR. The preliminary investigatory reports contain special categories of personal data such as data about health and sex life and information about suspected offences. They also contain names, contact details and personal numbers of victims and suspects. The research team changed their routines after the first unencrypted email, but could not explain why they then sent the same report a second time in an unencrypted email

In September 2019, Umeå University analyzed the data breach and found that it did not pose a high risk to the rights and freedoms of data subjects. As the email was addressed to a staff member at Swedish Police Authority who provided the researchers with the reports, the university concluded that there was no evidence of actual harm or unauthorized disclosure.

The university also scanned 108 preliminary investigation reports and uploaded them to the cloud storage provider Box. Box is a US-based cloud provider and was a sub-processor of the processor The Swedish University computer Network. Box Transferred personal data to the US on the basis of the Privacy Shield (in force at the time) and binding corporate rules. The files were confidential under Chapter 35(1) and Chapter 11(3) of The Public Access to Information and Secrecy Act (Offentlighets- och sekretesslagen).

The researchers stored the files in a folder in Box that was accessible only to the two researchers. The information was protected by 256-bit SSL encryption in transit and 256-bit encryption at rest. Encryption keys were kept separate from the data, and backups were also encrypted. Access to files was protected by single-factor authentication (username and password). In 2016, the University considered that Box met the legal and technical requirements for storing sensitive personal data. Nevertheless, the University considered that such data should not be stored in Box as a precautionary measure.","Personal data were not adequately protected

The DPA found that the University had breached Article 5(1)(f), Article 32(1) and Article 32(2) by failing to adequately protect the personal data in the reports. Although the emails were sent to the correct person at The Swedish Police Authority, they were sent unencrypted over the internet. The DPA recalled that the Internet is an open network and that unauthorized persons may gain access to information sent over such a network if it is not adequately protected, for example by encryption.

The data breach should have been documented and reported to the DPA

The DPA found that the University violated Article 33(1) and Article 33(5) by failing to timely document and report a data breach. According to the DPA, the university became aware of the data breach at the time the Swedish Police Authority told the researchers that it was inappropriate to send criminal investigations in unencrypted emails. According to the DPA, the university knew about the incident on at least April 3, 2019, not August 30, 2019, when it received the letter from the DPA informing it that it was under investigation.

Storage of sensitive personal data with a US cloud provider outside the EU

The DPA found that the University breached Article 5(1)(f), Article 32(1) and Article 32(2) by storing the 108 preliminary investigation reports with the cloud provider Box.

First of all, the University did not take sufficient technical measures with regard to the sensitivity of personal data. Although the data was encrypted in Box, anyone from any IP address could access the data if they had the correct username and password. The DPA recalled that one-factor authentication is vulnerable to phishing attacks and that it would be unlikely for the researchers to know if their username and password were in the wrong hands. The DPA held that sensitive personal data of this nature must be protected by multi-factor authentication.

The DPA reminded that a data controller must carry out a risk assessment and determine whether it is appropriate to store certain personal data with a particular processor. The assessment should be made in relation to the risk of unauthorized disclosure or access.

The DPA concluded that the preliminary investigative reports concerned rapes against men and contained sensitive personal data that was classified. The DPA considered that the data processing posed a high risk to the privacy of the data subjects if the information was disclosed to or accessed by unauthorized persons.

In addition, the DPA considered that the transfer of the personal data to the United States was problematic as the Public Access to Information and Secrecy Act does not apply in the US.

SEK 550 000 sanction fee

The DPA imposed a sanction fee of SEK 550 000 on Umeå University. SEK 450 000 related to the unencrypted emails and the storage of the preliminary investigation reports with a US cloud provider, SEK 100 000 related to the failure to document and report the data breach in a timely manner. The DPA deemed the violations in the unencrypted sending of emails and storage of the reports at the US cloud provider, as negligently caused. In this case, 108 criminal investigation reports containing highly sensitive personal data were stored with the US cloud provider without adequate data protection. On top of that, the university had stored the sensitive personal data in Box even though its own risk and vulnerability assessment concluded that such data should not be stored there.",NONCOMPLIANT,"Article 5, Article 32, Article 33","[5,43,31,46,0]"
"The housing company set up a surveillance camera to film the door of a tenant who had been objected to harassment and disturbances for a long time. In the camera's recording area, another tenant’s door could be seen, as well as tenants walking in and out of the apartment house. The camera recording was without sound recording or real-time monitoring, and the recordings could only be accessed by five people within the company.",The DPA held that Uppsalahem AB had processed personal data in breach of Article 6 (1) (f) GDPR by conducting camera surveillance of common areas in an apartment building.,NONCOMPLIANT,Article 6,"[18,17,42,21,24]"
"In the fall of 2018, the Danish DPA performed a number of investigations regarding selected companies' legal bases for processing and their implemented security measures. Dating.dk ApS was one of the companies under investigation.

Dating.dk informed the DPA that the company's legal basis for processing was consent pursuant to Article 6(1)(a) GDPR. New users of Dating.dk had to accept the company's privacy policy by ticking a box that read ""I accept the terms and conditions and the privacy policy"". The word ""privacy policy"" was a hyperlink redirecting the user to a website containing the policy document.","The DPA first had to assess whether the controller processed any special categories of personal data underArticle 9(1) GDPR. The DPA held that processing information about a data subject's sex life or sexual orientation involved the processing of special categories of personal data, regardless of whether the data subject explicitly revealed their sexual orientation. Additionally, the DPA highlighted the company's role as a controller for any personal data revealed in a data subject's ""biography"" on the website. The DPA also emphasized that the company's privacy policy mentioned processing of personal data regarding sexual orientation. The DPA therefore concluded that the controller processed special categories of personal data.

Secondly, the DPA had to assess whether the controller had a legal basis for the processing. The relevant legal bases were consent cf. Article 9(2)(a) GDPR and Article 6(1)(a) GDPR. The DPA referred to Article 4(11) GDPR, Article 7 GDPR and Recital 32 regarding the conditions for consent. The DPA held that the controller could not obtain a valid consent for data processing while at the same time asking the data subjects to agree to the terms and conditions of the service. Such consent could not be categorized as an unambiguous indication of the data subject's wishes. The DPA finally noted that the controller had not under any circumstances obtained an explicit consent to processing of special categories of personal data.

Lastly, the DPA had to assess whether the controller had implemented appropriate security measures as per Article 32(1) GDPR. The controller had in fact performed an assessment of the risks related to the processing. However, the DPA found that the risk assessment was partly incomplete.

As a result, the DPA issued severe criticism of the controller's processing of personal data, and ordered the controller to bring its processing operations into compliance with the GDPR.",NONCOMPLIANT,"Article 4, Article 6, Article 7, Article 9, Article 32","[30,22,39,0,13]"
"Controller is the Conservative People's Party. They had sent letters to a certain number of households in connection with an election campaign. The names and addresses of the recipients had been obtained from information that was publicly available, and information about voting habits in different areas had been gathered through statistical analyses. The letters, however, did not contain the information as listed in Article 14(1) and Article 14(2) GDPR. Instead, the controller had published an page on its website, on which they had provided this information.

After having been notified by multiple data subjects, the Danish DPA decided to investigate the Conservative People's Party's actions, and whether they were in accordance with the GDPR.","First, the DPA assessed whether the controller had legal basis for the processing of personal data. The DPA held that the Party had a legitimate interest in using the personal data for campaigning purposes, and that the use of such publicly available information was not particularly invasive to the data subjects' privacy. The controller, therefore, had legal basis for the processing, namely Article 6(1)(f) GDPR.

The DPA then assessed whether the Party had acted in accordance with the information obligations in Article 14 GDPR. First, the DPA stated that, contrary to the opinion of the controller, the exception laid down in Article 14(5)(c) GDPR was not applicable ""since the processing of information in connection with the sending of letters on the party's main issues is not expressly provided for by law"". Second the DPA held that the information could not be considered ""given to the data subject"" when the data subject would have to find the information on the website by themself.

Hence, the DPA reprimanded the controller for violating Article 14 GDPR.",NONCOMPLIANT,"Article 6, Article 14","[8,20,24,42,44]"
"Controller is Den Blå Avis' (DBA), an online platform for second hand goods. At the end of June 2020, the DPA conducted an ex officio investigation on DBA's processing of personal data of its website visitors. After the investigation, the DPA concluded that controller had not obtained valid consent for its processing of personal data. The controller then changed its consent management platform, after which the DPA re-investigated the matter, but then focussed on the new consent manager. Hence, in it's decision, the DPA has taken a position on the two different consent managers.","First, the DPA found that the consent was not specific, since by clicking ""accept"", personal data was processed for different processing purposes (like marketing and personalisation etc.), without these purposes being divided and clearly stated. Second, DBA had lacked to sufficiently inform the visitor that the personal data would be disclosed to third parties, nor did a link or fold-out menu appeared in close connection with the purpose for which the information was passed on. After assessing the second consent manager, the DPA found that the issues with the first CMP had not been resolved. Hence, the DPA concluded that neither the first, nor the second consent manager were adequate to obtain consent in accordance with Article 4(11) GDPR, and the processing was thus not in compliance with the principle of legality, reasonableness and transparency, Article 5(1)(a) GDPR.

Furthermore, the DPA considered that, because the controller uses Google Analytics, the data is transferred to the United States. Moreover, because the controller had not implemented any measures to ensure that protection of data subjects' personal data is essentially equivalent to that within the EU, the DPA states that ""the website visitors cannot reasonably expect [that] their information, in addition to being the subject of analyses and statistics on the dba.dk, [is] also disclosed to Google LLC's servers in the United States"". Hence, the DPA concluded that data subject's interests overrode the controller's legitimate interest, and thus, that the controller could not rely on Article 6(1)(f) GDPR, regarding the processing for statistical purposes. Apart from expressing criticism, however, the DPA did not use any of their corrective powers as laid down in Article 58(2) GDPR.",NONCOMPLIANT,"Article 4, Article 5, Article 6","[7,28,19,20,0]"
"In February 2020, the Danish DPA published a guide on the processing of personal data of website visitors. As a follow-up to this, and to focus on whether the rules in this area were complied with, the DPA decided in October 2020 to investigate the website www.naestved.dk, which is administered by the Næstved Municipality. The cookie banner on the website stated ""The website uses cookies to improve your experience, assess the use of the individual elements of the website and to support the marketing of our services. By clicking on the website, you accept the website's use of cookies."" Visitors could then choose between ""OK"" or ""Show details"".","First, the DPA found that the Næstved Municipality violated the principle of lawfulness, fairness, and transparency, Article 5(1)(a) GDPR. It emphasised that ""the texts on the website led visitors to believe that the municipality processed personal data for marketing purposes, even if this was not the case"".

Second, the DPA found that Næstved Municipality's processing of website visitors' personal data for statistical purposes took place in the scope of the municipality's public authority, and thus within the framework of Article 6(1)(e) GDPR. The DPA considered that the processing of personal data for statistics was related directly to its duty to guide and assist citizens, since the website's efficiency and ease were optimised through the statistics. In this regard, the DPA found it important that these statistics were provided by a third party who anonymised the statistics irreversibly. Lastly, the DPA considered that the sub-processing that was carried out by AWS, did not lead to an international data transfer because this was laid down in an agreement and ""publicly guaranteed"".",NONCOMPLIANT,"Article 5, Article 6","[31,23,0,14,29]"
"The controller is the Capital Region of Denmark (an administrative region). It operates a platform, the “Health Platform”, which is used by the Danish Health and Medicines Authority (the Authority). This platform has integrated the central database of the Authority, which holds all data on the prescriptions and medicine purchases of all Danish citizens. Both on 10 August 2020 and 8 July 2021, data breaches occurred because the Health Platform was initially updated, and affected the integrated database.

The code changes of the first update caused the database to incorrectly display the number of prescriptions patients were to receive, which led to unintended double subscriptions, affecting 2,310 data subjects. Although the controller became aware of the coding error, it did not immediately inform the Authority. The second data breach affected another 1,149 patients. Hence, in total, the two data breaches concerned sensitive personal data (health data) of 4,459 data subjects.","First, the DPA noted that the controller is obliged to take appropriate technical and organisational measures to ensure an appropriate level of security relating to its processing. Now, the DPA found during its investigation that the controller, before both updates, did not qualify and perform any tests to identify how the update on the platform would affect the integrated database. In this regard, the DPA emphasised that even minor changes in integrated systems can lead to significant risks of data subjects, the sensitive nature of the personal data and the fact that there were two breaches. Lastly, as explained, the controller did not inform the Authority. Considering all of the foregoing, the DPA concluded that the controller violated Article 32(1) GDPR.

Second, the DPA considered that the breach of health data poses a high risk to the rights of the citizens concerned. Moreover, it noted that the controller notified the data subjects affected by the data breach via a health professional notification. However, the DPA found that this notification satisfied the requirements of Article 34(2) and Article 33(3) GDPR.

The DPA expressed serious criticism to the controller for violating Article 32(1) GDPR. Moreover, it issued a warning pursuant to Article 58(2)(a) and ordered the controller to bring its processing operations into compliance with the GDPR, pursuant to Article 58(2)(d) GDPR.",NONCOMPLIANT,"Article 32, Article 33, Article 34, Article 58","[48,9,49,16,40]"
"A data subject had informed the team leader at her job that due to a fertility treatment, she would need some of her work tasks facilitated in the coming period. At work the following day, she read an email which had been sent to the entire department with 51 of her coworkers, where the team leader had informed everyone of her care needs and the reason why (fertility treatment).

Following this, the data subject lodged a complaint with the Danish DPA (Datatilsynet), stating she had not given her consent to the sharing of this sensitive information. The municipality admitted to having shared the information in question, but said it was due to a misunderstanding. They had also realised that the consent they thought they had obtained did not satisfy the GDPR requirements. Because of this, they had offered a monetary compensation to the data subject.

The DPA noted that the municipality had admitted the mistake and apologised for sharing the sensitive information without a valid consent, and that it was not necessary to inform the data subject's colleagues about the reason for her care needs.","The DPA held that the municipality's processing was in violation of Article 5(1)(c) GDPR. Because of the personal data's sensitive nature and the group of people who received the information, the DPA concluded that there were reasons to issue a reprimand against the municipality.",NONCOMPLIANT,Article 5,"[14,11,39,48,40]"
"In summer 2021, the Danish DPA investigated the data practices of a number of national municipalities. The controller in this case, the Allerød Municipality, was one of these. The investigation focused on Allerød Municipality's way of administering access rights in the administration of social welfare, in accordance with Article 32 GDPR.

First, the DPA asked the controller for a list of systems in which data on natural persons were processed, as well as the municipality's policies on auditing and sampling for unauthorised access attempts. The municipality shared its guidelines on logging and sampling, which stated that samples were taken at different intervals (e.g. 1 month, 2½ months, 5 months, 3 months, etc.) but never more than 6 months apart. After receiving this information, the DPA requested documentation on the random checks the municipality carried out in one of its systems.

The Allerød Municipality provided this documentation, which showed that it had carried out log checks on 24 June 2020, 25 September 2020 and 13 August 2021.","Following the inspection of Allerød Municipality, the DPA held that whilst the municipality's procedures for random checks of the log in the social administration's systems were generally satisfactory, it had failed to follow its own guidelines in at least one case.

The DPA added that in its opinion, carrying out such sampling every six months constitutes the absolute minimum of auditing systems that process a lot of confidential and/or sensitive information, or where the access rights are of a broader nature.

Thus, the Danish DPA issued a reprimand against the Allerød Municipality for failing to implement appropriate technical and organisational measures, as required by Article 32(1) GDPR, to ensure the proper administration of welfare.",NONCOMPLIANT,Article 32,"[11,35,47,36,38]"
"The controller is the Høje-Taastrup Municipality. It was among the selected municipalities that the Danish DPA had chosen (ex officio) to assess its compliance with the GDPR. The DPA focused on access rights in the municipalities’ filing systems. To assess these access rights, the DPA requested a list of 12 AD groups (so 12 different groups of users) who had access to a database in the GIS (Geographic Information System) which contained personal data. Moreover, it requested the unicipalities’ guidelines for joining the respective AD groups (so how a user would get a certain permission to access particular files).","The DPA found that the municipality violated Article 32(1) GDPR.

First, it considered that the municipality does not have guidelines or objective criteria in place to determine whether a user could join a particular AD group (which grants the user particular access to certain files). The DPA then noted that it follows from Article 32(1) GDPR, that user access to systems containing personal data is limited to the personal data that is necessary for the work-related needs of the user in question. Because of the absence of the guidelines or objective criteria, the DPA concluded that the municipality had not taken appropriate technical or organisational measures pursuant to Article 32(1) GDPR.

In this regard, the DPA stipulated that the fact that the municipality cannot document which users need access to the database due to work-related needs, is extra problematic if one considers that there were 410 users with access to the database. Hence, the DPA expressed criticism on the municipality, and encouraged the municipality to objectively describe which function or task must be present in order to gain access, and that this access is also verified by a manager.",NONCOMPLIANT,Article 32,"[11,31,41,49,16]"
"The controller is e-Boks, a digital platform for dialogue, shipping and storage of documents. The controller also manages e-Boks Express, a self-service portal where companies can send messages and documents. In March 2021, the Danish DPA carried out an investigation after it became aware that it was possible to access someone else’s user profile when logged in to e-Boks Express.

According to the controller, the problem was not caused by them. Their procedure requires the user to access the portal via a NemID Erhverv/NemID signature (which is a key file, key card or key app). According to the controller, the fact that a user, after signing in with a NemID keycard, was signed in to another user account, was caused by a technical error by Nets Danmark A/S (which manages the NemID Erhverv/NemID signatures). Nets confirmed this, and stated that the error only existed when a user signed in to e-Boks Express with a NemID key card (and not with a key file or key app). Moreover, they argued that it is clear from the log-files that ‘only’ 304 people could potentially have exploited the bug, and that the security breach ‘only’ lasted from 4 March 2021 to 27 April 2021.","First, the DPA noted that the unauthorised access to user profiles, meant that there was a personal data breach pursuant to Article 4(12) GDPR. Moreover, it stated that Article 32(1) GDPR obliges controllers to take appropriate technical and organisational measures to ensure a level of security appropriate to the risks associated with the controller’s processing of personal data. In this regard, it noted that this obligation normally implies that changes to existing IT platforms, and developments of new IT platforms, can only take place if security can be ensured. The DPA noted also that the controller did not carry out tests of all possible scenarios in which errors could occur. After all, it was not aware of the error that users were signed into the wrong account when they used a NemID key card as authentication.

Hence, the DPA concluded that the controller failed to implement appropriate technical and organisational measures pursuant to Article 32(1) GDPR, and criticised e-Boks.",NONCOMPLIANT,"Article 4, Article 32","[28,8,2,11,36]"
"The controller is the Danish Agency for Digitisation. As the responsible authority, it grants curators reading access to companies’ (digital) mailboxes in cases of bankruptcy, cessation, etc. The controller receives this access from the company e-Boks, a digital platform that, inter alia, manages access to mailboxes. The procedure is as follows: the controller compiles a list of which person/legal entity requests reading access to which mailbox, and provides this list to e-Boks, so that the latter can grant technical access to the mailbox.

On 29 March 2021, a law firm contacted the controller because, as trustee, they had received access to a companies’ mailbox. However, the law firm had received access to the mailbox of the wrong company. Hence, the controller had e-Boks, which is the digital platform that provides the controller with access to mailboxes, close access to the mailboxes. On 31 March 2021, the controller notified a personal data breach to the Danish DPA. From the controller’s investigation, it became clear that 26 curators had gotten access to the wrong companies’ digital mailbox. Moreover, the controller found that the data breach was caused because the controller had sent an incorrect list to e-Boks, and claimed that a technical error was the reason for this mistake. However, the controller also claimed there was no procedure in place to check the list for mistakes since, until then, mistakes had never occurred.","First, the DPA considered that the controller provides curators/trustees access to a large number of confidential information, and thus, higher requirements are placed on the controller’s diligence to ensure that there is no unauthorised access to the personal data. Moreover, the DPA considered that the controller had a procedure in place where a single human error could lead to major personal data breaches, and that the controller found this procedure sufficient since no errors had previously occurred. The DPA concluded that the controller did not have appropriate organisational and technical measures in place to ensure a level of security appropriate to the risks, and therefore violated Article 32(1) GDPR.

The DPA criticised the controller for this violation, but also noted that the controller had implemented a procedure where the lists were checked by multiple people to check for human errors.",NONCOMPLIANT,Article 32,"[6,11,31,1,15]"
"A security flaw in a health care IT system used by a Danish region had made it possible to access other individuals' personal data and to delete their bookings. After logging in to their own account, users were able to access personal data related to other users by changing a number in the URL of the website. From may 2018 and until april 2021, users could take advantage of this security flaw, and thus access all correspondence between health care personnel and their patients, including personal data such as names, social security numbers, cell phone numbers, addresses and health data. 498 599 patients were registered in the system in April 2021.

The region reported the personal data breach to the Danish DPA, and stated that there were no signs that the personal data has been accessed without authorisation or otherwise misused.","The DPA held that the controller acted in violation of the security requirements of article 32 GDPR. The controller had entered into a technical development contract with the developer of the IT system without including sufficient obligations related to testing. The contract framework included an obligation to perform user tests, however it did not contain clear obligations to perform security tests.

The DPA therefore reprimanded the controller for not implementing appropriate technical and organisational measures to ensure a level of security appropriate to the risk.",NONCOMPLIANT,Article 32,"[23,0,35,34,36]"
"On 12 July 2021, the Danish Customs and Tax Administration (CTA) reported a personal data breach to the Danish DPA (Datatilsynet). The CTA had sent a letter containing the personal data (of someone else) in the form of identification data, financial information and social security number, to the wrong recipient. The CTA knew already on 8 July that a breach had possibly occured, because the incorrect recipient made them aware. After the CTA's internal investigation, they concluded on 9 July that a personal data breach had indeed happened.

From the report to the DPA, the CTA stated that the affected data subject was informed on 10 July. Because of the information they had provided, the DPA closed the matter on 23 July.

However, on 20 August the DPA received a follow-up from the CTA, stating that they had not, in fact, informed the affected data subject on 10 July, as the initially reported, but on 18 August. The CTA explained that their late follow-up was due to the vacation period.

Because of the new information, the DPA decided to reopen the case.","The DPA held that the Customs and Tax Administration had not processed personal data in line with Article 34(1) GDPR. They expressed serious criticism of the way the CTA had dealt with the personal data breach, in particular i) that the CTA first, incorrectly, reported to the DPA that they had notified the affected data subject shortly after, and ii) that they blamed their late response on ""extraordinary circumstances"" due to vacation period, which the DPA does not agree is a valid excuse.",NONCOMPLIANT,Article 34,"[31,37,44,25,26]"
"The National Genome Center (NGC) is a leading healthcare agency developing personalized medicine in Denmark. The NGC conducted a Data Protection Impact Assessment (DPIA) concerning its work on gene sequencing and, on 9 December 2021, sent it to the Danish DPA for a consultation. The DPIA documentation contained clear language suggesting circumstances that could pose high risk to data subjects' rights. However, the NGC failed to implement any mitigating measures and it initiated the data processing prior to the consultation with the DPA.","The Danish DPA held that, by starting the data processing despite the high risk to data subjects, the National Genome Center did not comply with the requirement of prior consultation with a supervisory authority where a data protection impact assessment indicates that the processing would result in a high risk to data subjects in the absence of mitigating measures. On 13 January 2022, after the initial investigation, the DPA imposed a temporary ban on further collection of personal data and a restriction on processing the collected information, limiting it to storage only.",NONCOMPLIANT,Article 36,"[20,4,33,14,38]"
"In 2020, Danish Bank reported an issue with personal data deletion to the Danish DPA. In its investigation, the DPA discovered that the bank lacked policies and procedures for storage and erasure of personal data in over 400 systems. The bank could not demonstrate that it had manually deleted personal data either. The systems contain the personal data of millions of data subjects.","The Danish DPA Datatilsynet held that Danske Bank had breached a fundamental principle of the GDPR, where one is required to delete personal data one no longer needs (likely referring to Article 5(1)(e) GDPR).

Due to this, the DPA has filed a police report against Danske Bank and proposed a fine of €1,345,000 (DKK 10 million). The police will investigate the case before a final decision is made in the courts.",NONCOMPLIANT,Article 5,"[20,32,30,16,9]"
"Following a data breach notification submitted by Vejle Municipality, the DPA assessed the case.

Thereby, the DPA found that the municipality dental care used an automatic process to send welcome letters to custodians that contain addresses of both parents. The DPA concluded that the municipality failed to assess on case-by-case basis whether only the necessary information included in the letters and whether the personal data may be disclosed to the other parent. Thus, in several cases a parent received information about the other parent and/or child address, even though their name and address have been protected.

On 16 June 2021 the DPA has published a press release to announce that the Vejle Municipality has been reported to the police and a fine of DKK 200,000 has been proposed.","The Danish DPA chose to report Vejle Municipality to the police for breach of the GDPR, namely, the failure to implement appropriate security measures when processing personal data of patients and recommended a fine of DKK 200,000.

The municipality failed to assess whether it is at all necessary for the information to appear in the letters.

In determining the amount of the fine, the DPA considered inter alia the following aspects:

* the nature and seriousness of the infringement
* the GDPR's requirement that a fine in each individual case must be effective, proportionate to the infringement, and have a deterrent effect
* the size of the municipality in terms of population and the total operating license",NONCOMPLIANT,Article 83,"[7,27,44,48,36]"
"In January 2021, the Danish DPA discovered that Medicals Nordic used WhatsApp to transmit ""confidential information and health information"" about citizens tested in the company's test centres. The DPA initiated an own-volition inquiry to assess whether Medicals Nordic had implemented appropriate organisational and technical security measures to safeguard the transmission of citizens' information.

It found that employees at the company used their private phones to communicate confidential patient information to the central administration in charge of the four test centres it operated. It did so via WhatsApp group chats, to which all employees at these centres were added.

As such, even employees who did not have a work-related need to process information about patients could access it. It included, among other things, the social security number and health data of citizens. Further, ex-employees who no longer worked at the company were not removed from the group chat due to ""inadequate access management"", meaning they still had access to this data.","The Danish DPA held that ""confidential information and health information about a large number of citizens has been processed unsafely and passed on to unauthorized persons, including employees who did not have a work-related need to receive the information [and ex-employees]"".

It emphasised that in several cases the violations were intentional as Medicals Nordic did not carry out necessary data-related risk assessments.

Thus, it fined the company DDK 600,000 or approximately €80,500.",NONCOMPLIANT,Article 83,"[34,15,20,48,29]"
"Legelisten.no AS is a Norwegian limited liability company running a website where people anonymously can post reviews about dentists, doctors, psychologists and other healthcare personnel. A review must adhere to Legelisten's policy, it should include a heading and a description of at least 100 characters, as well as a rating from one to five stars. The user is asked to include positive and negative aspects and avoid offensive language, allegations of malpractice or rumors. The user must confirm their submission via email and all reviews are monitored and moderated by Legelisten as a part of their quality assurance process.

The Norwegian DPA received (and processed) several complaints related to the site since its inception in 2012. Their final decision relates to a case from 2015, when a dentist lodged a complaint after she had received a negative review. She claimed that the processing of her personal data did not have a legal basis og demanded to have her personal data removed from the site. The DPA disagreed and the case was submitted to the Norwegian Privacy Appeals Board (Personvernnemda), who returned the case to the DPA for new processing due to lack of consideration of the dentist's demand to have her personal data removed from Legelisten.

This time, the DPA also considered several other aspects of the case, particularly if Legelisten was the controller (Legelisten claimed they acted as a processor) and if Legelisten had legal grounds for processing reviews of healthcare personnel. The DPA also considered exemptions or derogations for processing carried out for journalistic purposes or the purpose of academic artistic or literary expression, or if the processing would be covered by the right to freedom of expression and information, seen against the Norwegian Personal Data Act, the Norwegian Constitution, and the European Convention on Human Rights.","The DPA investigated several aspects of the processing of personal data in the case, summarized below.

Personal data processing

The DPA described various categories of personal data processing:

Objective personal data' about healthcare personnel pertains to general information about their age, gender and when the invidivual received their license to practice medicine.

Subjective personal data' about healthcare personnel pertains to the reviews posted about them.

Information about warnings and penalties issued from the Norwegian Board of Health Supervision, also pertains to personal data about healthcare personnel.

Special category personal data about the users, when their review relates to the use of specialist healthcare services, for example a visit to a psychiatrist or oncologist.

Controller responsibility

The DPA found that Legelisten is the controller for all processing of personal data related to their site (as listed above), for both users and the healthcare personnel, because they in all these instances determine how the personal data will be processed (the purpose) and the means (technical platform, layout, which processors to use).

Legal grounds for processing

The DPA found that the legal grounds for processing of the various processing activities, are as follows:

* For the objective personal data about healthcare personnel: Article 6(1)(f), legitimate interest.
* For the subjective personal data about healthcare personnel: Article 6(1)(f), legitimate interest.
* For the information about warnings and penalties issed from the Norwegian Board of Health Supervision: Article 6(1)(f), legitimate interest.
* For the special category personal data: 
  * About diagnosis: Article 6(1)(a), cf. Article 9(2)(a), consent.
  * About the users' visits to a healthcare specialist (email address combined with review which relates to the use of specialist healthcare services): The DPA first reviewed the likely possible legal bases for processing (consent, fulfilment of a contract and legitimate interest), but concluded that there were no legal basis Legelisten could rely on for this processing activity and thus, the processing had to stop and all related data collected earlier, had to be deleted.

The relationship to freedom of speach and processing for journalistic purposes

The DPA found that there were no exemptions or derogations for processing carried out for journalistic purposes in this case. They also found that § 100(3) of the Norwegian Constitution, which relates to free speech, did not apply in this case, and that their decision does not contradict § 100(4) which relates to prior censorship. The DPA further found that their decision, which would result in an intervention in the freedom of speech, is justifiable seen against the European Convention on Human Rights Article 10.

Conclusion

In conclusion, the DPA held that:

1. Legelisten is required to allow healthcare personnel to opt out of being reviewed on the site, because this processing of their personal data lacks a legal basis.
2. Legelisten is required to establish an erasure policy to ensure that information about the withdrawal of healthcare personnels' authorisation to practice, licenses or approvals for specialist treatments, is deleted within five years after a new authorisation, license or approval has been granted, because this processing otherwise lacks a legal basis.
3. Legelisten is required to establish an erasure policy to ensure that information about the withdrawal of healthcare personnels' right to make requisitions, is deleted within two years after a new right has been granted, because this processing otherwise lacks a legal basis.
4. Legelisten is required to establish an erasure policy to ensure that information about the restriction of healthcare personnels' authorisation to practice, licenses, approvals for specialist treatments or right to make requisitions, is deleted within two years after the limitations have been repealed, because this processing otherwise lacks a legal basis.
5. Legelisten is required to establish an erasure policy to ensure that information about healthcare personnel who have received warnings from the Norwegian Board of Health Supervision, is deleted within two years after the warning was issued, because this processing otherwise lacks a legal basis.
6. Legelisten is required to ensure that information about the healthcare personnels' authorisation to practice, licenses, approvals for specialist treatments or right to make requisitions are correct and up to date.
7. Legelisten is required to delete information about healthcare personnel who no longer practice, because this processing of personal data is no longer relevant for the original purpose.
8. Legelisten is required to stop processing special category personal data by asking for or storing the email address of patients who have reviewed healthcare personnel in specialist health services, because this processing lacks a legal basis.
9. Legelisten is not granted an exception from the license requirement for processing personal data, because the processing of special category personal data lacks a legal basis.
10. Legelisten is required to provide information to healthcare personnel about the processing of their personal data.",NONCOMPLIANT,"Article 4, Article 5, Article 6, Article 7, Article 9, Article 85","[36,39,22,21,41]"
"In May 2018 a pupil at a school in Bergen notified the ICT helpdesk of a folder he had found online, containing several files with usernames and passwords of over 35,000 users. However, the school management did not follow up on the notice.

In August, the pupil logged onto the learning management system as the school's principal and sent a message to several people. He expressed later that he did so because the school had failed to take his first notice seriously. When the school discovered this, it notified the police, who found out that the pupil sent the notification. He admitted he had simply guessed the principal's password.

The municipality failed to first notify the Norwegian DPA (Datatilsynet) of the breaches, who discovered these initially after being contacted by several media outlets (after the municipality sent out a press release the same day).

The DPA's investigation revealed that the school had failed to enable two-factor authentication, despite a campaign the DPA conducted in 2013-2014 in the education sector. At the time, the DPA instructed all municipalities in Norway to enable strong authentication on their learning management systems and other administrative systems. Thus, the DPA argues that it is beyond doubt that Bergen municipality was well aware of this security requirement.

Following this incident, the municipality reset all passwords and enabled two-factor authentication.","The DPA first instructed Bergen municipality to enable two-factor authentication in their systems, cf. Article 5(1)(f) GDPR, cf. Article 32(1)(b). Second, the DPA fined the municipality about €158,315 (NOK 1,600,000) for the lack of sufficient technical and organisational measures required by Article 5(1)(f) and Article 32(1)(a) and Article 32(1)(b).",NONCOMPLIANT,"Article 5, Article 32","[10,3,22,8,34]"
"The case concerned vulnerabilities in the  mobile app “Skolemelding”.  In the application, pupils and guardians can communicate with teachers and administration at the school. There was a security issue with the application, where unauthorized users could access the application as authorized users and thus gaining access to the personal data of students. More than 63 000 pupils        were included in the data breach. In the application it was also possible to register special categories of data concerning the pupil in a “free-text” format, for example when sending the school information about why the pupil was too sick to attend school.","The fine was issued on the basis of a lack of security surrounding the log-in function, a breach of Article 32(1)(b). In addition, the application was launched without proper security testing, and included security flaws well known to the security community, a breach of Article 32(1)(d). Finally, launching the application with an unacceptable vulnerability, which the municipality did not conduct proper steps to close, and a lack of control with the supplier (CGI) regarding the results of the security testing, was a breach of the principle of accountability following Article 5(2) in conjunction with Article 5(1)(f).

The issued fine was NOK 1,200,000 (approximately €120,000), which was lower than the initially suggested fine of NOK 2,000,000 (approximately €200,000). The fine was lowered in part due to the quick action by the municipality to address the flaws and secure the personal data, and in part due to cooperation with the DPA, showing a will to fix the security flaws.

The municipality did not contest the evaluation by the DPA regarding the scope of the security breach.",NONCOMPLIANT,"Article 5, Article 32","[17,0,30,40,29]"
"A data subject lodged a complaint against the Norwegian Public Roads Administration (the controller) for failing to delete toll road crossings logs, which included personal data related to the car tag number, location and time of crossing. The data subject demonstrated that the controller still (at the time of the complaint) stored personal data about their place of residence dating back to 2008 and 2010.

The controller may legally store personal data related to toll road crossings for accounting purposes, but when the purposes have been fulfilled (storage for 5 years as per Norwegian accounting rules), the personal data must be deleted in line with Article 17(1) GDPR. However, the system used for keeping this data, lacked deletion functionality and the DPA found that the controller had not assessed, nor implemented, technical and organisational measures as required by the GDPR.

The Norwegian DPA's investigation revealed a complex situation of several involved parties and confusion around roles and responsibilities. The DPA, however, reasoned that the Norwegian Public Roads Administration was the controller for the personal data concerned.

Other parties involved were toll operators and a software supplier. The involved parties had argued amongst themselves who were to blame for the violations of the GDPR, with letters dating back to May 2017. The controller claimed they could not delete the personal data in question since the software system (where the toll road crossings logs were kept) lacked deletion functionality.","As the DPA had reasoned that the Norwegian Public Roads Administration was the controller and thus ultimately responsible for the processing of the personal data, the decision was made against them and not the other parties involved.

The Norwegian DPA instructed the controller to, without undue delay, delete the personal data related to the toll road crossings logs where the purpose for storing has been fulfilled. For the violations described above, the DPA held that they intended to fine the controller NOK 4 million for violating Article 5(1) GDPR, Article 17(1)(a), Article 17(1)(d) and Article 25(1), cf. Article 5(1)(c), Article 5(1)(d), Article 5(1)(e) and Article 5(1)(f).

However, the controller contested the decision, leading the DPA to reassess the case and subsequently reduce the fine to NOK 1 million (approximately €98,000 in June 2021).",NONCOMPLIANT,"Article 5, Article 6, Article 17, Article 25","[46,34,38,25,37]"
"The municipality sent a notification of a personal data breach to Datatilsynet concerning the use of the app Showbie, which started an investigation by Datatilsynet. (The fine was later reduced, see updated case description here.)

The app was used in school by a group which consisted of pupils with special needs. The main use of the app was to ease communication between the school and the home, in particular with regards to communication messages about absence. The app did not include separate accounts or logins for parents and the pupils. Information concerning “health” and “medications” could be added to tabs in the app. The tabs did not include health information, but personal data regarding medication was found in the calendar and in chats with parents. There were no guidelines or routines on how to use the app securely. Teachers and employees used the school’s wireless internet, while the parents used it on unsecured home networks or mobile internet. There was no two-factor authentication implemented, as required under security level 4 when dealing with health information","Datatilsynet highlighted statements from the municipality concerning how Showbie was not adapted for the processing of special categories of personal data, and that there had been no assessment of the risks connected to such processing. The person responsible for IT-security in the municipality stated that the app did not fulfil the requirements for the appropriate security level to process health data pursuant to Article 5(1)(f) GDPR, a conclusion Datatilsynet seemed to support in their decision.

Furthermore, Datatilsynet found it necessary to highlight that the established security level did not conform to the requirements under Article 32(1)(b), and ordered the municipality to implement measure to ensure a sufficient level of security.

Datatilsynet found that the municipality did not clearly communicate that the app should not be used to process special categories of data. The inclusion of the folders “health” and “medication” was carried out in cooperation between the special needs group at the school and the company RIKT AS. Datatilsynet emphasized that an impact assessment pursuant to Article 35 GDPR would have clearly established this.

The municipality did not find that any unauthorized persons had used or taken advantage of the lack of security. However, Datatilsynet stated that unauthorized persons could have had the opportunity to access personal data in the app due to the lacking security.",NONCOMPLIANT,"Article 5, Article 32, Article 35","[31,42,16,9,11]"
"A data subject lodged a complaint against the Norwegian DPA for several GDPR violations related to their website (https://www.datatilsynet.no). Since the DPA is disqualified from managing complaints lodged against them, the Ministry of Local Government and Regional Development, administratively superior to the DPA, appointed an external party to assess the complaint and make a decision.

First, the data subject claimed that the DPA violates Article 6 GDPR because they base all processing activities relating to website visits on Article 6(1)(f), when the second paragraph of Article 6(1) states that this lawful basis does not apply to processing carried out by public authorities in the performance of their tasks. The data subject opined that since the DPA is a public authority and operating their website happens as part of their tasks, they could not rely on this lawful basis. In addition, the data subject claims that even if the DPA could base certain processing activities on this lawful basis, the interests claimed are not necessary for the processing in question, for example claiming that storing keyword searches are not necessary to operate the website.

The DPA responds that they have assessed several possible lawful bases for processing of personal data in relation to their website, for example Article 6(1)(e) and Article 6(1)(a). However, they felt that (e) was not appropriate and that (a) was only partly appropriate. Thus, they concluded that Article 6(1)(f) was the correct lawful basis. As for the complaint from the data subject, they refer to the legal preparatory works related to the GDPR, where the Ministry of Justice and Public Security assumes that the exception referred to in the second paragraph of Article 6(1) only refers to the processing of personal data related to the exercise of the public authorities' tasks. The DPA also refers to the French DPA's use of this lawful basis for several of their processing activities and purposes.

Second, the data subject claimed that the DPA violates Article 13(1)(d) because the website privacy notice fails to specify which legitimate interests as per Article 6(1)(f) the DPA claims for the processing of the website feedback function and storing comments on their blog, contrary to the Article 29 Group's recommendations. The DPA admits that this information is missing, due to a mistake, but that it was corrected a long time ago.

Third, the data subject claimed that the DPA violates Article 5(1)(b) for not stating specific enough purposes, and thus also violating Article 5(2). The DPA disagreed and referred to their privacy notice, and to their internal controls system information security, privacy and data protection, as regards the accountability principle.

Fourth, the data subject claimed that the DPA violates Article 57(2) for not allowing data subjects to lodge complaints electronically and for making it unnecessary difficult to find information about how to lodge a complaint. The DPA disagreed and referred to the various ways this information was made available on their website. They agreed, however, that the current setup of lodging complaints was too cumbersome and not user friendly. They had been working on an online solution and expected this to be done during the Spring of 2020.

Fifth, the data subject claimed that the DPA violates Article 77 when requiring data subjects to contact the controller for a complaint, before lodging one with the DPA. The DPA justified this with the dramatic increase in number of cases over the last years and their experience with seeing many cases being resolved when the data subject contacts the controller directly. They admitted, however, that there could be necessary to soften the language, and therefore changed the word ""must"" to ""should"".","The General Director's replacement (""GDR"") held the following:

1) The DPA had not violated Article 6(1)(f). The GDR agreed with the DPA that there are no other lawful bases for the processing of personal data in relation to their website. The GDR referred to Recital 47 GDPR and that the DPA's tasks as per Article 57(1)(b) falls outside of the exception referred to in the second paragraph of Article 6(1). Finally, the GDR considers the necessity requirement to be fulfilled since the GDPR itself outlines the needs for information, cf. Article 57(1)(b).

2) The DPA violated Article 13(1)(d) because they failed to specify the legitimate interests claimed for the processing of the website feedback function and storing comments on their blog. As this was already recified by the DPA, the GDR only sufficed by stating his criticism in this regard.

3) The DPA had not violated Article 5(1)(b) or Article 5(2), cf. Article 24. The GDR notes that the DPA states 12 different purposes for processing personal data in their website privacy notice. To properly assess this allegation, the GDR would have to do a relatively comprehensive review of each purpose. Since the complaint does not specify exactly why the purposes are not explicit enough and does not specify any particular negative consequences for the data subject, the GDR does not find any violations in this regard.

4) The DPA had not violated Article 57(2) as the GDR found the information about how to lodge a complaint to the DPA, as sufficient, and because he does not interpret the Article to require electronic submissions of complaints.

5) The DPA violated Article 77 in requiring data subjects to first contact the controller directly and provide documentation relating to their complaint, to the DPA. The GDR assumes that the DPA will take necessary measures to correct these violations.",NONCOMPLIANT,"Article 5, Article 6, Article 12, Article 13, Article 24, Article 57, Article 70","[24,11,30,46,6]"
"Bergen municipality notified Datatilsynet of several personal data breaches pursuant to Article 33 GDPR concerning the use of the Vigilo-app.

Through the use of the app, biological parents without parental responsibility received information by email about which school the pupil attended - in total 477 parents without parental responsibility received such an email. By logging in to the app, information about the child's name, school/kindergarten, which grade, employees at the school, and the name of parents with parental responsibility could be found.

In addition, information that pupils were living on a secret address was disclosed to 113 parents.","Datatilsynet criticized the lack of security, and pointed amongst other things to an insufficient risk assessment, the time it took to issue guidelines to prevent such data breaches and the lack of quality of the guidelines, and an insufficient understanding of how the app worked at the time of rollout.",NONCOMPLIANT,"Article 5, Article 32","[42,45,27,26,48]"
"In early 2021, a Norwegian municipality (Østre Toten kommune) realized they had been exposed to a serious ransomware attack that locked employees out of key IT systems. Data had been encrypted and backups deleted.

About 30,000 documents were affected by the breach, including information about ethnic origin, political opinion, religious belief, trade union membership, sex life/sexual orientation, health, pedagogical diagnosis, birth number, electronic ID and bank account. About 2,000 documents were later discovered up for sale on the dark web. In total, about 160 GB of data was extracted and a large amount of data was irreparably lost.

The technical investigation revealed that the municipality had severe deficiencies in their IT systems and processes, including unsecured back-ups and the lack of two-factor authentication and proper log management. The criminals had likely gained access to the infrastructure through remote access solutions, combined with stolen login credentials which were likely obtained through phishing scams directed at the municipality's employees (about ten email addresses and passwords belonging to employees were discovered during the investigation).

The municipality notified the DPA about the breach and kept their inhabitants continuously informed. They also initiated a comprehensive work to establish routines for processing personal data and for data breach management.","The Norwegian DPA found that the municipality had neither protected personal data sufficiently, nor had proper internal controls in place, in breach of Articles 5(1)(f), 24 and 32, cf. the Personal Data Act § 26(1).

For this, the Norwegian DPA fined the municipality €409,768 (NOK 4,000,000). In addition, the DPA instructed the municipality to establish and implement an appropriate information security management system, and to conduct (and document) risk assessments for all key systems in their infrastructure with the aim of identifying the need for risk-reducing measures.",NONCOMPLIANT,"Article 5, Article 24, Article 32","[41,38,23,34,28]"
"Following a routine sweep of Irish IP addresses, the Irish National Cyber Security Centre (CSIRT-IE) discovered the exposed personal data of millions of people. They alerted the Norwegian National Cyber Security Centre (NCSC), who then alerted NIF.

The data breach followed NIF's move from an on-premise solution to Azure and was related to testing of a service (Elasticsearch) that was meant to improve member administration. NIF decided to conduct the testing on real data and, further, that it was necessary to use a significant amount of data. They also felt it was essential to conduct the testing quickly. NIF has admitted that they didn't conduct sufficient risk assessments, nor did they assess whether it was possible to use anonymized data or a narrower data selection.

The personal data was exposed online in a total of 87 days. As soon as NIF was notified of the breach, they immediately corrected the mistake. It's not know if anyone has actually exploited the data breach.

The personal data involved in the breach were names, gender, birth date, address, phone number, email address and club affiliation. Of the 3,2 million people affected by the breach, almost half a million were children aged 3-17 years.","The DPA held that NIF breached several fundamental principles as per the GDPR, as they lacked sufficient risk assessment, considerations, routines and security measures.

The DPA found that the testing was conducted without sufficient risk assessments and that NIF lacked routines and security measures to properly protect the personal data, thus breaching Article 32. The DPA also emphasized that the purpose for the processing (testing new solutions for member administration) could have been achieved in a less intrusive way, e.g. by processing synthetic data - or, at least, through processing significantly less personal data. NIF should also have limited the categories of data subjects on which the testing was conducted.

The DPA further assessed and concluded that NIF didn't have a purpose for the processing as per Article 5(1)(b), nor legal grounds as per Article 6.

In sum, the DPA found that NIF had breached Article 5(1)(a), (c) and (f), Article 6, and Article 32. For this, NIF was fined NOK 1,250,00 (~€123,656).",NONCOMPLIANT,"Article 5, Article 6, Article 32","[6,20,29,26,10]"
"In December 2019, the Norwegian DPA (Datatilsynet) was contacted by the National Criminal Investigation Service regarding a tip they had received about a webcam livestreame from a town's city centre, and consequently launched an investigation.

The company (Dragefossen AS, the controller) had installed a camera on the roof of the building they were located in. The camera rotated 360 degrees in the span of two minutes, but due to the setup, only about 270 degrees was in practice captured. A public road, the parking lot and entrance to several shops, a liquor store, bank, the town hall and several other buildings were recorded.

Footage was then livestreamed to their YouTube channel, which had 1090 subscribers on 26 May 2020 and 1530 subscribers on 1 October 2020. The DPA noted that they did not know how many in total had viewed the livestream, which had started on 19 August 2019, but that a prior livestream sent on 28 January 2019 had received 13,000 views during 140 days.

Recordings were saved on a dedicated server for 14 days before deleted, and had been shared with the police on several occasions in relation to events in the city centre.

The controller had informed about the webcam on their Facebook page and claimed that it was setup as a service to the town's inhabitants. They claimed that due to the low quality and distance of the recording, number plates or faces would not be recognisable.","Personal data

The DPA agreed with the controller's claim that it was unlikely that number plates or faces of people would be recognisable due to the distance and the quality of the recording. The DPA highlighted, however, that it would be possible to recognise the type of car someone was driving, what type of clothes people were wearing, the colour of their hair and rough hair style. The DPA highlighted that prior knowledge about someones schedule, shopping patterns, their car or their look could identify the person being recorded, for example by friends, significant others, family or colleagues. This view was supported by the police requesting access to the recordings on several occasions concerning events in the city centre.

As such, the DPA held that the recordings captured personal data pursuant to Article 4(1) GDPR.

Legal basis

Since the controller did not use the recordings, they had not assessed whether there was a legal basis for the processing as per Article 6. The DPA therefore assumed that the legal basis would have been legitimate interest as per Article 6(1)(f).

The DPA identified two processing operations with different purposes. The first one was the live feed of the city centre, where the purpose was to provide a service to customers and local residents. The second processing operation was saving the recording and keeping it for 14 days, for the purpose of providing security to the local residents by sharing the recordings with the police if needed.

Balancing of interests

For the first purpose, the DPA also questioned whether the recording pursued a legitimate interest, finding that it did not need to conclude as the balancing of interest was in the data subjects favour. The DPA also noted that the placement of the camera could be positioned at an angle that would not be as invasive to the privacy of the data subjects.

For the second purpose, the DPA held that it could not be established for certain that there was a legitimate interest for storing the recordings. The DPA referenced EDPB guidelines which state that purposes connected to protection against theft, vandalism and criminal acts may be a legitimate interest, noting however that such a purpose must be connected to a specific event and not based entirely on speculation. The DPA questioned whether a real danger for criminal acts was established, finding however that it did not need to conclude as the rights and freedoms of the data subject clearly outweighed the controller's interest.

Consequently, the DPA held that the camera surveillance and livestreaming violated Article 6(1) and Article 5(1)(a) and fined the controller €15,000.",NONCOMPLIANT,"Article 4, Article 5, Article 6","[31,34,38,9,17]"
"A trade union lodged a complaint about a controller for unlawful use of camera surveillance in the business. According to the complainant, the camera was put in place because they demanded a collective agreement for their members (i.e., the employees of the business). The camera, which was angled towards the reception area and the area towards the treatment room, had built-in microphone and speaker, motion sensor, full HD, 130 degrees view and comes with a mobile app with real-time access and access to recordings from the last seven days.

The general manager of the business had installed the mobile app on her phone and had not, according to the employees, discussed or informed the use of camera surveillance, with any of them. The general manager, however, claimed that she not only had discussed this with the employees, but they had requested her to install the camera because of violent incidences and other crime in the area. Despite this, she was not able to provide any documentation or proof of this discussion and agreement with the employees, which she considered unnecessary since the business is so small and verbal agreements should suffice.

The camera surveillance eventually stopped, but only because the camera itself stopped working.","The Norwegian DPA (Datatilsynet) held that the controller had breached Articles 5(1)(a) and (c), 6, 12(1) and 13 GDPR and for this fined the controller NOK 100,000 (approximately €9,473). The fine was reduced from NOK 150,000 because the business had a reduced turnover following the circumstances around COVID-19.

The DPA emphasized in particular that:

* The camera had a wide-angle lens capable of capturing 130 degrees.
* The camera was angled towards the reception area and the area towards the treatment room.
* The camera was able to record sound.
* The general manager had remote access through a mobile app on her mobile phone.
* The camera was enabled and the surveillance was active at all times, including with motion sensor.

Further, the DPA commented that the controller should have conducted a Data Protection Impact Assessment (DPIA) before installing the camera and considered other, less invasive ways to achieve the claimed purpose.",NONCOMPLIANT,"Article 5, Article 6, Article 12, Article 13","[12,33,43,6,19]"
"Following a news story on 25 October 2019, the Norwegian DPA (Datatilsynet) initiated an investigation into a road toll company ""Ferde AS"" for their transfers of personal data to a processor in China. The DPA limited their investigation to the period September 2017 to October 2019 and didn't assess the content of data processing agreements, risk assessments or issues related to the Schrems II ruling.

In 2017, several toll companies were merged and Ferde was established with effect from January 2018. Ferde registers car crossings in their toll stations and if a car passes without a toll transponder, or this doesn't register properly, a photo is taken of the car registration number (plate) and the image sent for automatic optical recognition processing. If the image quality is insufficient for automatic reading, it is forwarded for manual analysis to the company Unitel Braseth Services (UBS), who has employees in China. The software used is provided by the company Q-Free, where all data is stored in Norway.

Personal data include car registration numbers, time stamps and a numerical code corresponding to the station which was passed. About 12,5 million images are sent every year for manual processing, of which 10 million for regular processing and 2,5 million for follow-up processing. Since these are transferred to Ferde's processor UBS, with employees in China, it means personal data is transferred to a third country.

The DPA's investigation and an internal audit conducted by law firm Kluge AS revealed a number of deficiencies in Ferde's privacy and data protection practices:

1. Ferde had a data processing agreement with UBS, but this was undated and likely not in place between September 2017 to September 2018; 
2. Ferde's risk assessment for the use of UBS (and manual image processing in China) was undated and likely not in place between September 2017 and October 2019. The DPA noted that although Article 32 GDPR does not explicitly state the time when to conduct a risk assessment, it can be inferred from Article 5(2) GDPR, Article 24 GDPR, Article 25 GDPR and Article 32 GDPR, read together, that such an assessment should take place before the start of the processing operations in question; 
3. Ferde had signed the European Commission standard contractual clauses for the transfer of personal data to third countries, but this was undated and likely not in place between September 2017 and spring 2019. 

Furthermore, the DPA noted the following aggravating factors:

1. The infringements are breaching the fundamental requirements of having in place data processing agreements, risk assessments and valid transfer tools for third-country transfers;
2. The large amount of personal data transferred to China;
3. The duration of the violations (i.e. more than a year);
4. The negligence of not adhering to basic privacy and data protection obligations. The DPA noted in particular that the responsibility is with Ferde's Board of Directors, in accordance with the Norwegian Limited Liability Companies Act, and underlined that this negligence is to be attributed to the board, represented by the Chairperson.
5. The serious deficiencies with Ferde's internal control system.","The DPA fined Ferde NOK 5,000,000 (~€499,373) for:

1. Violating Article 28(3) GDPR for not having a data processing agreement in place;
2. Violating Article 32(2) GDPR, cf. Article 5(1)(f) GDPR and Article 5(2) GDPR for not having conducted a risk assessment; and
3. Violating Article 44 GDPR, for not having a transfer mechanism in place for the transfer of personal data to a third country.",NONCOMPLIANT,"Article 5, Article 28, Article 32, Article 44","[10,33,3,42,41]"
"The company Miljø- og Kvalitetsledelse operates a car wash facility, where a payment terminal was vandalised. Since the company had CCTV/camera surveillance, they were able to determine who the culprit was and, consequently, reported the incident to the police (and also to the culprit/data subject himself).

However, the company went on to disclose the footage to the data subject's employer, as they considered him to be ""out of balance"" because the data subject had also contacted a lawyer. The data subject was not notified of, nor consented to this disclosure.",The DPA held that the company lacked legal basis for the disclosure to the data subjects's employer and was therefore in violation of Articles 5(1)(a) and 6(1) GDPR. The recordings had already been handed over to the police and the further disclosure to the data subject’s employer was unnecessary for the (legitimate) purpose of preventing vandalism or resolving the case.,NONCOMPLIANT,"Article 5, Article 6","[23,46,17,25,34]"
"Coop Finnmark SA is part of a Norwegian cooperative selling groceries and more. The company submitted a data breach notification to the DPA after a store manager had filmed surveillance footage with his private mobile phone and shared this with a third party. He believed children were stealing, and his intention was to identify these. The woman he shared the footage with, sent it to her son, who sent it to someone else. The recording was, as such, shared with several people and reached, in the end, the child who was evidently stealing.

The store manager realized his mistake following the incident, notified the DPA and apologized to everyone involved.","The DPA notes that the company has legal grounds for using surveillance in their shop, in general, as per Article 6(1)(f). Filming and sharing a recording from the footage, however, is a new processing activity which also requires legal grounds as per the GDPR. The company has not determined legal grounds, as this processing activity shouldn't take place and is a breach of the company's internal routines.

The DPA notes that the purpose of the processing was to identify the children in the footage. Sharing the footage with third parties, however, was not necessary to achive the purpose. The company should have reported the incident to the police and waited for them to initiate a criminial investigation, including asking for surveillance footage.

Consequently, the DPA held that the company didn't have legal grounds for sharing the footage, as per Article 6. As the processing lacked legal basis, they were also in breach of Article 5(1)(a) GDPR. The company was fined €38,800.",NONCOMPLIANT,"Article 5, Article 6","[42,41,9,47,24]"
"Disqus is an American company owned by Zeta Global. The company offers an online public comment sharing platform, which was previously used by a number of Norwegian online newspapers, and it also engages in programmatic advertising.

The Norwegian DPA was made aware of the matter through news articles by the Norwegian National Broadcaster (NRK). According to the NRK, Disqus conducted unlawful tracking of visitors to Norwegian websites using the Disqus plugin. Their data were then disclosed to third party advertising partners. The NRK further wrote that this happened because Disqus was unaware that the GDPR applied in Norway, which Disqus’ parent company Zeta Global confirmed in an interview.https://www.datatilsynet.no/en/news/2021/intent-to-issue--25-million-fine-to-disqus-inc/","The Norwegian DPA ('Datatilsynet') found that both the material and territorial scope applied to the processing of personal data, with the DPA having competence to decide the case.

Datatilsynet highlighted that Disqus tracked, profiled and shared the personal data of all visitors to the websites implementing the Disqus widget without the users' knowledge, finding a breach of Article 12(1), 13 and 5(1)(a) GDPR.

Datatilsynet found that the processing could have been carried out with less invasive means, and did not pass the necessity condition pursuant to Article 6(1)(f) GDPR. In addition, the processing did not pass the balancing test. Datatilsynet highlighted the negative impact of wide-scale profiling, and that Disqus' interest in providing behavioral online marketing are less important compared to the adverse negative effects on the data subjects, and ""must weigh significantly less in the balancing of interests"" (p. 38).

In addition, Datatilsynet found that Disqus' failure to identify GDPR as applicable data protection law and failing to implement data protection safeguards in accordance to the GDPR was a breach of Article 5(2) GDPR.",NONCOMPLIANT,"Article 5, Article 6, Article 12, Article 13","[31,49,39,13,16]"
"A Norwegian hospital notified the DPA of three personal data breaches lasting between two and nine years.

The breaches found their origin in deficient internal systems upgrades, poorly managed access controls, routines not being followed, and lack of data deletion. The concerned personal data included names, social security numbers, health metrics data, sensitive health data (including information on substance abuse, or health data relating to children), and passwords stored in clear text in an unprotected server.

These breaches were discovered during an audit by the Norwegian Office of the Auditor General. A significant number of patients were affected (e.g. about 21,000 records containing sensitive health data in one breach alone). However, the hospital did not have a comprehensive log, making it impossible to fully determine the extent of each breach.","The DPA fined the hospital €76,870 (NOK 750,000) for breaching the requirements of internal control, security and safety for the processing of personal data under Article 32 GDPR, Article 24, Article 5(1)(f) and Article 5(2), as well as § 26(1) of the Personal Data Act  and §§ 22 and 23 of the Health Records Act (pasientjournalloven) .

The DPA also pointed out that the highest-level management position, on behalf of the hospital, is accountable for the (negligent) violation.",NONCOMPLIANT,"Article 5, Article 24, Article 32","[20,34,48,49,17]"
"An employee in a municipal health care center had access to highly sensitive personal data (image files) through an incorrectly configured script in a system used for creating letters. When adding images to the letters, they could access personal data about people with no affiliation to the municipality, including information about medical appointments, doctors' referrals, epicrisis and various medical examinations. The breach lasted from 01.01.2018 to 15.11.2019.

When the municipality discovered the breach, they chose not to contact the processor because of the gravity of the breach. Instead, the only informed employees using the system to avoid opening image files not created by the municipality, and sent a breach notification to the DPA. The DPA had to contact the processor about the breach, who consequently deleted the image files immediately and corrected the script.

Despite having an internal controls systems in place, the municipality admitted that it had been a challenge to ensure sufficient compliance throughout the organisation. Following the dialogue with the DPA, they increased their focus on information security and breach management, including procuring external assistance.","The DPA fined the municipality €40,478 (NOK 400,000) for breaching Article 32(1)(b) GDPR and Article 32(2), cf. Article 24 and requires them to submit to the DPA documentation on new policies and procedures.

The DPA found it aggravating that the municipality only took action to rectify the breach after the DPA sent their notification of the intent to issue a fine and corrective measures, i.e., about 11 months after they discovered the breach. Also, the fact that the case pertains to special category personal data as per Article 9 GDPR, increased the gravity of the breach.

Finally, the DPA assumed that the chief municipal executive (Norwegian ""rådmann""), as the main responsible on behalf of the municipality, is the one who had acted negligently and partly with intent.",NONCOMPLIANT,"Article 24, Article 32","[26,27,19,10,38]"
"The Norwegian Public Service Pension Fund  (SPK - Statens pensjonskasse) reported a personal data breach in September 2019. Between 2016-2019, they obtained a large amount of personal data from the Norwegian Tax Administration, much of which was not needed for their purpose. The data was meant to be used for correcting disbursed disability pensions. However, SPK lacked a filter to prevent receiving and storing unnecessary data, as well as organisational measures for deleting the superfluous data.

SPK themselves categorized the breach as serious, as it involved processing highly sensitive personal data about a vulnerable group of people (those receiving disability pensions). In total, about 44,000 people were affected by the breach, of which about 24,000 receiving disability pension.","First, the DPA stated that, although the SPK could rely on both Article 6(1)(c) and Article 6(1)(e) GDPR, the processing must have been necessary. The same necessity requirement follows from Article 9(2)(b) GDPR, since SPK processed health data. Because SPK processed unnecessary income information that was obtained from the Tax Authority, the necessity requirement was not met, in violation of Article 6(1) and Article 9(2) GDPR. In addition, the DPA found that the Public Service Pension Fund (SPK) had obtained excess personal data not needed for the purpose of calculating correct disability pension disbursements, in breach of Article 5(1)(c) GDPR. Lastly, SPK lacked sufficient routines for assessing what personal data was needed and for deleting superfluous data, in breach of Article 5(1)(e) GDPR.

Although the DPA found that the violations were not found intentional, but negligent, and SPK took measures to limit the damage, SPK violated basic principles of the GDPR, special categories of personal data were involved, and a large number of persons was affected. Hence, the DPA concluded that SPK needed to be fined, and considered the fine of € 99,940 (NOK 1 million) to be sufficient.",NONCOMPLIANT,"Article 5, Article 6, Article 9","[36,2,30,17,13]"
"A representative acting on behalf of Gveik AS conducted a credit rating on the complainant's sole proprietorship, despite the latter having no customer relationship or any other affiliation with either the representative or the company. The representative claimed that the credit rating was conducted by mistake and that they had tried to cancel it, unsuccessfully. The DPA noted that the credit rating seems to have been conducted due to ""nosiness"".

Gveik AS didn't have written routines for credit ratings, because these are only conducted for new customers and customers that ""request many new services"".","No, Gveik AS did not have legal grounds for processing the personal data of the complainant for credit scorings, as per Article 6(1)(f). For this offense, the company was fined NOK 75,000.

They also didn't have sufficient internal controls for the use of credit scoring in their business, as per Article 24. For this offense, the company is required to establish corresponding internal controls and submit a written confirmation and actual documentation of the internal controls, to the DPA.

The DPA also noted that Gveik AS likely didn't have sufficient technical and organizational security measures, but didn't find strong enough evidence to add further penalties for this.",NONCOMPLIANT,"Article 5, Article 6, Article 24, Article 32","[11,29,34,44,23]"
"The DPA reviewed two events where a company had obtained access to an employee's emails. In the first case, the company had accessed her inbox due to an acute situation where they needed to obtain crucial (business) information while the employee was on vacation (and couldn't be reached).

In the second case, however, the general manager had introduced a new policy, requiring the employee to continuously forward all her emails to a shared, common inbox at the company. After a month, she disabled this, however was instructed to enable it again.","In the first case, the DPA agreed that the company had a legal basis, due to an acute nature of the situation and the need for crucial (business) information. In the second case, however, the DPA held that the company had no legal basis for such processing, as it's highly invasive and not justified. The legal basis the company referred to, a national regulation concerning employers' access to employees' inboxes and other electronical material, was not applicable in this instance.

The DPA held that the company had no legal basis as per Article 6(1)(f) GDPR and that they had failed to inform the employee sufficiently as per Article 13 GDPR. Consequently, they were fined NOK 250 000 (€24,772), and also have to improve their internal controls in line with Article 24 GDPR.",NONCOMPLIANT,"Article 6, Article 13, Article 24","[27,30,28,13,39]"
"A former student asked a school to share their school folder. The municipality's routine is to keep records for access requests, which meant, in this case, that the folder was scanned and made available for access. It was, however, made openly available on their website and a local journalist was able to download the entire folder with its contents. The information was confidential, cf. the Education Act.

When the error was discovered, the folder was removed and the municipality notified the DPA of the personal data breach, as well as the affected data subject.","The DPA concluded that the municipality had breached the required information security requirements as per Article 32(1)(b), cf. Article 5, and that they didn't have any legal grounds for this processing as per Article 6, cf. Article 5 (the latter because the information was confidential and should never have been published openly). The municipality was fined €18,860.",NONCOMPLIANT,"Article 5, Article 6, Article 32","[42,20,33,11,48]"
"The complainant was subjected to multiple credit ratings by Innovation Norway*, despite having no customer relationship or any other affiliation with the latter. Nine credit ratings were conducted by one single employee, and it's unclear why the employee had the need to conduct these. One credit rating was conducted by a different employee, however this was due to a misunderstanding when investigating the other credit ratings.

When contacted by the DPA, Innovation Norway admitted they had no legal basis for this processing. They had routines for how to manage credit ratings, however this was found to be too generic, outdated and not adhered to. Innovation Norway had decided not to notify the DPA of the personal data breach, as they didn't consider the incident to have triggered this requirement as per Article 33 GDPR.

* Innovation Norway is state-owned and the Norwegian government's instrument for innovation and development of Norwegian enterprises and industry. Their programs and services are aimed at stimulating entrepreneurship in Norway. Conducting credit scoring of individuals and companies are common practice and not an issue in itself. The issue here was the misuse of credit scoring by one employee.","1. The DPA held that Innovation Norway did not have a legal basis as per Article 6(1)(f) GDPR to conduct the credit ratings in question.
2. They also held that Innovation Norway hadn't followed up on their own internal policies and procedures and these were insufficient.
3. They also held that Innovation Norway breached their duty to notify the DPA three of the (first) personal data breaches (unlawful credit ratings), however they upheld it at the fourth.

For these breaches, the DPA fined Innovation Norway NOK 1,000,000.",NONCOMPLIANT,"Article 6, Article 33","[6,7,22,32,38]"
"The temporary ban has its background from Datatilsynet’s decision to control the tracking app “Smittestopp”. Datatilsynet commented earlier on a lacking analysis of the risks and vulnerabilities connected to the use of the app. Datatilsynet decided to evaluate the app after receiving answers by the Institute of Public Health to an order of information connected to questions regarding the usefulness of the app, and if the interference to users privacy was proportional.

Unlike many other apps, Smittestopp use location data (to track movement) in addition to Bluetooth (to track whom the users’ were in contact with). The personal data is first stored locally, but approximately once an hour it is sent to an Azure server located in Ireland. The app would try to send the data for seven days provided it did not manage to connect to the server. The data was stored centrally for a maximum of 30 days. It was later planned that the data should be stored for a maximum of ten days.

The personal data uploaded was used for two purposes, tracking and limiting the spread of covid-19, as well as being used for research and analysis on aggregated and anonymised data.

Notification of covid-19 infections were only implemented in three (test) municipalities. A way to analyse, aggregate and anonymise the data was not in place at the time of the decision.

The users could not choose to share the data for one or both purposes.","Datatilsynet highlighted that the app is a big interference in users’ privacy, even during the threat of a pandemic, which entails that the processing of personal data is necessary and proportional. Part of this evaluation considered the social benefit of the app. According to the latest numbers, around 50-550 people in Norway was/is infected – approximately 0.01 % of the population. Existing measures works seemingly well in containing the spread of the virus.

Datatilsynet highlighted that the privacy impact happened at the time of collection, regardless of if the measures to anonymise, aggregate and use the data for research purposes was implemented, as the personal data is collected for these purposes.  It further stressed that as a controller, the Public Health Institute is responsible for clarifying which personal data is used for what purpose, and the Public Health Institute needs to establish that it is necessary to process each concrete (category) of personal data for the specific purpose.

Even if the measures to anonymise the information is not implemented, the Public Health Institute should have a better overview over which information was necessary to achieve the different purposes of tracking and anonymization.

Datatilsynet also highlighted that in the eyes of the DPA, Bluetooth technology is sufficient to achieve the aim of tracking and notifying users of covid-19 infection. In addition, that the Public Health Institute had not provided in a satisfactory manner why GPS location data was strictly necessary. In addition, the users should have the option to only use the data for one purpose and not the other, if they so wanted.

Datatilsynet concluded that Smittestopp was not limited to collecting data to what is necessary to fulfil the purpose of the app. As such, Datatilsynet found the app to be in breach of the data minimization principle found in Article 5(1)(c) GDPR.

The Public Health Institute did not have a good solution for dealing with subject access requests. In addition, deleting uploaded data from the app also deleted information about who had accessed the personal data. Datatilsynet highlighted that both were a breach of the data subject’s right to access under Article 15 GDPR, and thus also a breach of the principle of openness pursuant to Article 5(1)(a) GDPR.

Datatilsynet stressed that by issuing a temporary ban it would have the opportunity evaluate if the users' privacy was sufficiently protected when the Public Health Institute wanted to resume processing. Datatilsynet highlighted that it was their view that the Public Health Institute would need to document that the processing was proportional and neccessary in a more sufficient way, or change the implementation.

Datatilsynet emphasized that it was not finished reviewing the security of the app.",NONCOMPLIANT,"Article 5, Article 15","[45,47,37,6,11]"
"In January 2020, the Norwegian Consumer Council (Forbrukerrådet) and NOYB filed three complaints against the gay/bi dating app Grindr and five adtech companies for personal data Grindr were disclosing through their app with the aforementioned third party advertisers (Twitter`s MoPub, AT&T’s AppNexus (now Xandr), OpenX, AdColony, and Smaato). In particular, they highlighted the amount of sensitive personal data shared by such tech and adtech companies, including exact location, which is highly problematic in several countries and poses a real threat to the fundamental rights and freedoms of individuals.

Grindr alleged that they had valid consent for their processing of personal data and special category personal data, including disclosure to third parties. The company further held that they had legal grounds for processing special category personal data as per Article 9(2)(e), as Grindr users ""manifestly"" had made their use of the app public, simply by using it.

The DPA conducted a thorough analysis on the matter, specifically concerning the fundamental requirements for valid consent, i.e. a consent must be freely given, specific, informed and unambiguous. Their analysis demonstrated that Grindr, in fact, were in breach of all consent requirements as per the GDPR.","The DPA held that Grindr's alleged legal grounds, namely consent as per Article 6(1)(a) and explicit consent as per Article 9(2)(a), did not meet the requirements as per the GDPR. Further, they found that Article 9(2)(e) was not a relevant legal ground, as it couldn't be demonstrated that Grindr users ""manifestly"" made their use of the app public. Thus, Grindr did not fulfill one of the exceptions in Article 9(2)(e).

Consequently, the DPA held that Grindr did not have a legal basis under Article 6(1) for disclosing personal data to third party advertiserts, and that they did not have a valid exemption from the prohibition in Article 9(1) for processing and disclosing special category personal data. The DPA notified Grindr that they will be fined €9,610,000. The company has until February 15, 2021 to contest the fine.",NONCOMPLIANT,"Article 6, Article 9, Article 51, Article 58","[33,41,13,17,30]"
"Teachers at two junior high schools in Alesund municipality required their students to download the fitness app Strava for use in gym classes during the COVID-19 pandemic. The teachers used the app's tracking capabilities to validate that the students had conducted required exercises at home, for example bicycling a certain distance.

The teachers, schools, nor the municipality, conducted a risk assessment or a Data Protection Impact Assessment (DPIA) before deciding to use Strava in this way.","The DPA (Datatilsynet) held that the municipality had several breaches as per the GDPR:  1) For the lack of routines for technical and organisational security measures necessary to secure and demonstrate that the processing was in line with the GDPR, cf. Article 24(1).  2) For not having sufficient technical and organisational security measures in place to achive a level of protection suitable for ensuring confidentiality, integrity and robustness, and for not having conducted a risk assessment for the use of the app, cf. Article 32(1)(b), cf. Article 5.  3) For not conducting a Data Protection Impact Assessment (DPIA), cf. Article 35 (which the DPA assessed was necessary for this specific case).

For these breaches, the municipality was fined NOK 50 000,-.",NONCOMPLIANT,"Article 5, Article 24, Article 32, Article 35","[11,30,4,8,32]"
"A company enabled automatic forwarding of a former employee's emails, to ""uphold regular business operations"", and argued that it was the complainant fault this was deemed necessary. Despite several objections from the complainant, the company continued to monitor the email account over several months. The unlawful monitoring did not stop until the complainant contacted the DPA.","The DPA held that the company did not have a legal basis for monitoring the former employee's email account, as per Article 6(1)(f) GDPR. The DPA further held that the company failed to:

* provide the data subjects with required information, as per Article 13
* terminate the former employee's email account, as per Article 6(1)(f)
* erase the content of the former employee's email account, as per Article 17(1)(e)
* assess the former employee's objections, as per Article 21

For this, the company was fined NOK 200 000 (€19,600) and ordered to establish written internal controls and routines for access to current and former employees' email accounts and other electronic content, in line with Article 24.",NONCOMPLIANT,"Article 6, Article 13, Article 17, Article 21, Article 24","[10,20,41,16,38]"
"The two municipalities Rygge and Moss merged in January 2020. In the process of merging their IT systems for health records, several errors occurred:

* Incorrect registration of vaccines. Some people were registered as having received vaccines, when they in reality had not, and others were incorrectly registered as not having been given a vaccine, when they in fact had.
* Errors in health records for pregnant women, including error in the number of weeks into the pregnancy and related to information about the mother’s use of drugs/alcohol/nicotine.
* Patient health data was made accessible to unauthorized healthcare personnel and it was not possible to trace any unauthorized access (in Norway a patient has the opportunity and right to view who has accessed their medical information).
* Errors relating to daily operations (administration), such as appointment books.

28,000 people were transferred during the merger of the IT systems and about 2,000 could potentially have been affected by errors. However, no one were actually affected and the errors were rectified and are under control.

Moss municipality notified the DPA themselves about the personal data security breaches. The DPA found, in the end, that the municipality had breached § 22 of the Norwegian Health Records Act (pasientjournalloven) and Article 32(1)(b) and (d) GDPR (cf. Article 5 GDPR).","The DPA fined Moss municipality NOK 500,000 (€47,700) for insufficient technical and organisational measures to ensure a sufficient level of security when merging the IT systems. The DPA commented that the breaches were very serious and that the municipality should have conducted a data protection impact assessment (DPIA), as well as more testing before making the changes.",NONCOMPLIANT,"Article 5, Article 32","[37,11,39,26,9]"
"The Norwegian DPA (Datatilsynet) received a complaint from a data subject, stating that her former employer had changed the password of and taken over her work email account during her notice (resignation) period, without letting her know, thus not giving her an opportunity to delete personal content. Further, the email account was not deleted after she left the company.

The controller ignored her request to delete the email account and only set a vacation note. In his reply to the DPA, the controller argued that it was necessary to keep the inbox to uphold customer relations and ensure they received necessary operational information until the former employee had been replaced.

The controller did not agree that he had accessed ""personal"" emails. He had forwarded two emails he assumed to be personal, directly to the former employee, without opening them. In Norway, however, it is not relevant whether such emails are deemed personal or related to work - access to employees' inboxes is strictly regulated regardless.

The controller did not discontinue the former employee's email account until he received the first letter from the DPA. The DPA noted that the unlawful access to the complainant's email account was in breach of the fundamental principles of the GDPR, notably Article 5(1)(a) and (e) GDPR.","The DPA found violations of various provisions of the GDPR. It held that the controller violated Article 6(1)(f) GDPR when accessing the employee's email account and emails. Further, the Datatilsynet breached Article 21 GDPR since the controller insufficiently assessed the data subject's protest and nevertheless continued to process her personal data. Moreover, the controller did not inform the data subject and thereby violated Article 13 GDPR. The DPA found another breach of Article 6(1)(f) GDPR, as the controller did not discontinue the data subject's email. Finally, the right under Article 17(1)(e) GDPR was infringed as well, because the email content was not sufficiently erased.

For those violations, the controller was fined NOK 150,000 (~€14,700).

The controller was also required to update its internal practices and provide written confirmation, including documentation, to the DPA (unless the decision is appealed).",NONCOMPLIANT,"Article 5, Article 6, Article 13, Article 17, Article 21, Article 24","[29,12,23,17,45]"
"Østfold Hospital notified the DPA about a personal (patient) data breach, including insufficient security (lack of access controls and logs, not adhering to own policies and procedures) and storing personal data longer than necessary. Datatilsynets launched an investigation, which was concluded with a fine on 22 October 2020.","The DPA held that Article 32, cf. Article 24 and 5(1)(f), as well as the Health Records Act § 22, were breached due to unauthorized access to patient data; that Article 32, cf. Article 24 and 5(2), as well as the Health Records Act § 23, were breached due to unauthorized access to and possible unauthorized alteration of patient data; that Article 32, cf. Article 24 and 5(1)(f) and 5(2), as well as the Health Records Act §§ 22 and 23, were breached due lack of confidentiality, integrity and availability and that Article 32, cf. Article 24 and 5(1)(e), as well as the Health Records Act § 23, were breached due to unlawfully storing personal data.

The DPA finally held that the medical records system's option for extracting patient reports was not in line with the principles of data protection by design and default, cf. Article 25, cf. Articles 32 and 24, and that Østfold Hospital failed to adhere to the requirements as per Article 30 for this processing activity.",NONCOMPLIANT,"Article 5, Article 24, Article 32","[3,23,25,30,48]"
"A person lodged a complaint to the Norwegian DPA (Datatilsynet) for having been subject to what they felt was an unlawful credit rating by the company Ultra-Technology AS. The company claimed legal grounds for this in Article 6(1)(f) GDPR, pursuing a third party's legitimate interest.

After receiving the DPA's notification of a fine, the company claimed they had other internal policies and procedures in place which would be sufficient for credit ratings. They also claimed that the intended fine was too high.","The Norwegian DPA (Datatilsynet) held that Ultra-Technology AS had no legal basis as per Article 6(1)(f) GDPR to conduct the credit rating, because the legitimate interest must be based on the company's requirement and interest.

Consequently, the DPA fined the company €12,785 (NOK 125,000), reduced from NOK 175,000, however only due to the long case processing time (in line with the Norwegian Privacy Appeal Board's latest decisions) and not the company's request for a reduced fine.

The DPA also held that company must create a company policy and implement internal controls of their credit rating process, in line with Article 24.",NONCOMPLIANT,"Article 6, Article 24","[41,48,18,32,15]"
"A bank launched a new online portal for a selection of customers (about 500) where they would be able to see their loans. However, as a result of ""frequent navigation"" and, consequently, a problem with verifying sessions per user, some customers were able to see other customers' data, including contact information, while others only saw incorrect loan details. After a customer notified the bank that her loan details were incorrect, the bank immediately shut the portal down. By then, 91 customers had logged on and had potentially viewed incorrect data/ data of other data subjects. When asked about the exact reason why the discrepancy occurred, the bank was not able to recreate the error.

The bank claimed they tested the portal between May and August 2019. After this incident, they conducted thorough testing and added an extra verification measure in the system, before they testing once again and did another launch for a selection of customer. After 14 days without errors, they launched the portal to all customers and after six months operations, no new errors have been discovered.

When asked by the DPA, the bank said that they had assessed the risks for the rights and freedoms of the customers as ""low"" because they could not change the information themselves and the personal data presented were not of a sensitive nature. However, they were not able to document that they had made this assessment.","First, the DPA held that the bank did not comply with the GDPR requirements for conducting risk assessments. Both Article 24 and Article 32 GDPR impose such an obligation.

Considering the individual case a thorough assessment would have been necessary. This is due to the following facts: Although financial data do not constitute special categories of personal data within the meaning of Article 9 GDPR, they are nevertheless to be considered sensitive data. Personal data in a large number were processed.

However, the controller could not present documentation or in any other way demonstrate that they have made the necessary assessments.

Second, the DPA found that the controller failed to take appropriate technical measures (testing) when launching the new online portal.

The DPA repeated that the controller did not assess the risk correctly.

With regard to measures under Article 32 of the GDPR, the DPA has ruled the following. Despite of the facts that the controller tested the portal in its own test environment and only launched it for a selection of customers, those measures were not sufficient. The testing was not specifically described and documented. Further, the error occurred during frequent navigation of the page. The DPA considered that the breach could have been avoided if the bank had tested sufficiently.

Consequently, the DPA fined the controller NOK 400,000 (€ 39,700) for failing to assess risks and conduct testing when launching a new customer portal.",NONCOMPLIANT,"Article 24, Article 32","[40,25,17,9,32]"
"""Trumf"" is a customer loyalty program owned and run by the company with the same name (the controller). Users can register their Trumf card at various stores, gas stations, airlines and other Trumf partners to collect bonus points, which can then be used to purchase goods or be withdrawn as cash.

In 2016, it was discovered that people could register other people's bank account numbers to get access to their detailed purchase history. At the time, the Norwegian DPA (Datatilsynet) instructed the controller to mitigate this security risk. The controller confirmed that this would be dealt with promptly by implementing a verification mechanism which would solve the problem.

However, in 2020, the DPA, through various news stories, became aware that the security issue was still unresolved. The controller explained that it had been too challenging to resolve it and, further, that they did not report these breaches because they thought they did not have to. Consequently, they did not adhere to Article 33(5) GDPR, nor Article 33(1).","The Norwegian DPA held that Trumf had breached Article 33(1) for failing to notify them of repeated personal data breaches, Article 33(5) for failing to document these breaches, and Article 32 for failing to implement sufficient technical and organizational measures. For these violations, the DPA fined the controller €500,185 (NOK 5,000,000).",NONCOMPLIANT,"Article 32, Article 33","[12,22,6,13,26]"
"On their own initiative, the Norwegian DPA requested information from the Directorate of Norwegian Correctional Service (DCS) regarding their processing of personal data, specifically an overview of such processing (equivalent to Article 30 GDPR) for purposes related to the Execution of Sentences Act, and details about the controller, the various processing activities in the correctional services, as well as a description of the roles and responsibilities internally.

The DCS responded that they lack an overview of personal data processing activities, despite having procured a dedicated system for this purpose. They had initiated the work, but could only document ten processing activities - which are insufficient as per the GDPR, their own view. The DCS further stated that they process several - and many to a great extent - sensitive personal data related to sentencing. Consequently, it's important that the directorate has a good overview and control of personal data processing.","The DPA held that the Directorate of Correctional Service (DCS) must 1) establish records of processing activities in line with the Norwegian Personal Data Act of 2000 § 14 and the associated Regulation on personal data processing § 2-4, 2) describe how the responsibility for personal data processing is structured and distributed in the directorate, both organisationally and practically, cf. the Regulation on personal data processing § 2-7, and 3) send the DPA their internal controls documentation, cf. the Personal Data Act of 2000 § 14. Relevant documentation must be enclosed.",NONCOMPLIANT,Article 30,"[25,41,31,21,10]"
"In the fall of 2020, the Norwegian Parliament (Stortinget) had a personal data breach related to employees' email accounts, discovered after an employee had been contacted by their bank about an attempt of misuse of their payment card abroad. The Parliament discovered that the perpetrators had downloaded various data, including personal data information about their bank accounts, birth dates and health-related data.

The Parliament had not enabled two-factor authentication in their email system, despite having identified the lack of such as a ""high risk"" in their risk analysis of March 2020. They had also identified a lack of security culture, low competency and little focus on data protection as very high risks.

When the DPA reviewed the risk analysis in May 2021, two-factor authentication was still not fully implemented. In their notification of a decision, the DPA noted that the Parliament's administration, represented by the Secretary General, was grossly negligent.","The DPA found that the Parliament, despite having identified several risks, lacked sufficient technical and organizational measures, including two-factor authentication, thus breaching Article 32(1)(b) GDPR and Article 32(1)(d), cf. Article 5(1)(f) GDPR.

For this, the DPA fined the Parliament about €196,400 (NOK 2 million).",NONCOMPLIANT,"Article 5, Article 32","[47,31,43,34,48]"
Datatilsynet received a notification of a personal data breach from Asker municipality. The municipality had published 127 counts of personal ID numbers and information deemed confidential under the Public Administration Act in the title of the public records. The documents themselves were not published.,"The DPA found that the municipality had violated Articles 5 and 6 GDPR by publishing personal data on their webpage without a legal basis, and Articles 5 and 32(1)(b) by failing to implement appropriate technical and organisational measures to ensure ongoing confidentiality and integrity in their systems, and Article 24 GDPR for not implementing proper routines when handling the public records of mail. Datatilsynet held that publishing the title of documents containing sensitive information was a breach of Article 32(1)(b) GDPR, highlighting that the breach was reported to the municipality by a private individual and not noticed by the municipality itself. Datatilsynet highlighted that the personal data in question was not covered by the Public Administration Act. As such, the municipality did not have a legal basis cf. Article 6 GDPR. In addition, Datatilsynet found that the municipality lacked routines for publishing information to the public, violating Article 24 GDPR.",NONCOMPLIANT,"Article 5, Article 6, Article 24, Article 32","[5,8,30,37,47]"
"The Norwegian DPA (Datatilsynet) received a complaint from a data subject who had been credit rated by a private investigation company, whom had informed in their privacy notice that they should be viewed as the controller as per the GDPR, for any such processing of the personal data of third parties.

The controller had been hired by the data subject's former partner. She claimed to have a financial claim against the data subject. He disputed this and also claimed he did not have any  funds to pay for such a claim, regardless. Consequently, the controller conducted a credit rating of the data subject, to validate his claims.

Following the data subject's complaint, the DPA launched an investigation.","The DPA found that the controller lacked a legal basis as per Article 6(1) GDPR, and informs in their decision that the relevant legal basis as per the GDPR, is Article 6(1)(f). The DPA found that the controller had also breached Article 5(2) GDPR, cf. Article 24.

For this, the DPA intends to fine the controller NOK 50,000 (€5,000), for conducting a credit rating without a legal basis under Article 6(1) GDPR and for not adhering to the accountability principle as per Article 5(2) GDPR, cf. Article 24. The DPA also requires that the company implement internal controls of their credit rating process. The controller has four weeks to fulfill the penalties, unless they appeal.

The controller has three weeks to appeal the decision, otherwise it will take full effect.",NONCOMPLIANT,"Article 5, Article 6, Article 24","[41,11,37,13,24]"
"In April 2021, a data subject in Germany owning shares in the company Mowi ASA (controller) was notified by his bank that the controller had requested his personal data. After two unsuccessful attempts at getting information about this processing from the controller, the data subject lodged a complaint with the Norwegian DPA Datatilsynet, which initiated an investigation and contacted the controller.

The controller acknowledged that it had not responded to the data subject’s access request because the emails had ended up in the spam filter. It also confirmed that it did not provide information on the processing in question, directly to shareholders or in their privacy policy, but claimed it relied on the exceptions set out in Article 14(5)(a) and Article 14(5)(c) GDPR.","The DPA rejected the controller's views as it argued that the exceptions in Article 14(5) GDPR should be interpreted and applied narrowly and it is not sufficient to “assume” that a data subject has received the information required under Article 14 GDPR, as the controller did in this case. In addition, the DPA found the controller's privacy policy to be incomplete and misleading.

The controller did not raise any arguments to contest the DPA's conclusions and informed the DPA that it was in the process of updating their privacy policy, internal documentation and routines.

The DPA held that the controller had violated Article 14 GDPR and ordered it to take measures to ensure that data subjects, including shareholders whose personal data are processed pursuant to the Norwegian Public Limited Liability Companies Act, are provided with all of the information required by Article 14 GDPR, including by amending its privacy policy as necessary. The controller was also ordered to inform the DPA about its measures taken within four weeks.",NONCOMPLIANT,"Article 12, Article 14, Article 15, Article 55, Article 56","[22,2,11,20,35]"
"In August 2020, the Danish Data Protection Agency completed a planned written inspection at SIF Gruppen A / S. The audit focused on the company's compliance with the rules on disclosure by using control measures towards employees. The audit also focused on whether SIF Gruppen A / S 'observance of the duty to provide information complied with the regulation's basic principle of transparency.

SIF Gruppen A / S has informed the Danish Data Protection Agency that the company makes use of the following control measures towards employees:

CCTV surveillance in connection with employees' stays at the company's address.
   GPS monitoring in service cars.
   ""Find me"" function in mobile phones and tablets.

SIF Gruppen A / S has stated that the company's employees are informed about the TV surveillance via signs at the company. Based on the information provided, the Danish Data Protection Agency assumes that the signs constitutes the information that the employees are given about TV surveillance, and that the signs are not supplemented by additional written information to the employees.

SIF Gruppen A / S has stated that employees are notified of the processing of personal data in connection with the use of GPS monitoring as a control measure in the company's local agreements. In this connection, SIF Gruppen A / S has sent a template for such a local agreement, just as the company has sent copies of a number of signed local agreements as documentation of the company's compliance with the duty to provide information in practice.

It appears from the example provided that the overall purpose of GPS monitoring of the service vehicles is to collect data regarding driving history, driving behavior and technical data about the service vehicle. In this connection, a number of more specific purposes have been stated for which the information collected will be used.

Regarding the storage period, it appears that the collected information - for reasons of accounting, documentation and analytical purposes - is stored for up to 5 years, after which the information is deleted. However, individual information on the individual employee may not be used in employment law after 4 months.

Regarding any recipients of the information, it appears, among other things, that relevant administrative persons and managers will have access to individual information regarding vehicles within their own area of ​​responsibility and work. An updated list of user rights will be available in the system at all times.","The Danish Data Protection Agency finds that SIF Gruppen A / S ’notification of the processing of personal data in connection with GPS monitoring in the service vehicles does not meet the requirements of Article 13 (1) (c) (2) (d) GDPR.

Regarding the storage period, it appears that the collected information - for reasons of accounting, documentation and analytical purposes - is stored for up to 5 years, after which the information is deleted. However, individual information on the individual employee may not be used in employment law after 4 months.

Based on the submitted images, the Danish Data Protection Agency can conclude that the signage regarding CCTV only contains information about the fact that CCTV surveillance is carried out. In addition, a telephone number is indicated on the doorman, just as the company name is indicated on the sign. This is not enough information.",NONCOMPLIANT,"Article 5, Article 12, Article 13, Article 14","[4,41,14,29,35]"
The Datatilsynet conducted some investigations at Udbetaling Danmark focusing on the answers to access request and thus on the compliance with Articles 12 and 15 GDPR.,"Despite the procedures, guidelines and templates created and implemented by the controller, the Datatilsynet ruled that Udbetaling Danmark infringed both Articles 12(3) and 15 GDPR.

The authority stressed out that the controller did not provide the data subject with the necessary information pursuant to Article 15 (1) (h) GDPR. Indeed, the controller did not provide the data subject with the specific information on whether automatic decisions have been made against the data subject. The authority issued that the controller should from now on answer clearly to the data subject if he/she has been subject to automated decision making. For example, the authority recommend that the controller could state in each response whether or not automatic decisions have been made vis-à-vis the data subject.

In addition, the authority pointed out that the controller answered to 2 subject access requests with undue delay. Although the controller claimed that they needed time to confirm the data subject identification, the authority ruled that the one-month deadline was not respected and thus that, Article 12(3) was infringed.",NONCOMPLIANT,"Article 12, Article 15, Article 22","[0,11,30,32,29]"
The Datatilsynet conducted some audits at the Municipality of Odense focusing on the compliance of Articles 12 and 15 GDPR.,"The authority ruled that the controller had to some extend drafted guidelines, procedures, etc. for the municipality's compliance and its administrations with Article 15 GDPR.

However, the Datatilsynet stressed out that the Controller did not answer with the one month dealdine and thus, infringed Article 12(3) GDPR for some access requests. The authority pointed out that the controller did answer to 33% of the access requests with undue delay. Indeed, the Authority underlined that the administrations which are required to collect the information within a deadline of 14 days, as a first step, should apply this deadline only when it is necessary and not by default.",NONCOMPLIANT,"Article 12, Article 15","[33,29,19,35,42]"
"In December 2018 - February 2019, the Danish Data Protection Agency received a number of notifications from the country's municipalities regarding the Joint Municipal Management Information System (FLIS). The purpose of the system was to provide management information to the municipalities. However, the company managing the FLIS system (Kombit A/S), which in this instance was acting as processor, mistakenly forgot to limit the access to the data of the individual municipalities. Therefore, for the duration of 4 months, individual municipalities and suppliers of Business intelligence could illegally access the social security numbers and employment details of 4.2 million Danish citizens.","The processor of the information management system (Kombit A/S) tried to argue that no data was made publicly available on the Internet. However, it follows from Article 28(1) and Article 28(3)(f) of the GDPR that the data processor (in this instance Kombit A/S) is required to assist the data controller (the Danish municipalities) in ensuring compliance with the obligations under Articles 32 to 36, taking into account the nature of the processing and the information available to the data processor.

The DPA also held that it followed from Article 32(1) of the GDPR that the data controller and the data processor must implement appropriate technical and organizational measures to ensure the continued confidentiality of processing systems and services. In context, the DPA held that this meant that both the controller and processor had to ensure that the system which had been implemented (FLIS) had been tested for inconveniences. As a result of an error in the setup of a particular data filter in FLIS, there had been an unlawful disclosure of information, which involved information relating to the social security numbers and employment of 4.2 million Danish citizens. Therefore, there had been a breach of Article 32 of the GDPR.

Furthermore, the DPA held that Kombit A/S as a processor had not performed the necessary tests on the FLIS system, as it did not detect the incorrectly set up filter, which is what led to the unlawful disclosure of information in the first place. The DPA therefore found that Kombit A/S in its function as processor for the 74 municipalities had not complied with Article 28(1) of the GDPR through lacking appropriate technical and organizational measures.

On the basis of the above, the DPA expressed serious criticism against Kombit A/S, stating that its processing of personal data had not taken place in accordance with the GDPR.",NONCOMPLIANT,"Article 28, Article 32","[3,9,28,30,46]"
"The Danish Data Protection Authority has received a number of reported data breaches from more than twenty Danish banks in accordance with Article 33 GDPR. The reported data breaches concern the accidental disclosure of personal addresses in connection with automated payment transfers between banks. Automated payment transfers between the 25. May 2018 and the 22. August 2019 were affected. It is estimated that more than 20,000 customers have been affected by the error.

The Danish company Bankernes EDB Central (BEC) supplies software to banks and financial institutions. Payment transfers from BEC are usually accompanied by address information so the payee can identify the payer. BEC has access to personal addresses in the Danish Central Person Register (CPR). The CPR contains the possibility to protect personal addresses from disclosure. An error in the system operated by BEC led to the disclosure of personal addresses, regardless of a requested non-disclosure of addresses in the CPR.","The Danish DPA decided that BEC did not implement appropriate technical and organisational measures to protect personal data from unauthorized disclosure.

Subject to the critics is the fact that BEC initially used an older IT solution without the implementation of address protection. After the shift to a new system, errors occurred in connection with the marking of the protection of the addresses resulting in an unauthorized disclosure.

The Danish DPA emphasized that BEC has in response to the discovery of the unauthorized disclosures quickly and effectively made some changes to the patches in the IT-system which ended the breach. Further, adequate deletion measures have been taken.",NONCOMPLIANT,"Article 5, Article 32","[44,47,34,41,15]"
"In October 2019, the Danish DPA (Datatilsynet) was notified by a number of municipalities regarding the system ""Schultz Expose"", operated by the company JH Schultz Information A/S. The purpose of the system is to provide management information to the job centers in the municipalities, which on the basis of the information can make decisions concerning the municipality's operations on a database basis.

During a system update, a security component that was supposed to ensure that only the relevant information was available to users with access to the system was temporarily disabled. As the update - due to a process that could not be completed - did not proceed as expected, the security component was not reactivated as scheduled.

As a result of the error, it was possible for unauthorized employees in the municipalities to access employment-related information about approx. 1,5 million citizens from other municipalities.

The company has stated that access to the system occurred through a login with personal certificates, and that access to the system is logged. Thus, the processor was able to establish that three named employees in three municipalities accessed the system during the period when the security component was deactivated. Furthermore, in two of the three cases, data sets were retrieved containing information about citizens who did not belong to the municipality in question.

Types of personal data unlawfully accessed:

* gender, age and citizenship
* information about unemployment benefits, job clarification and similar, as well as corresponding target groups (unemployment benefit recipient, cash benefit recipient, etc.)
* job status: fully/partially unemployed
* work type: flex jobs, company internships, ordinary jobs, etc.
* place of work: the individual companies or organizations that are responsible for a given activity/job
* number of calls, type and time
* number of absences, exemptions and durations of these in connection with activities","The DPA held that the processor acted in breach of the GDPR, and expressed criticism for the security incident.",NONCOMPLIANT,"Article 28, Article 32","[4,12,17,19,43]"
"Following an investigation conducted by the DPA on 17 January 2020, it was found that almost 500,000 images of children and young people were published on Epic Booking´s Facebook page. The photos were taken at parties and other similar events since 2013 primarily using a selfie camera.

Epic Booking argued that the company does not process information about children below the age of 14 years, as it is against the company´s policy.

In its comments submitted to the DPA, Epic Booking stated that the company used a consent as a lawful bases for processing of the data subjects´ personal data (cf. Article 6(1)(a) of the GDPR) and the data subjects were informed about a possibility to revoke their consent.

Moreover, Epic Booking has submitted to the DPA a text with the information that had been provided to the data subjects prior to giving their consent for processing, and claimed that the company fulfilled its obligation under Article 13 of the GDPR.

Epic Booking also argued that the company has not set specific time limits for storing images on its Facebook page due to the data subjects´ expectation.","The DPA severely criticized Epic Booking for unlawful processing of personal data and issued an order to delete all pictures that were published on the company´s Facebook page without valid data subjects´ consent. The DPA found that the data subjects, at the time of giving consent, were not informed that the processing has multiple purposes and consequently, not be able to choose the purposes for which they wish to give their consent.

Additionally, the DPA expressed criticism for failing to set a specific time limit for storage of images on Epic Booking´s Facebook page. The DPA ordered the company to set a retention period for deletion of pictures, which will be published on its Facebook in the future, to maximum 60 days.

The DPA also severely criticized Epic Booking for failing to meet the obligation set out in Article 13(1) and (2) of the GDPR. The DPA found that the text provided to the data subjects at the time when personal data are obtained did not contain information on the purposes of the processing and the period for which the images will be stored on the company´s Facebook page.",NONCOMPLIANT,"Article 4, Article 5, Article 6, Article 13","[41,34,42,46,27]"
"In 2018, the management company PrivatBo assisted a housing fund with the sale of three properties. PrivatBo had provided the documents necessary for the sale of the properties to the occupants of the properties via USB keys. However, the documents handed to the occupants contained personal data of a confidential nature, such as the leases of tenants, which should not have been handed out. The matter was brought before the Danish DPA.",Datatilsynet held that PrivatBo had not complied with the requirements of Article 32 of the GDPR to implement appropriate technical and organizational security measures. Datatilsynet also chose to report PrivatBo to the police for the unintentional disclosure of personal information that took place as part of the handing over of the 424 USB keys. Datatilsynet also expressed further criticism against PrivatBo for sharing information about outstanding deposits and prepaid rent with residents in a property other than that which was subject to the tender obligation in question.,NONCOMPLIANT,Article 32,"[33,28,2,13,27]"
"The Danish company “BroBizz” that provides automatic payment on bridges and ferries reported three breaches of personal data security regarding the identification of natural persons.

It follows from Article 12 (1) GDPR that, without prejudice to Article 11, if there is reasonable doubt as to the identity of the natural person making a request under Articles 15 to 21, the data controller may request additional information necessary to confirm the identity of the data subject.

It further follows from Article 32 (1) GDPR that the data controller must take appropriate technical and organizational measures to ensure a level of security appropriate to the risks inherent in the data controller's processing of personal data.

In the opinion of Datatilsynet, this means, among other things, that data controllers must ensure that information about data subjects does not come to the attention of unauthorized persons.","After a review of the cases, Datatilsynet found that there is reason to express serious criticism that BroBizz's processing of personal data has not taken place in accordance with the rules of Article 32 GDPR since BroBizz has failed to comply with the requirement to implement appropriate organizational security measures in securing the identity of the natural person making a request within the meaning of Articles 15-21 GDPR.

Datatilsynet emphasized that the same type of incident happened three times within a short time. Therefore, the cases indicate that BroBizz's internal procedures and instructions are either insufficient or that employees are not sufficiently familiar with them.

Datatilsynet also found grounds for issuing an order from BroBizz to assess the risks to data subjects associated with the type of personal data processing undertaken by the company in securing the identity of the natural person making a request . The risk assessment is a part of the communication of the data breach to the data subject according to Article 34 (1), (2) GDPR and must include a mapping of the risk to the rights of the data subjects and then a balance of these risks in relation to the measures taken to protect these rights.

Datatilsynet stated that the copy of a risk assessment submitted by BroBizz is not considered to include an assessment of what risks a disclosure to unauthorized persons may pose to the rights and freedoms of customers. Datatilsynet ruled that the document deals only with the incident itself and does not affect possible risks to the rights of the data subjects, especially exemplified by the fact that the document shows that the consequence for the customer is that ""information is provided to the wrong customer"". The assessment may, for example, mention possible theft, for example. In addition, location information can have extremely unpleasant consequences for the data subject in the hands of people with bad intentions, for example in cases of harassment or stalking.

In addition, Datatilsynet lacks documentation on how BroBizz has arrived at the assessed consequences and probabilities, including special documentation on how BroBizz has concluded that the likelihood that employees process customer inquiries without verification is considered ""very small"". Datatilsynet did not agree, especially considering that this has happened in three cases shortly.",NONCOMPLIANT,"Article 32, Article 33, Article 34","[36,23,17,44,27]"
"The Family Court reported 158 breaches of personal data security to the Danish DPA. 130 (DPA's estimate) to 134 (Family Court's estimate) of the 158 involved accidental disclosure of personal data. 34 of the cases involved people with specially-requested protection of their name and address in the CPR register. The personal data of up to 3493 citizens were improperly disclosed in all.

The majority of cases were due to human error. A minority of cases occurred through the Family Court's self-service web interfaces, where parties to a case were able to see personal data of other involved persons. This was due to a programming mistake in querying the CPR register. There was insufficient frequency and rigor of system tests which should have caught such a mistake.

There was not a proper data processor agreement with CBRAIN A/S, one of the firms responsible for the web services, and there were no instructions with another data processor, Visma Consulting A/S.

Employees and middle management were aware of security issues since 2016. The leadership was made aware in April 2020, and their planned steps for addressing it were underprioritized.","The DPA held that the Family Court was in serious violation of Article 32(1) GDPR due to the scope of the data mishandling and the sensitivity of the subject. Moreover, the Family Court violated Article 28(3) with insufficient written agreement with two data processors, CBRAIN and Visma Consulting.",NONCOMPLIANT,"Article 28, Article 32, Article 33","[20,9,38,7,22]"
"On 3 January 2020 the Copenhagen Zoo reported a breach of personal data security to the Danish DPA. A software engineer informed the Zoo that via a self-developed script he acquired access to annual cardholders' log-in information (username and associated password). In turn, it was possible to gain unauthorized access to card numbers, names, addresses and e-mails of approx. 140,000 annual cardholders registered.

The Zoo was unable to say how many of data subjects were affected and for how long. It stated that the engineer gained access to the data but did not use it. Following the analysis of web page views, the Zoo concluded that it was unlikely that annual cardholders data were exposed to unauthorized parties.

The Zoo partially notified the data breach to data subjects on 3 January 2020 via e-mail and website. However, it did not inform data subjects about the likely consequences of the breach or an approximate indication of the period during which the breach lasted. Subsequently, the Danish DPA found out that the communication had not reached all of the annual cardholders registered.

After the breach of personal data security, the Zoo introduced a new log-in feature: (1) ""i'm not a robot"" feature and (2) a feature that blocks log-in for one hour after three erroneous log-in attempts. All annual card holders were forced to change their password.","The Danish DPA found that Zoo has not complied with Article 32 (1) of the GDPR by failing to implement an appropriate level of security of the login page for annual cardholders. The DPA advised to introduce a procedure that ensures regular assessment of the effectiveness of the security measures.

Furthermore, the DPA stated that the Zoo did not notify properly about the measures taken to deal with the breach and thus failed to comply with Article 33 (3) of the GDPR.

The DPA assessed that the Zoo did not comply with Article 34(1) of the GDPR by failing to carry out an adequate assessment of the risks posed to the data subjects. The communication provided by the Zoo to the annual cardholders was incomplete and inaccurate.

In the view of the DPA, a communication of the data breach only via a website to some of the data subjects constitutes a breach of Article 5(1a) of the GDPR.

The Zoo has been ordered to rectify the incomplete communication to all data subjects and to inform the data subjects of the breach in cases where there was a high risk. If the Zoo finds that it is not possible or requires a disproportionate effort to make an individual notification of the data subjects,  the communication can be made by public announcement or similar measure.",NONCOMPLIANT,"Article 5, Article 32, Article 33, Article 34","[24,40,13,10,3]"
"On 10 August, the secretariat of the Danish DPA has formally reported a data breach to the Datatilsynet. The breach consisted in the fact that papers which contained confidential and sensitive information, and which therefore should have been shredded, were inadvertently disposed as ordinary paper waste.

The situation started taking place from March 2020, while the DPA was in the process of moving into new premises. Even though the secretariat was aware of the data breach, a formal notification was only made on 10 August. The secretariat of the DPA stated that human error was the reason for the breach not having been reported within the 72-hour time limit mandated by Article 33(1).","The Datatilsynet found a violation of the GDPR, as the DPA's secretariat failed to ensure appropriate security measures, and failed to respect the data breach notification deadline. The DPA expressed 'serious criticism' regarding the data breach, and emphasised the authority's special obligation to observe and comply with the requirements that follow from the authority's own area of responsibility. Finally, the DPA noted that it has not been possible for the secretariat to identify the affected data subjects. Since the secretariat has published news about the data breach on its website on 20 and 26 August 2020, the Datatilsynet held that its secretariat acted in line with Article 34 GDPR.",NONCOMPLIANT,"Article 4, Article 32, Article 33, Article 34","[2,12,23,37,39]"
"During an audit visit to Arp-Hansen Hotel Group A / S (hereinafter Arp-Hansen), the Danish DPA became aware of a number of systems contained a lot of personal data that should have been deleted in accordance with Arp-Hansen's own set deletion deadlines. The DPA also found customer profiles which should have been deleted several years earlier. In summation, about 500,000 profiles were found that should have been deleted.","The Danish DPA held that Arp-Hansen was indeed in violation of Article 5(1)(e), noting in particular Arp-Hansen's lack of an objective reason for the extensive storage of information. Therefore, the DPA fined the hotel chain DKK 1,100,000.",NONCOMPLIANT,Article 5,"[0,12,18,43,48]"
"Lejre Municipality in Denmark reported a personal data breach and the Danish DPA asked the police to investigate the matter. It was found that a department of the Municipality uploaded minutes of meetings which contained personal data including sensitive data of adults and minors to a portal where employees had access without any control. Moreover, the Municipality did not notify the data subjects about the breach.","The DPA found that the Municipality had failed to comply with its obligation to take appropriate measures and that it should establish an access control system. It also emphasised the nature of the violation, the amount of the personal data that was exposed to the breach and the size of the municipality.",NONCOMPLIANT,Article 32,"[49,47,27,2,23]"
"Telenor Norge AS is largest digital services provider in Norway in the telecommunications and data services sectors.

The Datatilsynet opened a supervisory case based on information that Telenor had detected a security breach in its voicemail box function.","The Datatilsynet found that Telenor Norge had failed to fulfil its obligations under both Articles 33 and 32(1).

On this basis the Datatilsynet issued a reprimand to Telenor Norge pursuant to Article 58(2)(b) GDPR. Its rationale for issuing a reprimand rather than a fine was based on the Norwegian National Communications Authority already fining Telenor Norge 1.5 million NOK (approximately 139,000€) for the same incident under the Electronic Communications Act.",NONCOMPLIANT,"Article 32, Article 33, Article 58","[15,6,17,19,3]"
"One laptop belonging to the municipality Gladsaxe has been stolen from the city hall. The laptop was not encrypted. Personal data from more than 20,620 citizen were stored on the device, including information of sensitive nature and personal identification numbers.

The working laptop from one employee of the municipality Hørsholm has been other stolen from the car. It was also not encrypted. The data stored on the laptop referred to 1,600 employees of the municipality and contained social security numbers and other information of a sensitive nature.","The Danish DPA emphasized the great responsibility of municipalities, since processing of personal data happens in a large scale and also refers to sensitive data. According to the DPA the lack of encryption of devices means an unnecessary high risk to all citizen and, therefore, an actual breach of data security.

The DPA imposed a fine of DKK 100,00 against the municipality Gladsaxe and a fine of DKK 50,000 against the municipality Hørsholm.",NONCOMPLIANT,Article 32,"[9,47,24,3,29]"
"“IO” is an app run by the Italian public payment system “PagoPA S.p.A” (S.p.A is the Italian equivalent of PLC, Public Limited Company). The app IO offers access to all of the digital services of the Italian Public Administration, and has been downloaded by more than 11,5 million of users. It offers access to over 12,000 services, such as tax payment systems, which are provided by more than 5,000 national and local institutions.

The Italian DPA (Garante per la protezione dei dati personali) previously recognized some weaknesses in the IO app, in an opinion issued on June 12th, 2020 (9367375). For this reason, after the decree of May 31st, 2021—which established the digital COVID-19 Green Certifications— the Italian DPA reserved the right to conduct further investigation of the app IO, since citizens can use the app to receive and demonstrate their Green Certifications.

Through investigation, the Italian DPA detected some critical issues in the app’s interactions with Google LLC and Mixpanel Inc. These interactions include a tracking system that allows the app to link frequent behavioral patterns to certain identified (or identifiable) individuals while using the different services offered by the app IO. On the one hand, use of the app on an Android device automatically triggers Google's Firebase Analytics services, which allow Google to monitor installation of the app and to send push notifications. On the other hand, Mixpanel's tracking libraries, imbedded in the app IO, automatically sends data about a wide variety of app-based actions tied to a unique identified user back to Mixpanel systems. Both of these functions are triggered automatically during the user’s first access of the app IO, and it is up to the users themselves to disable the services if they are not interested in them.","The Italian DPA opined that data processing by Google and Mixpanel on the app IO do not conform to the principles of lawfulness, fairness and transparency, and the principles of purpose limitation, data minimization, and integrity, in accordance with Article 5(1) GDPR. It added that Google and Mixpanel had failed to make clear the purpose of data processing on the app, and that the forms of processing concerned are not strictly necessary for the purposes of ""assistance, debugging and improvement of the App IO"" declared by PagoPA.

Through the authority identified in Article 58(2)(f) GDPR, the Italian DPA imposed on PagoPA S.p.A the following limitations:

- Referring to Google LLC, the Italian DPA only allows data processing that is strictly necessary to send push notifications to app IO users who explicitly and freely activate this function for some services.

- Referring to Mixpanel Inc., the Italian DPA suspends data storage on user’s devices, access to data about app usage by identified users, and the collection of this data on Mixpanel’s systems; moreover, it suspends any other data processing concerning data that has already been sent to Mixpanel for purposes other than data retention, even by third parties.

In addition, through the authority identified in Article 58(2)(d) GDPR, the Italian DPA orders PagoPA S.p.A to adopt the appropriate technical measures to modify the activation terms of the available services in the app IO, the activation of push notifications, and the activation of forwarding functions linked to via-email, to guarantee the free, explicit, and specific consent of users to such data processing. The DPA PagoPA S.p.A to adopt these changes.",NONCOMPLIANT,"Article 5, Article 58","[29,39,48,49,40]"
"Foodinho is an Italy-based company and a subsidiary of GlovoApp23, a Spanish-based company. It operates a digital platform for on-demand food delivery in Milan. Employees are typically gig workers who deliver food orders by bike. Of relevance is that, in 2020, the Italian Supreme Court ruled that delivery riders have workers’ rights, regardless of whether they are self-employed. At the time of this decision, Foodinho has some 19,000 delivery riders on its platform.

This is the first decision from the Garante concerning riders and follows from a set of inspections on the handling of employees’ data by the main food delivery companies in Italy. As part of the investigation, the Garante also initiated, for the first time, a joint operation with the Spanish DPA (AEPD) under the terms of the GDPR to shed light on the operation of the digital platform owned by the holding company, GlovoApp23. Of concern to the Garante and the AEPD is how food delivery companies use algorithms to opaquely micromanage platform workers’ labor.

Investigation yielded multiple findings. Firstly, the company had failed to adequately inform its employees on the functioning of the platform and had not implemented suitable safeguards to ensure accuracy and fairness of the algorithmic results that were used to rate riders’ performance. The lack of such safeguards means that discriminatory reviews from clients affected rider ratings.

Secondly, Foodinho did not guarantee procedures to protect the right to obtain human intervention, express one’s opinion, and contest the rider rating resulting use of the algorithms in question, even though ratings could cause a rider to be excluded from job opportunities.

Furthermore, the Garante identified a number of further data protection shortcomings by Foodinho; it had failed to produce satisfactory Data Protection Impact Assessments, implement technical and organizational security measures, appoint a data protection officer appointment, keep records, and implement Data Protection by Design.","The Italian DPA (Garante) held that Foodinho had violated Articles 5(1)(a), (c) and (e), 13, 22, 25, 30, 32, 35 and 37 of the GDPR through its use of algorithms to manage riders doing food deliveries. Accordingly, it issued a fine of €2,600,000. In calculating the fine, the DPA took into account Foodinho’s resistance to cooperation during the investigation, and the large number of riders on the platform.

In addition, the DPA issued an injunction ordering Foodinho to take corrective measures for each violation.  Significantly, Foodinho will have to lay down measures preventing inappropriate and/or discriminatory use of reputational mechanisms based on feedback from customers and business partners.

Firstly, to minimize the risk of errors and biases in rider ratings, Foodinho was ordered to check accuracy and relevance of the data used by the system – chats, emails and phone calls between riders and customer care, geolocation at 15-second intervals, mapping of routes, estimated and actual delivery time, details on the handling of current and past orders, feedback from customers and partners, device battery level, etc.

Secondly, the DPA ordered Foodinho to address the discriminatory risk produced by the rating system, which relies on the application of a mathematical formula that penalizes riders who do not promptly accept orders or reject orders, while prioritizing riders who accept orders on schedule.

The DPA set a 60-day deadline for Foodinho to start implementing the measures required to remedy the serious shortcomings it had found, and gave Foodinho an additional 90 days to finalize a redesign of the algorithms.",NONCOMPLIANT,"Article 5, Article 13, Article 22, Article 25, Article 30, Article 32, Article 35, Article 37","[24,44,47,19,18]"
